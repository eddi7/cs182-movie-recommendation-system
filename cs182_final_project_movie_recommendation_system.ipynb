{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupationID</th>\n",
       "      <th>zip-code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID gender  age  occupationID zip-code\n",
       "0       1      F    1            10    48067\n",
       "1       2      M   56            16    70072\n",
       "2       3      M   25            15    55117\n",
       "3       4      M   45             7    02460\n",
       "4       5      M   25            20    55455"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_title = ['userID', 'gender', 'age', 'occupationID', 'zip-code']\n",
    "users_old = pd.read_csv('./ml-1m/users.dat', sep='::', header=None, names=users_title, engine = 'python')\n",
    "users_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieID                               title                        genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_title = ['movieID', 'title', 'genres']\n",
    "movies_old = pd.read_csv('./ml-1m/movies.dat', sep='::', header=None, names=movies_title, engine = 'python')\n",
    "movies_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating  timestamps\n",
       "0       1     1193       5   978300760\n",
       "1       1      661       3   978302109\n",
       "2       1      914       3   978301968\n",
       "3       1     3408       4   978300275\n",
       "4       1     2355       5   978824291"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_title = ['userID','movieID', 'rating', 'timestamps']\n",
    "ratings_old = pd.read_csv('./ml-1m/ratings.dat', sep='::', header=None, names=ratings_title, engine = 'python')\n",
    "ratings_old.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dara Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User table after preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupationID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  gender  age  occupationID\n",
       "0       1       0    0            10\n",
       "1       2       1    6            16\n",
       "2       3       1    2            15\n",
       "3       4       1    4             7\n",
       "4       5       1    2            20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv('./ml-1m/users.dat', sep='::', header=None, names=users_title, engine = 'python')\n",
    "\n",
    "# Mapping gender to number[0, 1] \n",
    "users['gender'] = users['gender'].astype('category')\n",
    "users['gender'] = users['gender'].cat.codes\n",
    "\n",
    "# Mapping age range from age gourp to 0 - 7\n",
    "age_mapping = {1: 0, 18: 1, 25: 2, 35: 3, 45: 4, 50: 5, 56: 6}\n",
    "users['age'] = users['age'].map(age_mapping)\n",
    "\n",
    "# Dropping the zip-code columm\n",
    "# users.drop('zip-code')\n",
    "users.drop('zip-code', axis=1, inplace=True)\n",
    "\n",
    "print(\"User table after preprocessing\")\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie table after preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[4269, 5129, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[3, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1052, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[4811, 2290, 1366, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1533, 2175, 1636, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1373, 605, 4829, 4526, 1255, 3771, 0, 0, 0, 0...</td>\n",
       "      <td>[5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieID                                              title  \\\n",
       "0        1  [4269, 5129, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1        2   [1052, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2        3  [4811, 2290, 1366, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3        4  [1533, 2175, 1636, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4        5  [1373, 605, 4829, 4526, 1255, 3771, 0, 0, 0, 0...   \n",
       "\n",
       "                                              genres  \n",
       "0  [3, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [2, 4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [5, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "3  [5, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('./ml-1m/movies.dat', sep='::', header=None, names=movies_title, engine = 'python')\n",
    "\n",
    "# Mapping the genres to the fixed length (len = 18) padded list\n",
    "genres_types = [\"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \n",
    "                \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \n",
    "                \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"]\n",
    "\n",
    "def genresToList(s):\n",
    "    result = [genres_types.index(g) + 1 for g in s.split(\"|\")]\n",
    "    result = result + [0 for i in range(18 - len(result))]\n",
    "    return result;\n",
    "    \n",
    "movies['genres'] = movies['genres'].apply(genresToList)\n",
    "\n",
    "# Remove year from title and mapping the title to the fixed length (len = 18) padded list\n",
    "def removeYear(s):\n",
    "    return s[:-7]\n",
    "movies['title'] = movies['title'].apply(removeYear)\n",
    "\n",
    "title_words = set()\n",
    "for title in movies[\"title\"]:\n",
    "    for word in title.split(\" \"):\n",
    "        title_words.add(word)\n",
    "title_words = list(title_words)\n",
    "        \n",
    "def titleToList(s):\n",
    "    result = [title_words.index(g) + 1 for g in s.split(\" \")]\n",
    "    result = result + [0 for i in range(15 - len(result))]\n",
    "    return result;\n",
    "\n",
    "movies['title'] = movies['title'].apply(titleToList)\n",
    "\n",
    "print(\"Movie table after preprocessing\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating table after preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating\n",
       "0       1     1193       5\n",
       "1       1      661       3\n",
       "2       1      914       3\n",
       "3       1     3408       4\n",
       "4       1     2355       5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('./ml-1m/ratings.dat', sep='::', header=None, names=ratings_title, engine = 'python')\n",
    "ratings.drop('timestamps', axis=1, inplace=True)\n",
    "\n",
    "print(\"Rating table after preprocessing\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "\n",
    "X_df, y_df = data.drop('rating', axis=1), data['rating']\n",
    "    \n",
    "X_all = X_df.values\n",
    "y_all = y_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions of Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User table dimensions:\n",
      "user_id_count: 6041\n",
      "user_gender_count: 2\n",
      "user_age_count: 7\n",
      "user_occupation_count: 21\n",
      "\n",
      "Movies table dimensions:\n",
      "movie_id_count: 3953\n",
      "movies_title_count: 5215\n",
      "movies_title_len: 15\n",
      "movies_genres_count: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"User table dimensions:\")\n",
    "user_id_count = users['userID'].nunique()+1\n",
    "print(\"user_id_count:\", user_id_count)\n",
    "\n",
    "user_gender_count = users['gender'].nunique()\n",
    "print(\"user_gender_count:\", user_gender_count)\n",
    "\n",
    "user_age_count = users['age'].nunique()\n",
    "print(\"user_age_count:\", user_age_count)\n",
    "\n",
    "user_occupation_count = users['occupationID'].nunique()\n",
    "print(\"user_occupation_count:\", user_occupation_count)\n",
    "\n",
    "\n",
    "print(\"\\nMovies table dimensions:\")\n",
    "movie_id_count = max(movies[\"movieID\"]) + 1\n",
    "print(\"movie_id_count:\", movie_id_count)\n",
    "\n",
    "movie_title_count = len(title_words) + 1\n",
    "print(\"movies_title_count:\", movie_title_count)\n",
    "\n",
    "movie_title_len = 15\n",
    "print(\"movies_title_len:\", movie_title_len)\n",
    "\n",
    "movie_genres_count = len(genres_types) + 1\n",
    "print(\"movies_genres_count:\", movie_genres_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieRecommendationModel():\n",
    "    def __init__(self, learning_rate, embed_dim = 32, filter_num = 8, window_sizes = {2, 3, 4, 5}):\n",
    "        \n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32)\n",
    "        self.ratings = tf.placeholder(tf.int32, [None, 1])\n",
    "        \n",
    "        ###########################\n",
    "        # User Features Embedding #\n",
    "        ###########################\n",
    "        self.user_id = tf.placeholder(tf.int32, [None, 1])\n",
    "        self.user_gender = tf.placeholder(tf.int32, [None, 1])\n",
    "        self.user_age = tf.placeholder(tf.int32, [None, 1])\n",
    "        self.user_job = tf.placeholder(tf.int32, [None, 1])\n",
    "        \n",
    "        uid_embed_matrix = tf.Variable(tf.random_uniform([user_id_count, embed_dim], -1, 1))\n",
    "        uid_embed_layer = tf.nn.embedding_lookup(uid_embed_matrix, self.user_id)\n",
    "    \n",
    "        gender_embed_matrix = tf.Variable(tf.random_uniform([user_gender_count, embed_dim // 2], -1, 1))\n",
    "        gender_embed_layer = tf.nn.embedding_lookup(gender_embed_matrix, self.user_gender)\n",
    "        \n",
    "        age_embed_matrix = tf.Variable(tf.random_uniform([user_age_count, embed_dim // 2], -1, 1))\n",
    "        age_embed_layer = tf.nn.embedding_lookup(age_embed_matrix, self.user_age)\n",
    "        \n",
    "        job_embed_matrix = tf.Variable(tf.random_uniform([user_occupation_count, embed_dim // 2], -1, 1))\n",
    "        job_embed_layer = tf.nn.embedding_lookup(job_embed_matrix, self.user_job)\n",
    "\n",
    "        # First FC \n",
    "        uid_fc_layer = tf.layers.dense(uid_embed_layer, embed_dim, activation=tf.nn.relu)\n",
    "        gender_fc_layer = tf.layers.dense(gender_embed_layer, embed_dim, activation=tf.nn.relu)\n",
    "        age_fc_layer = tf.layers.dense(age_embed_layer, embed_dim, activation=tf.nn.relu)\n",
    "        job_fc_layer = tf.layers.dense(job_embed_layer, embed_dim, activation=tf.nn.relu)\n",
    "        \n",
    "        # Second FC\n",
    "        user_combine_layer = tf.concat([uid_fc_layer, gender_fc_layer, age_fc_layer, job_fc_layer], 2)  #(?, 1, 128)\n",
    "        user_combine_layer = tf.contrib.layers.fully_connected(user_combine_layer, 200, tf.tanh)  #(?, 1, 200)\n",
    "    \n",
    "        user_combine_layer_flat = tf.reshape(user_combine_layer, [-1, 200])\n",
    "        \n",
    "        \n",
    "        #############################\n",
    "        # Movies Features Embedding #\n",
    "        #############################\n",
    "        self.movie_id = tf.placeholder(tf.int32, [None, 1])\n",
    "        self.movie_genres = tf.placeholder(tf.int32, [None, 18])\n",
    "        self.movie_titles = tf.placeholder(tf.int32, [None, 15])\n",
    "        \n",
    "        movie_id_embed_matrix = tf.Variable(tf.random_uniform([movie_id_count, embed_dim], -1, 1))\n",
    "        movie_id_embed_layer = tf.nn.embedding_lookup(movie_id_embed_matrix, self.movie_id)\n",
    "        \n",
    "        movie_genres_embed_matrix = tf.Variable(tf.random_uniform([movie_genres_count, embed_dim], -1, 1))\n",
    "        movie_genres_embed_layer = tf.nn.embedding_lookup(movie_genres_embed_matrix, self.movie_genres)\n",
    "        movie_genres_embed_layer = tf.reduce_sum(movie_genres_embed_layer, axis=1, keep_dims=True)\n",
    "        \n",
    "        movie_title_embed_matrix = tf.Variable(tf.random_uniform([movie_title_count, embed_dim], -1, 1))\n",
    "        movie_title_embed_layer = tf.nn.embedding_lookup(movie_title_embed_matrix, self.movie_titles)\n",
    "        movie_title_embed_layer = tf.reduce_sum(movie_title_embed_layer, axis=1, keep_dims=True)\n",
    "\n",
    "\n",
    "        # First FC Layer\n",
    "        movie_id_fc_layer = tf.layers.dense(movie_id_embed_layer, embed_dim, activation=tf.nn.relu)\n",
    "        movie_genres_fc_layer = tf.layers.dense(movie_genres_embed_layer, embed_dim, activation=tf.nn.relu)\n",
    "        movie_title_fc_layer = tf.layers.dense(movie_title_embed_layer, embed_dim, activation=tf.nn.relu)\n",
    "    \n",
    "        # Second FC Layer\n",
    "        movie_combine_layer = tf.concat([movie_id_fc_layer, movie_genres_fc_layer, movie_title_fc_layer], 2)  \n",
    "        movie_combine_layer = tf.contrib.layers.fully_connected(movie_combine_layer, 200, tf.tanh)\n",
    "    \n",
    "        movie_combine_layer_flat = tf.reshape(movie_combine_layer, [-1, 200])\n",
    "        \n",
    "        \n",
    "        pred_ratings = tf.reduce_sum(user_combine_layer_flat * movie_combine_layer_flat, axis=1)\n",
    "        self.pred_ratings = tf.expand_dims(pred_ratings, axis=1)\n",
    "        \n",
    "        cost = tf.losses.mean_squared_error(self.ratings, self.pred_ratings )\n",
    "        self.loss = tf.reduce_mean(cost)\n",
    "        \n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        self.train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n",
    "        self.saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = MovieRecommendationModel(learning_rate = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Batch:  0 / 3125 train_loss: 45.92952\n",
      "Epoch:  0  Batch:  20 / 3125 train_loss: 6.6519213\n",
      "Epoch:  0  Batch:  40 / 3125 train_loss: 4.4100714\n",
      "Epoch:  0  Batch:  60 / 3125 train_loss: 2.8271098\n",
      "Epoch:  0  Batch:  80 / 3125 train_loss: 2.3507607\n",
      "Epoch:  0  Batch:  100 / 3125 train_loss: 2.0651507\n",
      "Epoch:  0  Batch:  120 / 3125 train_loss: 2.1276565\n",
      "Epoch:  0  Batch:  140 / 3125 train_loss: 1.9820973\n",
      "Epoch:  0  Batch:  160 / 3125 train_loss: 1.6276827\n",
      "Epoch:  0  Batch:  180 / 3125 train_loss: 1.7095152\n",
      "Epoch:  0  Batch:  200 / 3125 train_loss: 1.7110256\n",
      "Epoch:  0  Batch:  220 / 3125 train_loss: 1.5151602\n",
      "Epoch:  0  Batch:  240 / 3125 train_loss: 1.5769289\n",
      "Epoch:  0  Batch:  260 / 3125 train_loss: 1.6753664\n",
      "Epoch:  0  Batch:  280 / 3125 train_loss: 1.6482515\n",
      "Epoch:  0  Batch:  300 / 3125 train_loss: 1.6682382\n",
      "Epoch:  0  Batch:  320 / 3125 train_loss: 1.6478379\n",
      "Epoch:  0  Batch:  340 / 3125 train_loss: 1.3686538\n",
      "Epoch:  0  Batch:  360 / 3125 train_loss: 1.352354\n",
      "Epoch:  0  Batch:  380 / 3125 train_loss: 1.3522003\n",
      "Epoch:  0  Batch:  400 / 3125 train_loss: 1.4053447\n",
      "Epoch:  0  Batch:  420 / 3125 train_loss: 1.2282393\n",
      "Epoch:  0  Batch:  440 / 3125 train_loss: 1.4455616\n",
      "Epoch:  0  Batch:  460 / 3125 train_loss: 1.4625077\n",
      "Epoch:  0  Batch:  480 / 3125 train_loss: 1.4619806\n",
      "Epoch:  0  Batch:  500 / 3125 train_loss: 1.099957\n",
      "Epoch:  0  Batch:  520 / 3125 train_loss: 1.4847405\n",
      "Epoch:  0  Batch:  540 / 3125 train_loss: 1.3602304\n",
      "Epoch:  0  Batch:  560 / 3125 train_loss: 1.5370895\n",
      "Epoch:  0  Batch:  580 / 3125 train_loss: 1.4421098\n",
      "Epoch:  0  Batch:  600 / 3125 train_loss: 1.3884194\n",
      "Epoch:  0  Batch:  620 / 3125 train_loss: 1.5063481\n",
      "Epoch:  0  Batch:  640 / 3125 train_loss: 1.3886256\n",
      "Epoch:  0  Batch:  660 / 3125 train_loss: 1.346974\n",
      "Epoch:  0  Batch:  680 / 3125 train_loss: 1.309536\n",
      "Epoch:  0  Batch:  700 / 3125 train_loss: 1.4003084\n",
      "Epoch:  0  Batch:  720 / 3125 train_loss: 1.2061312\n",
      "Epoch:  0  Batch:  740 / 3125 train_loss: 1.4098401\n",
      "Epoch:  0  Batch:  760 / 3125 train_loss: 1.3292736\n",
      "Epoch:  0  Batch:  780 / 3125 train_loss: 1.3826921\n",
      "Epoch:  0  Batch:  800 / 3125 train_loss: 1.2254155\n",
      "Epoch:  0  Batch:  820 / 3125 train_loss: 1.2188244\n",
      "Epoch:  0  Batch:  840 / 3125 train_loss: 1.2712789\n",
      "Epoch:  0  Batch:  860 / 3125 train_loss: 1.1810715\n",
      "Epoch:  0  Batch:  880 / 3125 train_loss: 1.1506511\n",
      "Epoch:  0  Batch:  900 / 3125 train_loss: 1.2453855\n",
      "Epoch:  0  Batch:  920 / 3125 train_loss: 1.2916937\n",
      "Epoch:  0  Batch:  940 / 3125 train_loss: 1.3127131\n",
      "Epoch:  0  Batch:  960 / 3125 train_loss: 1.3570359\n",
      "Epoch:  0  Batch:  980 / 3125 train_loss: 1.4213138\n",
      "Epoch:  0  Batch:  1000 / 3125 train_loss: 1.4057683\n",
      "Epoch:  0  Batch:  1020 / 3125 train_loss: 1.3622537\n",
      "Epoch:  0  Batch:  1040 / 3125 train_loss: 1.2792406\n",
      "Epoch:  0  Batch:  1060 / 3125 train_loss: 1.4484172\n",
      "Epoch:  0  Batch:  1080 / 3125 train_loss: 1.2008736\n",
      "Epoch:  0  Batch:  1100 / 3125 train_loss: 1.3811398\n",
      "Epoch:  0  Batch:  1120 / 3125 train_loss: 1.2418315\n",
      "Epoch:  0  Batch:  1140 / 3125 train_loss: 1.3947783\n",
      "Epoch:  0  Batch:  1160 / 3125 train_loss: 1.296528\n",
      "Epoch:  0  Batch:  1180 / 3125 train_loss: 1.2935538\n",
      "Epoch:  0  Batch:  1200 / 3125 train_loss: 1.2395288\n",
      "Epoch:  0  Batch:  1220 / 3125 train_loss: 1.1542828\n",
      "Epoch:  0  Batch:  1240 / 3125 train_loss: 1.0761845\n",
      "Epoch:  0  Batch:  1260 / 3125 train_loss: 1.2950058\n",
      "Epoch:  0  Batch:  1280 / 3125 train_loss: 1.2361972\n",
      "Epoch:  0  Batch:  1300 / 3125 train_loss: 1.2833332\n",
      "Epoch:  0  Batch:  1320 / 3125 train_loss: 1.2274945\n",
      "Epoch:  0  Batch:  1340 / 3125 train_loss: 1.0653077\n",
      "Epoch:  0  Batch:  1360 / 3125 train_loss: 1.1936637\n",
      "Epoch:  0  Batch:  1380 / 3125 train_loss: 1.0888451\n",
      "Epoch:  0  Batch:  1400 / 3125 train_loss: 1.3135233\n",
      "Epoch:  0  Batch:  1420 / 3125 train_loss: 1.21381\n",
      "Epoch:  0  Batch:  1440 / 3125 train_loss: 1.1396875\n",
      "Epoch:  0  Batch:  1460 / 3125 train_loss: 1.2589552\n",
      "Epoch:  0  Batch:  1480 / 3125 train_loss: 1.178374\n",
      "Epoch:  0  Batch:  1500 / 3125 train_loss: 1.3321728\n",
      "Epoch:  0  Batch:  1520 / 3125 train_loss: 1.3096589\n",
      "Epoch:  0  Batch:  1540 / 3125 train_loss: 1.3099201\n",
      "Epoch:  0  Batch:  1560 / 3125 train_loss: 1.1971109\n",
      "Epoch:  0  Batch:  1580 / 3125 train_loss: 1.2152858\n",
      "Epoch:  0  Batch:  1600 / 3125 train_loss: 1.2314286\n",
      "Epoch:  0  Batch:  1620 / 3125 train_loss: 1.2208828\n",
      "Epoch:  0  Batch:  1640 / 3125 train_loss: 1.2465558\n",
      "Epoch:  0  Batch:  1660 / 3125 train_loss: 1.2863021\n",
      "Epoch:  0  Batch:  1680 / 3125 train_loss: 1.2135196\n",
      "Epoch:  0  Batch:  1700 / 3125 train_loss: 1.1110404\n",
      "Epoch:  0  Batch:  1720 / 3125 train_loss: 1.158408\n",
      "Epoch:  0  Batch:  1740 / 3125 train_loss: 1.2011588\n",
      "Epoch:  0  Batch:  1760 / 3125 train_loss: 1.2428646\n",
      "Epoch:  0  Batch:  1780 / 3125 train_loss: 1.1260383\n",
      "Epoch:  0  Batch:  1800 / 3125 train_loss: 1.2171078\n",
      "Epoch:  0  Batch:  1820 / 3125 train_loss: 1.1946647\n",
      "Epoch:  0  Batch:  1840 / 3125 train_loss: 1.2619933\n",
      "Epoch:  0  Batch:  1860 / 3125 train_loss: 1.2384297\n",
      "Epoch:  0  Batch:  1880 / 3125 train_loss: 1.2207766\n",
      "Epoch:  0  Batch:  1900 / 3125 train_loss: 1.08098\n",
      "Epoch:  0  Batch:  1920 / 3125 train_loss: 1.1441135\n",
      "Epoch:  0  Batch:  1940 / 3125 train_loss: 1.1757667\n",
      "Epoch:  0  Batch:  1960 / 3125 train_loss: 1.1245937\n",
      "Epoch:  0  Batch:  1980 / 3125 train_loss: 1.1259439\n",
      "Epoch:  0  Batch:  2000 / 3125 train_loss: 1.4210277\n",
      "Epoch:  0  Batch:  2020 / 3125 train_loss: 1.3250501\n",
      "Epoch:  0  Batch:  2040 / 3125 train_loss: 1.1504388\n",
      "Epoch:  0  Batch:  2060 / 3125 train_loss: 0.977963\n",
      "Epoch:  0  Batch:  2080 / 3125 train_loss: 1.2919215\n",
      "Epoch:  0  Batch:  2100 / 3125 train_loss: 1.126545\n",
      "Epoch:  0  Batch:  2120 / 3125 train_loss: 1.0942163\n",
      "Epoch:  0  Batch:  2140 / 3125 train_loss: 1.2420572\n",
      "Epoch:  0  Batch:  2160 / 3125 train_loss: 1.1387734\n",
      "Epoch:  0  Batch:  2180 / 3125 train_loss: 1.1454511\n",
      "Epoch:  0  Batch:  2200 / 3125 train_loss: 1.140279\n",
      "Epoch:  0  Batch:  2220 / 3125 train_loss: 1.063437\n",
      "Epoch:  0  Batch:  2240 / 3125 train_loss: 0.9949498\n",
      "Epoch:  0  Batch:  2260 / 3125 train_loss: 1.1110882\n",
      "Epoch:  0  Batch:  2280 / 3125 train_loss: 1.2033389\n",
      "Epoch:  0  Batch:  2300 / 3125 train_loss: 1.1952507\n",
      "Epoch:  0  Batch:  2320 / 3125 train_loss: 1.2593238\n",
      "Epoch:  0  Batch:  2340 / 3125 train_loss: 1.2270532\n",
      "Epoch:  0  Batch:  2360 / 3125 train_loss: 1.1722671\n",
      "Epoch:  0  Batch:  2380 / 3125 train_loss: 1.1142416\n",
      "Epoch:  0  Batch:  2400 / 3125 train_loss: 1.2134095\n",
      "Epoch:  0  Batch:  2420 / 3125 train_loss: 1.1779737\n",
      "Epoch:  0  Batch:  2440 / 3125 train_loss: 1.2295628\n",
      "Epoch:  0  Batch:  2460 / 3125 train_loss: 1.1333091\n",
      "Epoch:  0  Batch:  2480 / 3125 train_loss: 1.2450334\n",
      "Epoch:  0  Batch:  2500 / 3125 train_loss: 1.227519\n",
      "Epoch:  0  Batch:  2520 / 3125 train_loss: 1.1269419\n",
      "Epoch:  0  Batch:  2540 / 3125 train_loss: 1.104022\n",
      "Epoch:  0  Batch:  2560 / 3125 train_loss: 1.0289466\n",
      "Epoch:  0  Batch:  2580 / 3125 train_loss: 1.0605297\n",
      "Epoch:  0  Batch:  2600 / 3125 train_loss: 1.1066462\n",
      "Epoch:  0  Batch:  2620 / 3125 train_loss: 1.1515132\n",
      "Epoch:  0  Batch:  2640 / 3125 train_loss: 1.0914757\n",
      "Epoch:  0  Batch:  2660 / 3125 train_loss: 1.2490385\n",
      "Epoch:  0  Batch:  2680 / 3125 train_loss: 1.0660152\n",
      "Epoch:  0  Batch:  2700 / 3125 train_loss: 1.1668501\n",
      "Epoch:  0  Batch:  2720 / 3125 train_loss: 1.1723691\n",
      "Epoch:  0  Batch:  2740 / 3125 train_loss: 1.2205068\n",
      "Epoch:  0  Batch:  2760 / 3125 train_loss: 1.1702404\n",
      "Epoch:  0  Batch:  2780 / 3125 train_loss: 1.0773735\n",
      "Epoch:  0  Batch:  2800 / 3125 train_loss: 1.3716443\n",
      "Epoch:  0  Batch:  2820 / 3125 train_loss: 1.3635371\n",
      "Epoch:  0  Batch:  2840 / 3125 train_loss: 1.131188\n",
      "Epoch:  0  Batch:  2860 / 3125 train_loss: 1.1277341\n",
      "Epoch:  0  Batch:  2880 / 3125 train_loss: 1.1600883\n",
      "Epoch:  0  Batch:  2900 / 3125 train_loss: 1.2317828\n",
      "Epoch:  0  Batch:  2920 / 3125 train_loss: 1.1728349\n",
      "Epoch:  0  Batch:  2940 / 3125 train_loss: 1.1109145\n",
      "Epoch:  0  Batch:  2960 / 3125 train_loss: 1.1800106\n",
      "Epoch:  0  Batch:  2980 / 3125 train_loss: 1.1696187\n",
      "Epoch:  0  Batch:  3000 / 3125 train_loss: 1.1567241\n",
      "Epoch:  0  Batch:  3020 / 3125 train_loss: 1.2135365\n",
      "Epoch:  0  Batch:  3040 / 3125 train_loss: 1.1397918\n",
      "Epoch:  0  Batch:  3060 / 3125 train_loss: 1.1313845\n",
      "Epoch:  0  Batch:  3080 / 3125 train_loss: 1.2437205\n",
      "Epoch:  0  Batch:  3100 / 3125 train_loss: 1.1684034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Batch:  3120 / 3125 train_loss: 0.99696624\n",
      "Epoch:  1  Batch:  0 / 3125 train_loss: 1.2627752\n",
      "Epoch:  1  Batch:  20 / 3125 train_loss: 1.0628741\n",
      "Epoch:  1  Batch:  40 / 3125 train_loss: 1.1364341\n",
      "Epoch:  1  Batch:  60 / 3125 train_loss: 0.9504841\n",
      "Epoch:  1  Batch:  80 / 3125 train_loss: 1.1361308\n",
      "Epoch:  1  Batch:  100 / 3125 train_loss: 1.2025025\n",
      "Epoch:  1  Batch:  120 / 3125 train_loss: 1.233949\n",
      "Epoch:  1  Batch:  140 / 3125 train_loss: 1.161137\n",
      "Epoch:  1  Batch:  160 / 3125 train_loss: 1.019345\n",
      "Epoch:  1  Batch:  180 / 3125 train_loss: 1.1083473\n",
      "Epoch:  1  Batch:  200 / 3125 train_loss: 1.3672626\n",
      "Epoch:  1  Batch:  220 / 3125 train_loss: 1.1486139\n",
      "Epoch:  1  Batch:  240 / 3125 train_loss: 1.1341122\n",
      "Epoch:  1  Batch:  260 / 3125 train_loss: 1.1801536\n",
      "Epoch:  1  Batch:  280 / 3125 train_loss: 1.2028058\n",
      "Epoch:  1  Batch:  300 / 3125 train_loss: 1.1725489\n",
      "Epoch:  1  Batch:  320 / 3125 train_loss: 1.2639608\n",
      "Epoch:  1  Batch:  340 / 3125 train_loss: 1.0002515\n",
      "Epoch:  1  Batch:  360 / 3125 train_loss: 1.0431529\n",
      "Epoch:  1  Batch:  380 / 3125 train_loss: 1.1345439\n",
      "Epoch:  1  Batch:  400 / 3125 train_loss: 1.0713708\n",
      "Epoch:  1  Batch:  420 / 3125 train_loss: 0.9999201\n",
      "Epoch:  1  Batch:  440 / 3125 train_loss: 1.1631474\n",
      "Epoch:  1  Batch:  460 / 3125 train_loss: 1.1164105\n",
      "Epoch:  1  Batch:  480 / 3125 train_loss: 1.2131665\n",
      "Epoch:  1  Batch:  500 / 3125 train_loss: 0.8402084\n",
      "Epoch:  1  Batch:  520 / 3125 train_loss: 1.1589243\n",
      "Epoch:  1  Batch:  540 / 3125 train_loss: 1.0177603\n",
      "Epoch:  1  Batch:  560 / 3125 train_loss: 1.2153057\n",
      "Epoch:  1  Batch:  580 / 3125 train_loss: 1.1915104\n",
      "Epoch:  1  Batch:  600 / 3125 train_loss: 1.2021793\n",
      "Epoch:  1  Batch:  620 / 3125 train_loss: 1.1783543\n",
      "Epoch:  1  Batch:  640 / 3125 train_loss: 1.1523933\n",
      "Epoch:  1  Batch:  660 / 3125 train_loss: 1.0733051\n",
      "Epoch:  1  Batch:  680 / 3125 train_loss: 1.1276138\n",
      "Epoch:  1  Batch:  700 / 3125 train_loss: 1.1227264\n",
      "Epoch:  1  Batch:  720 / 3125 train_loss: 0.99306196\n",
      "Epoch:  1  Batch:  740 / 3125 train_loss: 1.1016419\n",
      "Epoch:  1  Batch:  760 / 3125 train_loss: 1.0298753\n",
      "Epoch:  1  Batch:  780 / 3125 train_loss: 1.138961\n",
      "Epoch:  1  Batch:  800 / 3125 train_loss: 1.0009916\n",
      "Epoch:  1  Batch:  820 / 3125 train_loss: 1.0298358\n",
      "Epoch:  1  Batch:  840 / 3125 train_loss: 1.034924\n",
      "Epoch:  1  Batch:  860 / 3125 train_loss: 0.9934499\n",
      "Epoch:  1  Batch:  880 / 3125 train_loss: 0.98391116\n",
      "Epoch:  1  Batch:  900 / 3125 train_loss: 1.0694871\n",
      "Epoch:  1  Batch:  920 / 3125 train_loss: 1.1092646\n",
      "Epoch:  1  Batch:  940 / 3125 train_loss: 1.157205\n",
      "Epoch:  1  Batch:  960 / 3125 train_loss: 1.1434848\n",
      "Epoch:  1  Batch:  980 / 3125 train_loss: 1.3179225\n",
      "Epoch:  1  Batch:  1000 / 3125 train_loss: 1.1305693\n",
      "Epoch:  1  Batch:  1020 / 3125 train_loss: 1.1172957\n",
      "Epoch:  1  Batch:  1040 / 3125 train_loss: 0.9871874\n",
      "Epoch:  1  Batch:  1060 / 3125 train_loss: 1.2288145\n",
      "Epoch:  1  Batch:  1080 / 3125 train_loss: 1.041903\n",
      "Epoch:  1  Batch:  1100 / 3125 train_loss: 1.0947633\n",
      "Epoch:  1  Batch:  1120 / 3125 train_loss: 1.0658232\n",
      "Epoch:  1  Batch:  1140 / 3125 train_loss: 1.1581149\n",
      "Epoch:  1  Batch:  1160 / 3125 train_loss: 1.0977626\n",
      "Epoch:  1  Batch:  1180 / 3125 train_loss: 1.1066164\n",
      "Epoch:  1  Batch:  1200 / 3125 train_loss: 1.110689\n",
      "Epoch:  1  Batch:  1220 / 3125 train_loss: 1.0593811\n",
      "Epoch:  1  Batch:  1240 / 3125 train_loss: 0.8939681\n",
      "Epoch:  1  Batch:  1260 / 3125 train_loss: 1.1541007\n",
      "Epoch:  1  Batch:  1280 / 3125 train_loss: 1.0759084\n",
      "Epoch:  1  Batch:  1300 / 3125 train_loss: 1.0560093\n",
      "Epoch:  1  Batch:  1320 / 3125 train_loss: 1.0873876\n",
      "Epoch:  1  Batch:  1340 / 3125 train_loss: 0.88584226\n",
      "Epoch:  1  Batch:  1360 / 3125 train_loss: 0.96306324\n",
      "Epoch:  1  Batch:  1380 / 3125 train_loss: 0.9572159\n",
      "Epoch:  1  Batch:  1400 / 3125 train_loss: 1.121853\n",
      "Epoch:  1  Batch:  1420 / 3125 train_loss: 1.095172\n",
      "Epoch:  1  Batch:  1440 / 3125 train_loss: 1.0165343\n",
      "Epoch:  1  Batch:  1460 / 3125 train_loss: 1.0902182\n",
      "Epoch:  1  Batch:  1480 / 3125 train_loss: 1.0425926\n",
      "Epoch:  1  Batch:  1500 / 3125 train_loss: 1.1353159\n",
      "Epoch:  1  Batch:  1520 / 3125 train_loss: 1.0897977\n",
      "Epoch:  1  Batch:  1540 / 3125 train_loss: 1.150837\n",
      "Epoch:  1  Batch:  1560 / 3125 train_loss: 0.9923161\n",
      "Epoch:  1  Batch:  1580 / 3125 train_loss: 1.0636418\n",
      "Epoch:  1  Batch:  1600 / 3125 train_loss: 1.0459095\n",
      "Epoch:  1  Batch:  1620 / 3125 train_loss: 1.0071242\n",
      "Epoch:  1  Batch:  1640 / 3125 train_loss: 1.0852007\n",
      "Epoch:  1  Batch:  1660 / 3125 train_loss: 1.1408896\n",
      "Epoch:  1  Batch:  1680 / 3125 train_loss: 1.0610006\n",
      "Epoch:  1  Batch:  1700 / 3125 train_loss: 0.93368727\n",
      "Epoch:  1  Batch:  1720 / 3125 train_loss: 0.9886586\n",
      "Epoch:  1  Batch:  1740 / 3125 train_loss: 1.0811187\n",
      "Epoch:  1  Batch:  1760 / 3125 train_loss: 1.0754797\n",
      "Epoch:  1  Batch:  1780 / 3125 train_loss: 0.9913015\n",
      "Epoch:  1  Batch:  1800 / 3125 train_loss: 1.0252006\n",
      "Epoch:  1  Batch:  1820 / 3125 train_loss: 1.0340149\n",
      "Epoch:  1  Batch:  1840 / 3125 train_loss: 1.1106335\n",
      "Epoch:  1  Batch:  1860 / 3125 train_loss: 1.1098939\n",
      "Epoch:  1  Batch:  1880 / 3125 train_loss: 1.0486231\n",
      "Epoch:  1  Batch:  1900 / 3125 train_loss: 0.9353627\n",
      "Epoch:  1  Batch:  1920 / 3125 train_loss: 1.0185792\n",
      "Epoch:  1  Batch:  1940 / 3125 train_loss: 0.95998144\n",
      "Epoch:  1  Batch:  1960 / 3125 train_loss: 0.94416976\n",
      "Epoch:  1  Batch:  1980 / 3125 train_loss: 1.0269718\n",
      "Epoch:  1  Batch:  2000 / 3125 train_loss: 1.2904695\n",
      "Epoch:  1  Batch:  2020 / 3125 train_loss: 1.2129388\n",
      "Epoch:  1  Batch:  2040 / 3125 train_loss: 0.938887\n",
      "Epoch:  1  Batch:  2060 / 3125 train_loss: 0.8669516\n",
      "Epoch:  1  Batch:  2080 / 3125 train_loss: 1.116391\n",
      "Epoch:  1  Batch:  2100 / 3125 train_loss: 0.93294406\n",
      "Epoch:  1  Batch:  2120 / 3125 train_loss: 0.96529174\n",
      "Epoch:  1  Batch:  2140 / 3125 train_loss: 1.0792818\n",
      "Epoch:  1  Batch:  2160 / 3125 train_loss: 1.0155404\n",
      "Epoch:  1  Batch:  2180 / 3125 train_loss: 0.97956485\n",
      "Epoch:  1  Batch:  2200 / 3125 train_loss: 0.9417212\n",
      "Epoch:  1  Batch:  2220 / 3125 train_loss: 0.92718464\n",
      "Epoch:  1  Batch:  2240 / 3125 train_loss: 0.8945682\n",
      "Epoch:  1  Batch:  2260 / 3125 train_loss: 1.049311\n",
      "Epoch:  1  Batch:  2280 / 3125 train_loss: 1.0442084\n",
      "Epoch:  1  Batch:  2300 / 3125 train_loss: 1.0234709\n",
      "Epoch:  1  Batch:  2320 / 3125 train_loss: 1.1205866\n",
      "Epoch:  1  Batch:  2340 / 3125 train_loss: 1.049906\n",
      "Epoch:  1  Batch:  2360 / 3125 train_loss: 1.0114002\n",
      "Epoch:  1  Batch:  2380 / 3125 train_loss: 0.96961105\n",
      "Epoch:  1  Batch:  2400 / 3125 train_loss: 1.0740993\n",
      "Epoch:  1  Batch:  2420 / 3125 train_loss: 0.9586475\n",
      "Epoch:  1  Batch:  2440 / 3125 train_loss: 1.0189412\n",
      "Epoch:  1  Batch:  2460 / 3125 train_loss: 0.9676825\n",
      "Epoch:  1  Batch:  2480 / 3125 train_loss: 1.1302123\n",
      "Epoch:  1  Batch:  2500 / 3125 train_loss: 1.0443921\n",
      "Epoch:  1  Batch:  2520 / 3125 train_loss: 1.0270563\n",
      "Epoch:  1  Batch:  2540 / 3125 train_loss: 0.9716948\n",
      "Epoch:  1  Batch:  2560 / 3125 train_loss: 0.8607155\n",
      "Epoch:  1  Batch:  2580 / 3125 train_loss: 0.89720184\n",
      "Epoch:  1  Batch:  2600 / 3125 train_loss: 0.9764388\n",
      "Epoch:  1  Batch:  2620 / 3125 train_loss: 0.96030116\n",
      "Epoch:  1  Batch:  2640 / 3125 train_loss: 0.9959299\n",
      "Epoch:  1  Batch:  2660 / 3125 train_loss: 1.1725682\n",
      "Epoch:  1  Batch:  2680 / 3125 train_loss: 0.94095117\n",
      "Epoch:  1  Batch:  2700 / 3125 train_loss: 1.0491097\n",
      "Epoch:  1  Batch:  2720 / 3125 train_loss: 0.97294855\n",
      "Epoch:  1  Batch:  2740 / 3125 train_loss: 1.0409822\n",
      "Epoch:  1  Batch:  2760 / 3125 train_loss: 0.9687613\n",
      "Epoch:  1  Batch:  2780 / 3125 train_loss: 0.8918309\n",
      "Epoch:  1  Batch:  2800 / 3125 train_loss: 1.17419\n",
      "Epoch:  1  Batch:  2820 / 3125 train_loss: 1.2222779\n",
      "Epoch:  1  Batch:  2840 / 3125 train_loss: 0.9671766\n",
      "Epoch:  1  Batch:  2860 / 3125 train_loss: 0.91495115\n",
      "Epoch:  1  Batch:  2880 / 3125 train_loss: 1.0100331\n",
      "Epoch:  1  Batch:  2900 / 3125 train_loss: 1.0226709\n",
      "Epoch:  1  Batch:  2920 / 3125 train_loss: 0.9748149\n",
      "Epoch:  1  Batch:  2940 / 3125 train_loss: 1.0046833\n",
      "Epoch:  1  Batch:  2960 / 3125 train_loss: 0.9996303\n",
      "Epoch:  1  Batch:  2980 / 3125 train_loss: 0.9590559\n",
      "Epoch:  1  Batch:  3000 / 3125 train_loss: 1.0249515\n",
      "Epoch:  1  Batch:  3020 / 3125 train_loss: 1.1357956\n",
      "Epoch:  1  Batch:  3040 / 3125 train_loss: 1.014456\n",
      "Epoch:  1  Batch:  3060 / 3125 train_loss: 0.93033123\n",
      "Epoch:  1  Batch:  3080 / 3125 train_loss: 1.1249412\n",
      "Epoch:  1  Batch:  3100 / 3125 train_loss: 1.046138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  Batch:  3120 / 3125 train_loss: 0.9112665\n",
      "Epoch:  2  Batch:  0 / 3125 train_loss: 1.0739379\n",
      "Epoch:  2  Batch:  20 / 3125 train_loss: 0.9529214\n",
      "Epoch:  2  Batch:  40 / 3125 train_loss: 1.0261157\n",
      "Epoch:  2  Batch:  60 / 3125 train_loss: 0.8175447\n",
      "Epoch:  2  Batch:  80 / 3125 train_loss: 1.0048189\n",
      "Epoch:  2  Batch:  100 / 3125 train_loss: 1.0711725\n",
      "Epoch:  2  Batch:  120 / 3125 train_loss: 1.0781959\n",
      "Epoch:  2  Batch:  140 / 3125 train_loss: 1.0446535\n",
      "Epoch:  2  Batch:  160 / 3125 train_loss: 0.8692248\n",
      "Epoch:  2  Batch:  180 / 3125 train_loss: 0.9920111\n",
      "Epoch:  2  Batch:  200 / 3125 train_loss: 1.2036651\n",
      "Epoch:  2  Batch:  220 / 3125 train_loss: 1.0328631\n",
      "Epoch:  2  Batch:  240 / 3125 train_loss: 1.0431936\n",
      "Epoch:  2  Batch:  260 / 3125 train_loss: 1.0272353\n",
      "Epoch:  2  Batch:  280 / 3125 train_loss: 1.0535004\n",
      "Epoch:  2  Batch:  300 / 3125 train_loss: 1.105937\n",
      "Epoch:  2  Batch:  320 / 3125 train_loss: 1.1459008\n",
      "Epoch:  2  Batch:  340 / 3125 train_loss: 0.8751153\n",
      "Epoch:  2  Batch:  360 / 3125 train_loss: 0.9097251\n",
      "Epoch:  2  Batch:  380 / 3125 train_loss: 0.9957844\n",
      "Epoch:  2  Batch:  400 / 3125 train_loss: 0.9899034\n",
      "Epoch:  2  Batch:  420 / 3125 train_loss: 0.8421083\n",
      "Epoch:  2  Batch:  440 / 3125 train_loss: 1.0377865\n",
      "Epoch:  2  Batch:  460 / 3125 train_loss: 0.94116485\n",
      "Epoch:  2  Batch:  480 / 3125 train_loss: 1.1126834\n",
      "Epoch:  2  Batch:  500 / 3125 train_loss: 0.7570138\n",
      "Epoch:  2  Batch:  520 / 3125 train_loss: 1.0059569\n",
      "Epoch:  2  Batch:  540 / 3125 train_loss: 0.8853183\n",
      "Epoch:  2  Batch:  560 / 3125 train_loss: 1.0666046\n",
      "Epoch:  2  Batch:  580 / 3125 train_loss: 1.0623298\n",
      "Epoch:  2  Batch:  600 / 3125 train_loss: 0.99511325\n",
      "Epoch:  2  Batch:  620 / 3125 train_loss: 0.9993683\n",
      "Epoch:  2  Batch:  640 / 3125 train_loss: 0.99241626\n",
      "Epoch:  2  Batch:  660 / 3125 train_loss: 0.9490493\n",
      "Epoch:  2  Batch:  680 / 3125 train_loss: 1.0400486\n",
      "Epoch:  2  Batch:  700 / 3125 train_loss: 0.9987004\n",
      "Epoch:  2  Batch:  720 / 3125 train_loss: 0.8699628\n",
      "Epoch:  2  Batch:  740 / 3125 train_loss: 0.9630494\n",
      "Epoch:  2  Batch:  760 / 3125 train_loss: 0.8730756\n",
      "Epoch:  2  Batch:  780 / 3125 train_loss: 1.0014329\n",
      "Epoch:  2  Batch:  800 / 3125 train_loss: 0.85703266\n",
      "Epoch:  2  Batch:  820 / 3125 train_loss: 0.9418138\n",
      "Epoch:  2  Batch:  840 / 3125 train_loss: 0.9173142\n",
      "Epoch:  2  Batch:  860 / 3125 train_loss: 0.9047215\n",
      "Epoch:  2  Batch:  880 / 3125 train_loss: 0.87552536\n",
      "Epoch:  2  Batch:  900 / 3125 train_loss: 0.95107615\n",
      "Epoch:  2  Batch:  920 / 3125 train_loss: 1.0119883\n",
      "Epoch:  2  Batch:  940 / 3125 train_loss: 0.9591698\n",
      "Epoch:  2  Batch:  960 / 3125 train_loss: 1.0374646\n",
      "Epoch:  2  Batch:  980 / 3125 train_loss: 1.1884961\n",
      "Epoch:  2  Batch:  1000 / 3125 train_loss: 1.0593395\n",
      "Epoch:  2  Batch:  1020 / 3125 train_loss: 0.9998381\n",
      "Epoch:  2  Batch:  1040 / 3125 train_loss: 0.880409\n",
      "Epoch:  2  Batch:  1060 / 3125 train_loss: 1.0434978\n",
      "Epoch:  2  Batch:  1080 / 3125 train_loss: 0.9351072\n",
      "Epoch:  2  Batch:  1100 / 3125 train_loss: 0.949247\n",
      "Epoch:  2  Batch:  1120 / 3125 train_loss: 0.9621516\n",
      "Epoch:  2  Batch:  1140 / 3125 train_loss: 1.0013812\n",
      "Epoch:  2  Batch:  1160 / 3125 train_loss: 0.971589\n",
      "Epoch:  2  Batch:  1180 / 3125 train_loss: 0.95737994\n",
      "Epoch:  2  Batch:  1200 / 3125 train_loss: 1.0554748\n",
      "Epoch:  2  Batch:  1220 / 3125 train_loss: 1.0136724\n",
      "Epoch:  2  Batch:  1240 / 3125 train_loss: 0.8061134\n",
      "Epoch:  2  Batch:  1260 / 3125 train_loss: 1.0499926\n",
      "Epoch:  2  Batch:  1280 / 3125 train_loss: 0.99345803\n",
      "Epoch:  2  Batch:  1300 / 3125 train_loss: 0.9549833\n",
      "Epoch:  2  Batch:  1320 / 3125 train_loss: 0.96442056\n",
      "Epoch:  2  Batch:  1340 / 3125 train_loss: 0.7879082\n",
      "Epoch:  2  Batch:  1360 / 3125 train_loss: 0.8727804\n",
      "Epoch:  2  Batch:  1380 / 3125 train_loss: 0.874311\n",
      "Epoch:  2  Batch:  1400 / 3125 train_loss: 0.99225783\n",
      "Epoch:  2  Batch:  1420 / 3125 train_loss: 1.0040903\n",
      "Epoch:  2  Batch:  1440 / 3125 train_loss: 0.886017\n",
      "Epoch:  2  Batch:  1460 / 3125 train_loss: 0.96660316\n",
      "Epoch:  2  Batch:  1480 / 3125 train_loss: 0.9242841\n",
      "Epoch:  2  Batch:  1500 / 3125 train_loss: 0.9945173\n",
      "Epoch:  2  Batch:  1520 / 3125 train_loss: 0.9280342\n",
      "Epoch:  2  Batch:  1540 / 3125 train_loss: 1.0623472\n",
      "Epoch:  2  Batch:  1560 / 3125 train_loss: 0.9015492\n",
      "Epoch:  2  Batch:  1580 / 3125 train_loss: 1.0080452\n",
      "Epoch:  2  Batch:  1600 / 3125 train_loss: 0.9257443\n",
      "Epoch:  2  Batch:  1620 / 3125 train_loss: 0.92232\n",
      "Epoch:  2  Batch:  1640 / 3125 train_loss: 0.9903586\n",
      "Epoch:  2  Batch:  1660 / 3125 train_loss: 1.0701799\n",
      "Epoch:  2  Batch:  1680 / 3125 train_loss: 0.9616548\n",
      "Epoch:  2  Batch:  1700 / 3125 train_loss: 0.85948706\n",
      "Epoch:  2  Batch:  1720 / 3125 train_loss: 0.9300013\n",
      "Epoch:  2  Batch:  1740 / 3125 train_loss: 1.0149491\n",
      "Epoch:  2  Batch:  1760 / 3125 train_loss: 0.98706865\n",
      "Epoch:  2  Batch:  1780 / 3125 train_loss: 0.92612433\n",
      "Epoch:  2  Batch:  1800 / 3125 train_loss: 0.9163575\n",
      "Epoch:  2  Batch:  1820 / 3125 train_loss: 0.94232535\n",
      "Epoch:  2  Batch:  1840 / 3125 train_loss: 1.0073705\n",
      "Epoch:  2  Batch:  1860 / 3125 train_loss: 1.0202259\n",
      "Epoch:  2  Batch:  1880 / 3125 train_loss: 0.9458389\n",
      "Epoch:  2  Batch:  1900 / 3125 train_loss: 0.8727261\n",
      "Epoch:  2  Batch:  1920 / 3125 train_loss: 0.9207462\n",
      "Epoch:  2  Batch:  1940 / 3125 train_loss: 0.8455392\n",
      "Epoch:  2  Batch:  1960 / 3125 train_loss: 0.84648013\n",
      "Epoch:  2  Batch:  1980 / 3125 train_loss: 0.96982086\n",
      "Epoch:  2  Batch:  2000 / 3125 train_loss: 1.1666533\n",
      "Epoch:  2  Batch:  2020 / 3125 train_loss: 1.1155057\n",
      "Epoch:  2  Batch:  2040 / 3125 train_loss: 0.85732275\n",
      "Epoch:  2  Batch:  2060 / 3125 train_loss: 0.8133773\n",
      "Epoch:  2  Batch:  2080 / 3125 train_loss: 1.0510381\n",
      "Epoch:  2  Batch:  2100 / 3125 train_loss: 0.87993634\n",
      "Epoch:  2  Batch:  2120 / 3125 train_loss: 0.89538604\n",
      "Epoch:  2  Batch:  2140 / 3125 train_loss: 0.9740175\n",
      "Epoch:  2  Batch:  2160 / 3125 train_loss: 0.9407654\n",
      "Epoch:  2  Batch:  2180 / 3125 train_loss: 0.9209579\n",
      "Epoch:  2  Batch:  2200 / 3125 train_loss: 0.85449815\n",
      "Epoch:  2  Batch:  2220 / 3125 train_loss: 0.8502041\n",
      "Epoch:  2  Batch:  2240 / 3125 train_loss: 0.8584306\n",
      "Epoch:  2  Batch:  2260 / 3125 train_loss: 0.96936023\n",
      "Epoch:  2  Batch:  2280 / 3125 train_loss: 0.9732621\n",
      "Epoch:  2  Batch:  2300 / 3125 train_loss: 0.9415092\n",
      "Epoch:  2  Batch:  2320 / 3125 train_loss: 1.0034139\n",
      "Epoch:  2  Batch:  2340 / 3125 train_loss: 0.9531435\n",
      "Epoch:  2  Batch:  2360 / 3125 train_loss: 0.9320697\n",
      "Epoch:  2  Batch:  2380 / 3125 train_loss: 0.8882847\n",
      "Epoch:  2  Batch:  2400 / 3125 train_loss: 1.0039245\n",
      "Epoch:  2  Batch:  2420 / 3125 train_loss: 0.85400474\n",
      "Epoch:  2  Batch:  2440 / 3125 train_loss: 0.8905047\n",
      "Epoch:  2  Batch:  2460 / 3125 train_loss: 0.8955407\n",
      "Epoch:  2  Batch:  2480 / 3125 train_loss: 1.0762565\n",
      "Epoch:  2  Batch:  2500 / 3125 train_loss: 0.9263518\n",
      "Epoch:  2  Batch:  2520 / 3125 train_loss: 0.98732406\n",
      "Epoch:  2  Batch:  2540 / 3125 train_loss: 0.8839075\n",
      "Epoch:  2  Batch:  2560 / 3125 train_loss: 0.76282156\n",
      "Epoch:  2  Batch:  2580 / 3125 train_loss: 0.84697616\n",
      "Epoch:  2  Batch:  2600 / 3125 train_loss: 0.90030265\n",
      "Epoch:  2  Batch:  2620 / 3125 train_loss: 0.8724433\n",
      "Epoch:  2  Batch:  2640 / 3125 train_loss: 0.93632996\n",
      "Epoch:  2  Batch:  2660 / 3125 train_loss: 1.0957154\n",
      "Epoch:  2  Batch:  2680 / 3125 train_loss: 0.8675903\n",
      "Epoch:  2  Batch:  2700 / 3125 train_loss: 0.99312556\n",
      "Epoch:  2  Batch:  2720 / 3125 train_loss: 0.8680559\n",
      "Epoch:  2  Batch:  2740 / 3125 train_loss: 0.9315823\n",
      "Epoch:  2  Batch:  2760 / 3125 train_loss: 0.8635889\n",
      "Epoch:  2  Batch:  2780 / 3125 train_loss: 0.82408285\n",
      "Epoch:  2  Batch:  2800 / 3125 train_loss: 1.0682971\n",
      "Epoch:  2  Batch:  2820 / 3125 train_loss: 1.1370337\n",
      "Epoch:  2  Batch:  2840 / 3125 train_loss: 0.88277006\n",
      "Epoch:  2  Batch:  2860 / 3125 train_loss: 0.8175361\n",
      "Epoch:  2  Batch:  2880 / 3125 train_loss: 0.91080594\n",
      "Epoch:  2  Batch:  2900 / 3125 train_loss: 0.92513037\n",
      "Epoch:  2  Batch:  2920 / 3125 train_loss: 0.8860593\n",
      "Epoch:  2  Batch:  2940 / 3125 train_loss: 0.95500433\n",
      "Epoch:  2  Batch:  2960 / 3125 train_loss: 0.92440104\n",
      "Epoch:  2  Batch:  2980 / 3125 train_loss: 0.8789722\n",
      "Epoch:  2  Batch:  3000 / 3125 train_loss: 0.97251797\n",
      "Epoch:  2  Batch:  3020 / 3125 train_loss: 1.08188\n",
      "Epoch:  2  Batch:  3040 / 3125 train_loss: 0.954417\n",
      "Epoch:  2  Batch:  3060 / 3125 train_loss: 0.8457275\n",
      "Epoch:  2  Batch:  3080 / 3125 train_loss: 1.0593615\n",
      "Epoch:  2  Batch:  3100 / 3125 train_loss: 1.000524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2  Batch:  3120 / 3125 train_loss: 0.87244916\n",
      "Epoch:  3  Batch:  0 / 3125 train_loss: 1.0214763\n",
      "Epoch:  3  Batch:  20 / 3125 train_loss: 0.8875773\n",
      "Epoch:  3  Batch:  40 / 3125 train_loss: 0.95585096\n",
      "Epoch:  3  Batch:  60 / 3125 train_loss: 0.76859164\n",
      "Epoch:  3  Batch:  80 / 3125 train_loss: 0.92287314\n",
      "Epoch:  3  Batch:  100 / 3125 train_loss: 0.9975845\n",
      "Epoch:  3  Batch:  120 / 3125 train_loss: 1.0003259\n",
      "Epoch:  3  Batch:  140 / 3125 train_loss: 0.9762056\n",
      "Epoch:  3  Batch:  160 / 3125 train_loss: 0.80363744\n",
      "Epoch:  3  Batch:  180 / 3125 train_loss: 0.9116775\n",
      "Epoch:  3  Batch:  200 / 3125 train_loss: 1.1026936\n",
      "Epoch:  3  Batch:  220 / 3125 train_loss: 0.9528003\n",
      "Epoch:  3  Batch:  240 / 3125 train_loss: 0.99488014\n",
      "Epoch:  3  Batch:  260 / 3125 train_loss: 0.9592123\n",
      "Epoch:  3  Batch:  280 / 3125 train_loss: 0.9843594\n",
      "Epoch:  3  Batch:  300 / 3125 train_loss: 1.0736194\n",
      "Epoch:  3  Batch:  320 / 3125 train_loss: 1.054177\n",
      "Epoch:  3  Batch:  340 / 3125 train_loss: 0.79653955\n",
      "Epoch:  3  Batch:  360 / 3125 train_loss: 0.85548353\n",
      "Epoch:  3  Batch:  380 / 3125 train_loss: 0.9117524\n",
      "Epoch:  3  Batch:  400 / 3125 train_loss: 0.9321114\n",
      "Epoch:  3  Batch:  420 / 3125 train_loss: 0.79085505\n",
      "Epoch:  3  Batch:  440 / 3125 train_loss: 0.95042074\n",
      "Epoch:  3  Batch:  460 / 3125 train_loss: 0.8740412\n",
      "Epoch:  3  Batch:  480 / 3125 train_loss: 1.0410628\n",
      "Epoch:  3  Batch:  500 / 3125 train_loss: 0.7099654\n",
      "Epoch:  3  Batch:  520 / 3125 train_loss: 0.94443905\n",
      "Epoch:  3  Batch:  540 / 3125 train_loss: 0.81518716\n",
      "Epoch:  3  Batch:  560 / 3125 train_loss: 1.0038381\n",
      "Epoch:  3  Batch:  580 / 3125 train_loss: 1.0122318\n",
      "Epoch:  3  Batch:  600 / 3125 train_loss: 0.89320827\n",
      "Epoch:  3  Batch:  620 / 3125 train_loss: 0.93354917\n",
      "Epoch:  3  Batch:  640 / 3125 train_loss: 0.9093249\n",
      "Epoch:  3  Batch:  660 / 3125 train_loss: 0.8985354\n",
      "Epoch:  3  Batch:  680 / 3125 train_loss: 0.9745442\n",
      "Epoch:  3  Batch:  700 / 3125 train_loss: 0.9514642\n",
      "Epoch:  3  Batch:  720 / 3125 train_loss: 0.82033706\n",
      "Epoch:  3  Batch:  740 / 3125 train_loss: 0.90748286\n",
      "Epoch:  3  Batch:  760 / 3125 train_loss: 0.7986046\n",
      "Epoch:  3  Batch:  780 / 3125 train_loss: 0.9289051\n",
      "Epoch:  3  Batch:  800 / 3125 train_loss: 0.7978622\n",
      "Epoch:  3  Batch:  820 / 3125 train_loss: 0.8892175\n",
      "Epoch:  3  Batch:  840 / 3125 train_loss: 0.8629037\n",
      "Epoch:  3  Batch:  860 / 3125 train_loss: 0.86915904\n",
      "Epoch:  3  Batch:  880 / 3125 train_loss: 0.82829154\n",
      "Epoch:  3  Batch:  900 / 3125 train_loss: 0.8963149\n",
      "Epoch:  3  Batch:  920 / 3125 train_loss: 0.9527275\n",
      "Epoch:  3  Batch:  940 / 3125 train_loss: 0.8926123\n",
      "Epoch:  3  Batch:  960 / 3125 train_loss: 0.96756315\n",
      "Epoch:  3  Batch:  980 / 3125 train_loss: 1.1119143\n",
      "Epoch:  3  Batch:  1000 / 3125 train_loss: 1.004774\n",
      "Epoch:  3  Batch:  1020 / 3125 train_loss: 0.95698345\n",
      "Epoch:  3  Batch:  1040 / 3125 train_loss: 0.8187002\n",
      "Epoch:  3  Batch:  1060 / 3125 train_loss: 0.96669924\n",
      "Epoch:  3  Batch:  1080 / 3125 train_loss: 0.8955898\n",
      "Epoch:  3  Batch:  1100 / 3125 train_loss: 0.8908462\n",
      "Epoch:  3  Batch:  1120 / 3125 train_loss: 0.91313446\n",
      "Epoch:  3  Batch:  1140 / 3125 train_loss: 0.92944205\n",
      "Epoch:  3  Batch:  1160 / 3125 train_loss: 0.8959897\n",
      "Epoch:  3  Batch:  1180 / 3125 train_loss: 0.8840015\n",
      "Epoch:  3  Batch:  1200 / 3125 train_loss: 1.0186462\n",
      "Epoch:  3  Batch:  1220 / 3125 train_loss: 0.9878181\n",
      "Epoch:  3  Batch:  1240 / 3125 train_loss: 0.7724267\n",
      "Epoch:  3  Batch:  1260 / 3125 train_loss: 0.9767375\n",
      "Epoch:  3  Batch:  1280 / 3125 train_loss: 0.9497385\n",
      "Epoch:  3  Batch:  1300 / 3125 train_loss: 0.891152\n",
      "Epoch:  3  Batch:  1320 / 3125 train_loss: 0.9074461\n",
      "Epoch:  3  Batch:  1340 / 3125 train_loss: 0.74924624\n",
      "Epoch:  3  Batch:  1360 / 3125 train_loss: 0.8219304\n",
      "Epoch:  3  Batch:  1380 / 3125 train_loss: 0.83353996\n",
      "Epoch:  3  Batch:  1400 / 3125 train_loss: 0.9347304\n",
      "Epoch:  3  Batch:  1420 / 3125 train_loss: 0.94893396\n",
      "Epoch:  3  Batch:  1440 / 3125 train_loss: 0.8293449\n",
      "Epoch:  3  Batch:  1460 / 3125 train_loss: 0.9000896\n",
      "Epoch:  3  Batch:  1480 / 3125 train_loss: 0.8583939\n",
      "Epoch:  3  Batch:  1500 / 3125 train_loss: 0.92047065\n",
      "Epoch:  3  Batch:  1520 / 3125 train_loss: 0.85284376\n",
      "Epoch:  3  Batch:  1540 / 3125 train_loss: 1.0118289\n",
      "Epoch:  3  Batch:  1560 / 3125 train_loss: 0.8454479\n",
      "Epoch:  3  Batch:  1580 / 3125 train_loss: 0.9808497\n",
      "Epoch:  3  Batch:  1600 / 3125 train_loss: 0.8573543\n",
      "Epoch:  3  Batch:  1620 / 3125 train_loss: 0.88399994\n",
      "Epoch:  3  Batch:  1640 / 3125 train_loss: 0.9394608\n",
      "Epoch:  3  Batch:  1660 / 3125 train_loss: 1.0260438\n",
      "Epoch:  3  Batch:  1680 / 3125 train_loss: 0.9174037\n",
      "Epoch:  3  Batch:  1700 / 3125 train_loss: 0.8285624\n",
      "Epoch:  3  Batch:  1720 / 3125 train_loss: 0.89004153\n",
      "Epoch:  3  Batch:  1740 / 3125 train_loss: 0.97763777\n",
      "Epoch:  3  Batch:  1760 / 3125 train_loss: 0.9331516\n",
      "Epoch:  3  Batch:  1780 / 3125 train_loss: 0.89995915\n",
      "Epoch:  3  Batch:  1800 / 3125 train_loss: 0.8662387\n",
      "Epoch:  3  Batch:  1820 / 3125 train_loss: 0.88146174\n",
      "Epoch:  3  Batch:  1840 / 3125 train_loss: 0.9613141\n",
      "Epoch:  3  Batch:  1860 / 3125 train_loss: 0.9720212\n",
      "Epoch:  3  Batch:  1880 / 3125 train_loss: 0.8899052\n",
      "Epoch:  3  Batch:  1900 / 3125 train_loss: 0.83206403\n",
      "Epoch:  3  Batch:  1920 / 3125 train_loss: 0.8690848\n",
      "Epoch:  3  Batch:  1940 / 3125 train_loss: 0.8071617\n",
      "Epoch:  3  Batch:  1960 / 3125 train_loss: 0.78646374\n",
      "Epoch:  3  Batch:  1980 / 3125 train_loss: 0.9380438\n",
      "Epoch:  3  Batch:  2000 / 3125 train_loss: 1.0953948\n",
      "Epoch:  3  Batch:  2020 / 3125 train_loss: 1.0428923\n",
      "Epoch:  3  Batch:  2040 / 3125 train_loss: 0.8239658\n",
      "Epoch:  3  Batch:  2060 / 3125 train_loss: 0.7917738\n",
      "Epoch:  3  Batch:  2080 / 3125 train_loss: 1.0281997\n",
      "Epoch:  3  Batch:  2100 / 3125 train_loss: 0.85739344\n",
      "Epoch:  3  Batch:  2120 / 3125 train_loss: 0.85271\n",
      "Epoch:  3  Batch:  2140 / 3125 train_loss: 0.9089936\n",
      "Epoch:  3  Batch:  2160 / 3125 train_loss: 0.8969401\n",
      "Epoch:  3  Batch:  2180 / 3125 train_loss: 0.8981308\n",
      "Epoch:  3  Batch:  2200 / 3125 train_loss: 0.8183668\n",
      "Epoch:  3  Batch:  2220 / 3125 train_loss: 0.81571317\n",
      "Epoch:  3  Batch:  2240 / 3125 train_loss: 0.84465444\n",
      "Epoch:  3  Batch:  2260 / 3125 train_loss: 0.9331649\n",
      "Epoch:  3  Batch:  2280 / 3125 train_loss: 0.9267942\n",
      "Epoch:  3  Batch:  2300 / 3125 train_loss: 0.9063966\n",
      "Epoch:  3  Batch:  2320 / 3125 train_loss: 0.96148455\n",
      "Epoch:  3  Batch:  2340 / 3125 train_loss: 0.9021569\n",
      "Epoch:  3  Batch:  2360 / 3125 train_loss: 0.89090097\n",
      "Epoch:  3  Batch:  2380 / 3125 train_loss: 0.8509798\n",
      "Epoch:  3  Batch:  2400 / 3125 train_loss: 0.9619199\n",
      "Epoch:  3  Batch:  2420 / 3125 train_loss: 0.8025634\n",
      "Epoch:  3  Batch:  2440 / 3125 train_loss: 0.8274212\n",
      "Epoch:  3  Batch:  2460 / 3125 train_loss: 0.8606055\n",
      "Epoch:  3  Batch:  2480 / 3125 train_loss: 1.0329862\n",
      "Epoch:  3  Batch:  2500 / 3125 train_loss: 0.86459625\n",
      "Epoch:  3  Batch:  2520 / 3125 train_loss: 0.9668902\n",
      "Epoch:  3  Batch:  2540 / 3125 train_loss: 0.84271276\n",
      "Epoch:  3  Batch:  2560 / 3125 train_loss: 0.70860434\n",
      "Epoch:  3  Batch:  2580 / 3125 train_loss: 0.8291649\n",
      "Epoch:  3  Batch:  2600 / 3125 train_loss: 0.85891795\n",
      "Epoch:  3  Batch:  2620 / 3125 train_loss: 0.83291054\n",
      "Epoch:  3  Batch:  2640 / 3125 train_loss: 0.89157724\n",
      "Epoch:  3  Batch:  2660 / 3125 train_loss: 1.0458632\n",
      "Epoch:  3  Batch:  2680 / 3125 train_loss: 0.829638\n",
      "Epoch:  3  Batch:  2700 / 3125 train_loss: 0.9472896\n",
      "Epoch:  3  Batch:  2720 / 3125 train_loss: 0.8099462\n",
      "Epoch:  3  Batch:  2740 / 3125 train_loss: 0.8785807\n",
      "Epoch:  3  Batch:  2760 / 3125 train_loss: 0.8087411\n",
      "Epoch:  3  Batch:  2780 / 3125 train_loss: 0.7938086\n",
      "Epoch:  3  Batch:  2800 / 3125 train_loss: 1.0214508\n",
      "Epoch:  3  Batch:  2820 / 3125 train_loss: 1.0840578\n",
      "Epoch:  3  Batch:  2840 / 3125 train_loss: 0.84182525\n",
      "Epoch:  3  Batch:  2860 / 3125 train_loss: 0.781919\n",
      "Epoch:  3  Batch:  2880 / 3125 train_loss: 0.8598467\n",
      "Epoch:  3  Batch:  2900 / 3125 train_loss: 0.8862921\n",
      "Epoch:  3  Batch:  2920 / 3125 train_loss: 0.85028696\n",
      "Epoch:  3  Batch:  2940 / 3125 train_loss: 0.9303752\n",
      "Epoch:  3  Batch:  2960 / 3125 train_loss: 0.8813257\n",
      "Epoch:  3  Batch:  2980 / 3125 train_loss: 0.83936644\n",
      "Epoch:  3  Batch:  3000 / 3125 train_loss: 0.9443371\n",
      "Epoch:  3  Batch:  3020 / 3125 train_loss: 1.0435145\n",
      "Epoch:  3  Batch:  3040 / 3125 train_loss: 0.92069715\n",
      "Epoch:  3  Batch:  3060 / 3125 train_loss: 0.80371165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3  Batch:  3080 / 3125 train_loss: 1.0277853\n",
      "Epoch:  3  Batch:  3100 / 3125 train_loss: 0.98015773\n",
      "Epoch:  3  Batch:  3120 / 3125 train_loss: 0.8415786\n",
      "Epoch:  4  Batch:  0 / 3125 train_loss: 0.9901511\n",
      "Epoch:  4  Batch:  20 / 3125 train_loss: 0.8613374\n",
      "Epoch:  4  Batch:  40 / 3125 train_loss: 0.91468436\n",
      "Epoch:  4  Batch:  60 / 3125 train_loss: 0.7471137\n",
      "Epoch:  4  Batch:  80 / 3125 train_loss: 0.8645395\n",
      "Epoch:  4  Batch:  100 / 3125 train_loss: 0.9565268\n",
      "Epoch:  4  Batch:  120 / 3125 train_loss: 0.95485854\n",
      "Epoch:  4  Batch:  140 / 3125 train_loss: 0.9370911\n",
      "Epoch:  4  Batch:  160 / 3125 train_loss: 0.77109754\n",
      "Epoch:  4  Batch:  180 / 3125 train_loss: 0.8732782\n",
      "Epoch:  4  Batch:  200 / 3125 train_loss: 1.040536\n",
      "Epoch:  4  Batch:  220 / 3125 train_loss: 0.90599304\n",
      "Epoch:  4  Batch:  240 / 3125 train_loss: 0.9672131\n",
      "Epoch:  4  Batch:  260 / 3125 train_loss: 0.9313061\n",
      "Epoch:  4  Batch:  280 / 3125 train_loss: 0.9537469\n",
      "Epoch:  4  Batch:  300 / 3125 train_loss: 1.0519927\n",
      "Epoch:  4  Batch:  320 / 3125 train_loss: 1.0041585\n",
      "Epoch:  4  Batch:  340 / 3125 train_loss: 0.7503606\n",
      "Epoch:  4  Batch:  360 / 3125 train_loss: 0.8292094\n",
      "Epoch:  4  Batch:  380 / 3125 train_loss: 0.86391586\n",
      "Epoch:  4  Batch:  400 / 3125 train_loss: 0.8961221\n",
      "Epoch:  4  Batch:  420 / 3125 train_loss: 0.76264924\n",
      "Epoch:  4  Batch:  440 / 3125 train_loss: 0.89493287\n",
      "Epoch:  4  Batch:  460 / 3125 train_loss: 0.83957773\n",
      "Epoch:  4  Batch:  480 / 3125 train_loss: 0.997633\n",
      "Epoch:  4  Batch:  500 / 3125 train_loss: 0.6839697\n",
      "Epoch:  4  Batch:  520 / 3125 train_loss: 0.92034996\n",
      "Epoch:  4  Batch:  540 / 3125 train_loss: 0.7772223\n",
      "Epoch:  4  Batch:  560 / 3125 train_loss: 0.9775874\n",
      "Epoch:  4  Batch:  580 / 3125 train_loss: 0.9882512\n",
      "Epoch:  4  Batch:  600 / 3125 train_loss: 0.84040886\n",
      "Epoch:  4  Batch:  620 / 3125 train_loss: 0.9018814\n",
      "Epoch:  4  Batch:  640 / 3125 train_loss: 0.8694273\n",
      "Epoch:  4  Batch:  660 / 3125 train_loss: 0.8715196\n",
      "Epoch:  4  Batch:  680 / 3125 train_loss: 0.938157\n",
      "Epoch:  4  Batch:  700 / 3125 train_loss: 0.924319\n",
      "Epoch:  4  Batch:  720 / 3125 train_loss: 0.7909453\n",
      "Epoch:  4  Batch:  740 / 3125 train_loss: 0.8822776\n",
      "Epoch:  4  Batch:  760 / 3125 train_loss: 0.764308\n",
      "Epoch:  4  Batch:  780 / 3125 train_loss: 0.8911854\n",
      "Epoch:  4  Batch:  800 / 3125 train_loss: 0.77264774\n",
      "Epoch:  4  Batch:  820 / 3125 train_loss: 0.85347694\n",
      "Epoch:  4  Batch:  840 / 3125 train_loss: 0.8307553\n",
      "Epoch:  4  Batch:  860 / 3125 train_loss: 0.84639806\n",
      "Epoch:  4  Batch:  880 / 3125 train_loss: 0.8041877\n",
      "Epoch:  4  Batch:  900 / 3125 train_loss: 0.8705393\n",
      "Epoch:  4  Batch:  920 / 3125 train_loss: 0.92992663\n",
      "Epoch:  4  Batch:  940 / 3125 train_loss: 0.8580858\n",
      "Epoch:  4  Batch:  960 / 3125 train_loss: 0.9223769\n",
      "Epoch:  4  Batch:  980 / 3125 train_loss: 1.0552856\n",
      "Epoch:  4  Batch:  1000 / 3125 train_loss: 0.9749383\n",
      "Epoch:  4  Batch:  1020 / 3125 train_loss: 0.9291612\n",
      "Epoch:  4  Batch:  1040 / 3125 train_loss: 0.7951525\n",
      "Epoch:  4  Batch:  1060 / 3125 train_loss: 0.9288291\n",
      "Epoch:  4  Batch:  1080 / 3125 train_loss: 0.8821002\n",
      "Epoch:  4  Batch:  1100 / 3125 train_loss: 0.85969806\n",
      "Epoch:  4  Batch:  1120 / 3125 train_loss: 0.87590104\n",
      "Epoch:  4  Batch:  1140 / 3125 train_loss: 0.88734585\n",
      "Epoch:  4  Batch:  1160 / 3125 train_loss: 0.8437922\n",
      "Epoch:  4  Batch:  1180 / 3125 train_loss: 0.84746015\n",
      "Epoch:  4  Batch:  1200 / 3125 train_loss: 0.992024\n",
      "Epoch:  4  Batch:  1220 / 3125 train_loss: 0.97324216\n",
      "Epoch:  4  Batch:  1240 / 3125 train_loss: 0.7554952\n",
      "Epoch:  4  Batch:  1260 / 3125 train_loss: 0.9330259\n",
      "Epoch:  4  Batch:  1280 / 3125 train_loss: 0.9190825\n",
      "Epoch:  4  Batch:  1300 / 3125 train_loss: 0.8536606\n",
      "Epoch:  4  Batch:  1320 / 3125 train_loss: 0.87797624\n",
      "Epoch:  4  Batch:  1340 / 3125 train_loss: 0.73445547\n",
      "Epoch:  4  Batch:  1360 / 3125 train_loss: 0.79104805\n",
      "Epoch:  4  Batch:  1380 / 3125 train_loss: 0.8138554\n",
      "Epoch:  4  Batch:  1400 / 3125 train_loss: 0.90600014\n",
      "Epoch:  4  Batch:  1420 / 3125 train_loss: 0.91201854\n",
      "Epoch:  4  Batch:  1440 / 3125 train_loss: 0.79733413\n",
      "Epoch:  4  Batch:  1460 / 3125 train_loss: 0.861484\n",
      "Epoch:  4  Batch:  1480 / 3125 train_loss: 0.8259814\n",
      "Epoch:  4  Batch:  1500 / 3125 train_loss: 0.8810106\n",
      "Epoch:  4  Batch:  1520 / 3125 train_loss: 0.813576\n",
      "Epoch:  4  Batch:  1540 / 3125 train_loss: 0.9771569\n",
      "Epoch:  4  Batch:  1560 / 3125 train_loss: 0.80651337\n",
      "Epoch:  4  Batch:  1580 / 3125 train_loss: 0.9627822\n",
      "Epoch:  4  Batch:  1600 / 3125 train_loss: 0.81380475\n",
      "Epoch:  4  Batch:  1620 / 3125 train_loss: 0.8583871\n",
      "Epoch:  4  Batch:  1640 / 3125 train_loss: 0.91286457\n",
      "Epoch:  4  Batch:  1660 / 3125 train_loss: 0.99443144\n",
      "Epoch:  4  Batch:  1680 / 3125 train_loss: 0.8959966\n",
      "Epoch:  4  Batch:  1700 / 3125 train_loss: 0.80822515\n",
      "Epoch:  4  Batch:  1720 / 3125 train_loss: 0.86320305\n",
      "Epoch:  4  Batch:  1740 / 3125 train_loss: 0.9564489\n",
      "Epoch:  4  Batch:  1760 / 3125 train_loss: 0.8952954\n",
      "Epoch:  4  Batch:  1780 / 3125 train_loss: 0.88789964\n",
      "Epoch:  4  Batch:  1800 / 3125 train_loss: 0.8364831\n",
      "Epoch:  4  Batch:  1820 / 3125 train_loss: 0.8449228\n",
      "Epoch:  4  Batch:  1840 / 3125 train_loss: 0.9370769\n",
      "Epoch:  4  Batch:  1860 / 3125 train_loss: 0.9477372\n",
      "Epoch:  4  Batch:  1880 / 3125 train_loss: 0.8568708\n",
      "Epoch:  4  Batch:  1900 / 3125 train_loss: 0.80223316\n",
      "Epoch:  4  Batch:  1920 / 3125 train_loss: 0.83802414\n",
      "Epoch:  4  Batch:  1940 / 3125 train_loss: 0.7916497\n",
      "Epoch:  4  Batch:  1960 / 3125 train_loss: 0.75040257\n",
      "Epoch:  4  Batch:  1980 / 3125 train_loss: 0.9145635\n",
      "Epoch:  4  Batch:  2000 / 3125 train_loss: 1.0511378\n",
      "Epoch:  4  Batch:  2020 / 3125 train_loss: 0.99364495\n",
      "Epoch:  4  Batch:  2040 / 3125 train_loss: 0.806577\n",
      "Epoch:  4  Batch:  2060 / 3125 train_loss: 0.7767637\n",
      "Epoch:  4  Batch:  2080 / 3125 train_loss: 1.0139734\n",
      "Epoch:  4  Batch:  2100 / 3125 train_loss: 0.8396814\n",
      "Epoch:  4  Batch:  2120 / 3125 train_loss: 0.8270245\n",
      "Epoch:  4  Batch:  2140 / 3125 train_loss: 0.87154293\n",
      "Epoch:  4  Batch:  2160 / 3125 train_loss: 0.8670751\n",
      "Epoch:  4  Batch:  2180 / 3125 train_loss: 0.8841639\n",
      "Epoch:  4  Batch:  2200 / 3125 train_loss: 0.80077326\n",
      "Epoch:  4  Batch:  2220 / 3125 train_loss: 0.7988088\n",
      "Epoch:  4  Batch:  2240 / 3125 train_loss: 0.8351329\n",
      "Epoch:  4  Batch:  2260 / 3125 train_loss: 0.9112483\n",
      "Epoch:  4  Batch:  2280 / 3125 train_loss: 0.8942219\n",
      "Epoch:  4  Batch:  2300 / 3125 train_loss: 0.8875264\n",
      "Epoch:  4  Batch:  2320 / 3125 train_loss: 0.9421878\n",
      "Epoch:  4  Batch:  2340 / 3125 train_loss: 0.8726916\n",
      "Epoch:  4  Batch:  2360 / 3125 train_loss: 0.8688313\n",
      "Epoch:  4  Batch:  2380 / 3125 train_loss: 0.83115375\n",
      "Epoch:  4  Batch:  2400 / 3125 train_loss: 0.9330423\n",
      "Epoch:  4  Batch:  2420 / 3125 train_loss: 0.7754251\n",
      "Epoch:  4  Batch:  2440 / 3125 train_loss: 0.794829\n",
      "Epoch:  4  Batch:  2460 / 3125 train_loss: 0.84431905\n",
      "Epoch:  4  Batch:  2480 / 3125 train_loss: 1.0013964\n",
      "Epoch:  4  Batch:  2500 / 3125 train_loss: 0.83083564\n",
      "Epoch:  4  Batch:  2520 / 3125 train_loss: 0.95156014\n",
      "Epoch:  4  Batch:  2540 / 3125 train_loss: 0.82148385\n",
      "Epoch:  4  Batch:  2560 / 3125 train_loss: 0.6770797\n",
      "Epoch:  4  Batch:  2580 / 3125 train_loss: 0.81944585\n",
      "Epoch:  4  Batch:  2600 / 3125 train_loss: 0.82920396\n",
      "Epoch:  4  Batch:  2620 / 3125 train_loss: 0.8096097\n",
      "Epoch:  4  Batch:  2640 / 3125 train_loss: 0.8614814\n",
      "Epoch:  4  Batch:  2660 / 3125 train_loss: 1.0100534\n",
      "Epoch:  4  Batch:  2680 / 3125 train_loss: 0.8073685\n",
      "Epoch:  4  Batch:  2700 / 3125 train_loss: 0.91574347\n",
      "Epoch:  4  Batch:  2720 / 3125 train_loss: 0.77297693\n",
      "Epoch:  4  Batch:  2740 / 3125 train_loss: 0.85147095\n",
      "Epoch:  4  Batch:  2760 / 3125 train_loss: 0.7774737\n",
      "Epoch:  4  Batch:  2780 / 3125 train_loss: 0.7800277\n",
      "Epoch:  4  Batch:  2800 / 3125 train_loss: 1.0008726\n",
      "Epoch:  4  Batch:  2820 / 3125 train_loss: 1.0529921\n",
      "Epoch:  4  Batch:  2840 / 3125 train_loss: 0.82241\n",
      "Epoch:  4  Batch:  2860 / 3125 train_loss: 0.7691376\n",
      "Epoch:  4  Batch:  2880 / 3125 train_loss: 0.8330851\n",
      "Epoch:  4  Batch:  2900 / 3125 train_loss: 0.86744887\n",
      "Epoch:  4  Batch:  2920 / 3125 train_loss: 0.83287054\n",
      "Epoch:  4  Batch:  2940 / 3125 train_loss: 0.9131775\n",
      "Epoch:  4  Batch:  2960 / 3125 train_loss: 0.85324925\n",
      "Epoch:  4  Batch:  2980 / 3125 train_loss: 0.8168304\n",
      "Epoch:  4  Batch:  3000 / 3125 train_loss: 0.92627484\n",
      "Epoch:  4  Batch:  3020 / 3125 train_loss: 1.0160822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4  Batch:  3040 / 3125 train_loss: 0.8987607\n",
      "Epoch:  4  Batch:  3060 / 3125 train_loss: 0.7778839\n",
      "Epoch:  4  Batch:  3080 / 3125 train_loss: 1.0058441\n",
      "Epoch:  4  Batch:  3100 / 3125 train_loss: 0.9718087\n",
      "Epoch:  4  Batch:  3120 / 3125 train_loss: 0.8234869\n"
     ]
    }
   ],
   "source": [
    "model_file = \"models/final_movies_recommendations_model\"\n",
    "\n",
    "losses = {'train':[], 'test':[]}\n",
    "\n",
    "\n",
    "# Number of Epochs\n",
    "num_epochs = 5\n",
    "# Batch Size\n",
    "batch_size = 256\n",
    "dropout_keep_prob = 0.5\n",
    "\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 20\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch_index in range(num_epochs):\n",
    "        train_X,test_X, train_y, test_y = train_test_split(X_all, y_all, test_size = 0.2, random_state = 0)  \n",
    "        \n",
    "        for batch_index in range(len(train_X) // batch_size):\n",
    "            \n",
    "            start_index = batch_index * batch_size\n",
    "            end_index = min((batch_index+1)*batch_size , len(train_X))\n",
    "            x = train_X[start_index:end_index]\n",
    "            y = train_y[start_index:end_index]\n",
    "\n",
    "            genres = np.zeros([batch_size, 18])\n",
    "            for i in range(batch_size):\n",
    "                genres[i] = x.take(6,1)[i]\n",
    "\n",
    "            titles = np.zeros([batch_size, movie_title_len])\n",
    "            for i in range(batch_size):\n",
    "                titles[i] = x.take(5,1)[i]\n",
    "\n",
    "            feed = {\n",
    "                model.user_id: np.reshape(x.take(0,1), [batch_size, 1]),\n",
    "                model.user_gender: np.reshape(x.take(2,1), [batch_size, 1]),\n",
    "                model.user_age: np.reshape(x.take(3,1), [batch_size, 1]),\n",
    "                model.user_job: np.reshape(x.take(4,1), [batch_size, 1]),\n",
    "                model.movie_id: np.reshape(x.take(1,1), [batch_size, 1]),\n",
    "                model.movie_genres: genres,  \n",
    "                model.movie_titles: titles,  \n",
    "                model.ratings: np.reshape(y, [batch_size, 1]),\n",
    "                model.dropout_keep_prob: dropout_keep_prob\n",
    "                }\n",
    "\n",
    "            step, train_loss, _ = sess.run([model.global_step, model.loss, model.train_op], feed)  #cost\n",
    "            losses['train'].append(train_loss)\n",
    "\n",
    "            if(batch_index % show_every_n_batches == 0):\n",
    "                print('Epoch: ',epoch_index,' Batch: ',batch_index,\"/\",len(train_X)//batch_size,'train_loss:',train_loss)\n",
    "    \n",
    "    model.saver.save(sess, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses['train'], label='Training loss')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Usage of pre-trained Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_map = {val[0]:i for i, val in enumerate(movies.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_movie(user_id_val, movie_id_val):\n",
    "    \n",
    "    with tf.Session() as sess:  \n",
    "        model.saver.restore(sess, model_file)\n",
    "        \n",
    "        genres = np.zeros([1, 18])\n",
    "        genres[0] = movies.values[movie_id_map[movie_id_val]][2]\n",
    "    \n",
    "        titles = np.zeros([1, movie_title_len])\n",
    "        titles[0] = movies.values[movie_id_map[movie_id_val]][1]\n",
    "    \n",
    "        feed = {\n",
    "              model.user_id: np.reshape(users.values[user_id_val-1][0], [1, 1]),\n",
    "              model.user_gender: np.reshape(users.values[user_id_val-1][1], [1, 1]),\n",
    "              model.user_age: np.reshape(users.values[user_id_val-1][2], [1, 1]),\n",
    "              model.user_job: np.reshape(users.values[user_id_val-1][3], [1, 1]),\n",
    "              model.movie_id: np.reshape(movies.values[movie_id_map[movie_id_val]][0], [1, 1]),\n",
    "              model.movie_genres: genres,  \n",
    "              model.movie_titles: titles,  \n",
    "              model.dropout_keep_prob: 1\n",
    "        }\n",
    "    \n",
    "        # Get Prediction\n",
    "        pred_rating= sess.run([model.pred_ratings], feed)  \n",
    "    \n",
    "        return (pred_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/final_movies_recommendations_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[4.1669364]], dtype=float32)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_movie(2, 1193)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
