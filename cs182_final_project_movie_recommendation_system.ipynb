{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommandation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6040, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupationID</th>\n",
       "      <th>zip-code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID gender  age  occupationID zip-code\n",
       "0       1      F    1            10    48067\n",
       "1       2      M   56            16    70072\n",
       "2       3      M   25            15    55117\n",
       "3       4      M   45             7    02460\n",
       "4       5      M   25            20    55455"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_title = ['userID', 'gender', 'age', 'occupationID', 'zip-code']\n",
    "users_old = pd.read_csv('./ml-1m/users.dat', sep='::', header=None, names=users_title, engine = 'python')\n",
    "print(users_old.shape)\n",
    "users_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3883, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieID                               title                        genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_title = ['movieID', 'title', 'genres']\n",
    "movies_old = pd.read_csv('./ml-1m/movies.dat', sep='::', header=None, names=movies_title, engine = 'python')\n",
    "print(movies_old.shape)\n",
    "movies_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000209, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating  timestamps\n",
       "0       1     1193       5   978300760\n",
       "1       1      661       3   978302109\n",
       "2       1      914       3   978301968\n",
       "3       1     3408       4   978300275\n",
       "4       1     2355       5   978824291"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_title = ['userID','movieID', 'rating', 'timestamps']\n",
    "ratings_old = pd.read_csv('./ml-1m/ratings.dat', sep='::', header=None, names=ratings_title, engine = 'python')\n",
    "print(ratings_old.shape)\n",
    "ratings_old.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dara Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User table after preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupationID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  gender  age  occupationID\n",
       "0       1       0    0            10\n",
       "1       2       1    6            16\n",
       "2       3       1    2            15\n",
       "3       4       1    4             7\n",
       "4       5       1    2            20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv('./ml-1m/users.dat', sep='::', header=None, names=users_title, engine = 'python')\n",
    "\n",
    "# Mapping gender to number[0, 1] \n",
    "users['gender'] = users['gender'].astype('category')\n",
    "users['gender'] = users['gender'].cat.codes\n",
    "\n",
    "# Mapping age range from age gourp to 0 - 7\n",
    "age_mapping = {1: 0, 18: 1, 25: 2, 35: 3, 45: 4, 50: 5, 56: 6}\n",
    "users['age'] = users['age'].map(age_mapping)\n",
    "\n",
    "# Dropping the zip-code columm\n",
    "# users.drop('zip-code')\n",
    "users.drop('zip-code', axis=1, inplace=True)\n",
    "\n",
    "print(\"User table after preprocessing\")\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie table after preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[4402, 3830, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[3, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[2282, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[2346, 3282, 4261, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[3285, 2115, 4434, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1357, 2495, 52, 5162, 958, 3482, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieID                                              title  \\\n",
       "0        1  [4402, 3830, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1        2   [2282, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2        3  [2346, 3282, 4261, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3        4  [3285, 2115, 4434, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4        5  [1357, 2495, 52, 5162, 958, 3482, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              genres  \n",
       "0  [3, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [2, 4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [5, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "3  [5, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('./ml-1m/movies.dat', sep='::', header=None, names=movies_title, engine = 'python')\n",
    "\n",
    "# Mapping the genres to the fixed length (len = 18) padded list\n",
    "genres_types = [\"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \n",
    "                \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \n",
    "                \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"]\n",
    "\n",
    "def genresToList(s):\n",
    "    result = [genres_types.index(g) + 1 for g in s.split(\"|\")]\n",
    "    result = result + [0 for i in range(18 - len(result))]\n",
    "    return result;\n",
    "    \n",
    "movies['genres'] = movies['genres'].apply(genresToList)\n",
    "\n",
    "# Remove year from title and mapping the title to the fixed length (len = 18) padded list\n",
    "def removeYear(s):\n",
    "    return s[:-7]\n",
    "movies['title'] = movies['title'].apply(removeYear)\n",
    "\n",
    "title_words = set()\n",
    "for title in movies[\"title\"]:\n",
    "    for word in title.split(\" \"):\n",
    "        title_words.add(word)\n",
    "title_words = list(title_words)\n",
    "        \n",
    "def titleToList(s):\n",
    "    result = [title_words.index(g) + 1 for g in s.split(\" \")]\n",
    "    result = result + [0 for i in range(15 - len(result))]\n",
    "    return result;\n",
    "\n",
    "movies['title'] = movies['title'].apply(titleToList)\n",
    "\n",
    "print(\"Movie table after preprocessing\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating table after preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating\n",
       "0       1     1193       5\n",
       "1       1      661       3\n",
       "2       1      914       3\n",
       "3       1     3408       4\n",
       "4       1     2355       5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('./ml-1m/ratings.dat', sep='::', header=None, names=ratings_title, engine = 'python')\n",
    "ratings.drop('timestamps', axis=1, inplace=True)\n",
    "\n",
    "print(\"Rating table after preprocessing\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "\n",
    "X_df, y_df = data.drop('rating', axis=1), data['rating']\n",
    "    \n",
    "X_all = X_df.values\n",
    "y_all = y_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User table dimensions:\n",
      "user_id_count: 6041\n",
      "user_gender_count: 2\n",
      "user_age_count: 7\n",
      "user_occupation_count: 21\n",
      "\n",
      "Movies table dimensions:\n",
      "movie_id_count: 3953\n",
      "movies_title_count: 5215\n",
      "movies_title_len: 15\n",
      "movies_genres_count: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"User table dimensions:\")\n",
    "user_id_count = users['userID'].nunique()+1\n",
    "print(\"user_id_count:\", user_id_count)\n",
    "\n",
    "user_gender_count = users['gender'].nunique()\n",
    "print(\"user_gender_count:\", user_gender_count)\n",
    "\n",
    "user_age_count = users['age'].nunique()\n",
    "print(\"user_age_count:\", user_age_count)\n",
    "\n",
    "user_occupation_count = users['occupationID'].nunique()\n",
    "print(\"user_occupation_count:\", user_occupation_count)\n",
    "\n",
    "\n",
    "print(\"\\nMovies table dimensions:\")\n",
    "movie_id_count = max(movies[\"movieID\"]) + 1\n",
    "print(\"movie_id_count:\", movie_id_count)\n",
    "\n",
    "movie_title_count = len(title_words) + 1\n",
    "print(\"movies_title_count:\", movie_title_count)\n",
    "\n",
    "movie_title_len = 15\n",
    "print(\"movies_title_len:\", movie_title_len)\n",
    "\n",
    "movie_genres_count = len(genres_types) + 1\n",
    "print(\"movies_genres_count:\", movie_genres_count)\n",
    "\n",
    "movieid2idx = {val[0]:i for i, val in enumerate(movies.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieRecommendationModel():\n",
    "    def __init__(self, learning_rate, embed_dim = 32, filter_num = 8, window_sizes = {2, 3, 4, 5}):\n",
    "        \n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32)\n",
    "        self.ratings = tf.placeholder(tf.int32, [None, 1])\n",
    "        \n",
    "        ###########################\n",
    "        # User Features Embedding #\n",
    "        ###########################\n",
    "        self.user_id = tf.placeholder(tf.int32, [None, 1])\n",
    "        self.user_gender = tf.placeholder(tf.int32, [None, 1])\n",
    "        self.user_age = tf.placeholder(tf.int32, [None, 1])\n",
    "        self.user_job = tf.placeholder(tf.int32, [None, 1])\n",
    "        \n",
    "        uid_embed_matrix = tf.Variable(tf.random_uniform([user_id_count, embed_dim], -1, 1))\n",
    "        uid_embed_layer = tf.nn.embedding_lookup(uid_embed_matrix, self.user_id)\n",
    "    \n",
    "        gender_embed_matrix = tf.Variable(tf.random_uniform([user_gender_count, embed_dim // 2], -1, 1))\n",
    "        gender_embed_layer = tf.nn.embedding_lookup(gender_embed_matrix, self.user_gender)\n",
    "        \n",
    "        age_embed_matrix = tf.Variable(tf.random_uniform([user_age_count, embed_dim // 2], -1, 1))\n",
    "        age_embed_layer = tf.nn.embedding_lookup(age_embed_matrix, self.user_age)\n",
    "        \n",
    "        job_embed_matrix = tf.Variable(tf.random_uniform([user_occupation_count, embed_dim // 2], -1, 1))\n",
    "        job_embed_layer = tf.nn.embedding_lookup(job_embed_matrix, self.user_job)\n",
    "\n",
    "        # First FC \n",
    "        uid_fc_layer = tf.layers.dense(uid_embed_layer, embed_dim, activation=tf.nn.relu)\n",
    "        gender_fc_layer = tf.layers.dense(gender_embed_layer, embed_dim, activation=tf.nn.relu)\n",
    "        age_fc_layer = tf.layers.dense(age_embed_layer, embed_dim, activation=tf.nn.relu)\n",
    "        job_fc_layer = tf.layers.dense(job_embed_layer, embed_dim, activation=tf.nn.relu)\n",
    "        \n",
    "        # Second FC\n",
    "        user_combine_layer = tf.concat([uid_fc_layer, gender_fc_layer, age_fc_layer, job_fc_layer], 2)  \n",
    "        user_combine_layer = tf.contrib.layers.fully_connected(user_combine_layer, 200, tf.tanh)  \n",
    "        self.user_combine_layer_flat = tf.reshape(user_combine_layer, [-1, 200])\n",
    "        \n",
    "        \n",
    "        #############################\n",
    "        # Movies Features Embedding #\n",
    "        #############################\n",
    "        self.movie_id = tf.placeholder(tf.int32, [None, 1])\n",
    "        self.movie_genres = tf.placeholder(tf.int32, [None, 18])\n",
    "        self.movie_titles = tf.placeholder(tf.int32, [None, 15])\n",
    "        \n",
    "        movie_id_embed_matrix = tf.Variable(tf.random_uniform([movie_id_count, embed_dim], -1, 1))\n",
    "        movie_id_embed_layer = tf.nn.embedding_lookup(movie_id_embed_matrix, self.movie_id)\n",
    "        \n",
    "        movie_genres_embed_matrix = tf.Variable(tf.random_uniform([movie_genres_count, embed_dim], -1, 1))\n",
    "        movie_genres_embed_layer = tf.nn.embedding_lookup(movie_genres_embed_matrix, self.movie_genres)\n",
    "        movie_genres_embed_layer = tf.reduce_sum(movie_genres_embed_layer, axis=1, keep_dims=True)\n",
    "        \n",
    "        movie_title_embed_matrix = tf.Variable(tf.random_uniform([movie_title_count, embed_dim], -1, 1))\n",
    "        movie_title_embed_layer = tf.nn.embedding_lookup(movie_title_embed_matrix, self.movie_titles)\n",
    "        movie_title_embed_layer_expand = tf.expand_dims(movie_title_embed_layer, -1)\n",
    "    \n",
    "        # CNN layer for movie titles\n",
    "        pool_layer_lst = []\n",
    "        for window_size in window_sizes:\n",
    "            filter_weights = tf.Variable(tf.truncated_normal([window_size, embed_dim, 1, filter_num],stddev=0.1))\n",
    "            filter_bias = tf.Variable(tf.constant(0.1, shape=[filter_num]))\n",
    "            \n",
    "            conv_layer = tf.nn.conv2d(movie_title_embed_layer_expand, filter_weights, [1,1,1,1], padding=\"VALID\")\n",
    "            relu_layer = tf.nn.relu(tf.nn.bias_add(conv_layer,filter_bias))\n",
    "            \n",
    "            maxpool_layer = tf.nn.max_pool(relu_layer, [1,movie_title_len - window_size + 1 ,1,1], [1,1,1,1], padding=\"VALID\")\n",
    "            pool_layer_lst.append(maxpool_layer)\n",
    "\n",
    "        \n",
    "        pool_layer = tf.concat(pool_layer_lst, 3)\n",
    "        max_num = len(window_sizes) * filter_num\n",
    "        pool_layer_flat = tf.reshape(pool_layer , [-1, 1, max_num])\n",
    "\n",
    "        dropout_layer = tf.nn.dropout(pool_layer_flat, self.dropout_keep_prob)\n",
    "        \n",
    "        # First FC \n",
    "        movie_id_fc_layer = tf.layers.dense(movie_id_embed_layer, embed_dim, activation=tf.nn.relu)\n",
    "        movie_genres_fc_layer = tf.layers.dense(movie_genres_embed_layer, embed_dim, activation=tf.nn.relu)\n",
    "    \n",
    "        # Second FC\n",
    "        movie_combine_layer = tf.concat([movie_id_fc_layer, movie_genres_fc_layer, dropout_layer], 2)  \n",
    "        movie_combine_layer = tf.contrib.layers.fully_connected(movie_combine_layer, 200, tf.tanh)  \n",
    "        self.movie_combine_layer_flat = tf.reshape(movie_combine_layer, [-1, 200])\n",
    "        \n",
    "        \n",
    "        pred_ratings = tf.reduce_sum(self.user_combine_layer_flat * self.movie_combine_layer_flat, axis=1)\n",
    "        self.pred_ratings = tf.expand_dims(pred_ratings, axis=1)\n",
    "        \n",
    "        # MSE Loss\n",
    "        cost = tf.losses.mean_squared_error(self.ratings, self.pred_ratings )\n",
    "        self.loss = tf.reduce_mean(cost)\n",
    "        \n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        gradients = optimizer.compute_gradients(self.loss)  #cost\n",
    "        self.train_op = optimizer.apply_gradients(gradients, global_step=self.global_step)\n",
    "        self.saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-10-8e3f5285d2a1>:28: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-10-8e3f5285d2a1>:51: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From <ipython-input-10-8e3f5285d2a1>:74: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = MovieRecommendationModel(learning_rate = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Batch:  0 / 3125 train_loss: 46.47184\n",
      "Epoch:  0  Batch:  20 / 3125 train_loss: 8.729784\n",
      "Epoch:  0  Batch:  40 / 3125 train_loss: 4.52647\n",
      "Epoch:  0  Batch:  60 / 3125 train_loss: 3.0631037\n",
      "Epoch:  0  Batch:  80 / 3125 train_loss: 2.3731756\n",
      "Epoch:  0  Batch:  100 / 3125 train_loss: 2.2199736\n",
      "Epoch:  0  Batch:  120 / 3125 train_loss: 2.5581226\n",
      "Epoch:  0  Batch:  140 / 3125 train_loss: 2.0382137\n",
      "Epoch:  0  Batch:  160 / 3125 train_loss: 1.5954967\n",
      "Epoch:  0  Batch:  180 / 3125 train_loss: 1.8497385\n",
      "Epoch:  0  Batch:  200 / 3125 train_loss: 1.9151881\n",
      "Epoch:  0  Batch:  220 / 3125 train_loss: 1.9614351\n",
      "Epoch:  0  Batch:  240 / 3125 train_loss: 1.7499074\n",
      "Epoch:  0  Batch:  260 / 3125 train_loss: 1.7494941\n",
      "Epoch:  0  Batch:  280 / 3125 train_loss: 1.766271\n",
      "Epoch:  0  Batch:  300 / 3125 train_loss: 1.6526048\n",
      "Epoch:  0  Batch:  320 / 3125 train_loss: 1.6229589\n",
      "Epoch:  0  Batch:  340 / 3125 train_loss: 1.3879076\n",
      "Epoch:  0  Batch:  360 / 3125 train_loss: 1.5291357\n",
      "Epoch:  0  Batch:  380 / 3125 train_loss: 1.4686635\n",
      "Epoch:  0  Batch:  400 / 3125 train_loss: 1.4319007\n",
      "Epoch:  0  Batch:  420 / 3125 train_loss: 1.361434\n",
      "Epoch:  0  Batch:  440 / 3125 train_loss: 1.5670052\n",
      "Epoch:  0  Batch:  460 / 3125 train_loss: 1.4013063\n",
      "Epoch:  0  Batch:  480 / 3125 train_loss: 1.6162776\n",
      "Epoch:  0  Batch:  500 / 3125 train_loss: 1.120237\n",
      "Epoch:  0  Batch:  520 / 3125 train_loss: 1.3596858\n",
      "Epoch:  0  Batch:  540 / 3125 train_loss: 1.4667834\n",
      "Epoch:  0  Batch:  560 / 3125 train_loss: 1.4663618\n",
      "Epoch:  0  Batch:  580 / 3125 train_loss: 1.4988513\n",
      "Epoch:  0  Batch:  600 / 3125 train_loss: 1.4564334\n",
      "Epoch:  0  Batch:  620 / 3125 train_loss: 1.5075648\n",
      "Epoch:  0  Batch:  640 / 3125 train_loss: 1.4605627\n",
      "Epoch:  0  Batch:  660 / 3125 train_loss: 1.4691932\n",
      "Epoch:  0  Batch:  680 / 3125 train_loss: 1.390556\n",
      "Epoch:  0  Batch:  700 / 3125 train_loss: 1.4277822\n",
      "Epoch:  0  Batch:  720 / 3125 train_loss: 1.2117059\n",
      "Epoch:  0  Batch:  740 / 3125 train_loss: 1.4050215\n",
      "Epoch:  0  Batch:  760 / 3125 train_loss: 1.4240608\n",
      "Epoch:  0  Batch:  780 / 3125 train_loss: 1.4307369\n",
      "Epoch:  0  Batch:  800 / 3125 train_loss: 1.3750215\n",
      "Epoch:  0  Batch:  820 / 3125 train_loss: 1.3168528\n",
      "Epoch:  0  Batch:  840 / 3125 train_loss: 1.3793236\n",
      "Epoch:  0  Batch:  860 / 3125 train_loss: 1.1158614\n",
      "Epoch:  0  Batch:  880 / 3125 train_loss: 1.2943766\n",
      "Epoch:  0  Batch:  900 / 3125 train_loss: 1.2753999\n",
      "Epoch:  0  Batch:  920 / 3125 train_loss: 1.3165547\n",
      "Epoch:  0  Batch:  940 / 3125 train_loss: 1.4957652\n",
      "Epoch:  0  Batch:  960 / 3125 train_loss: 1.4550414\n",
      "Epoch:  0  Batch:  980 / 3125 train_loss: 1.4352633\n",
      "Epoch:  0  Batch:  1000 / 3125 train_loss: 1.2907948\n",
      "Epoch:  0  Batch:  1020 / 3125 train_loss: 1.4192032\n",
      "Epoch:  0  Batch:  1040 / 3125 train_loss: 1.293263\n",
      "Epoch:  0  Batch:  1060 / 3125 train_loss: 1.441915\n",
      "Epoch:  0  Batch:  1080 / 3125 train_loss: 1.2177312\n",
      "Epoch:  0  Batch:  1100 / 3125 train_loss: 1.335101\n",
      "Epoch:  0  Batch:  1120 / 3125 train_loss: 1.3760612\n",
      "Epoch:  0  Batch:  1140 / 3125 train_loss: 1.3637621\n",
      "Epoch:  0  Batch:  1160 / 3125 train_loss: 1.3295438\n",
      "Epoch:  0  Batch:  1180 / 3125 train_loss: 1.2579308\n",
      "Epoch:  0  Batch:  1200 / 3125 train_loss: 1.2573462\n",
      "Epoch:  0  Batch:  1220 / 3125 train_loss: 1.1698849\n",
      "Epoch:  0  Batch:  1240 / 3125 train_loss: 1.1637735\n",
      "Epoch:  0  Batch:  1260 / 3125 train_loss: 1.2782917\n",
      "Epoch:  0  Batch:  1280 / 3125 train_loss: 1.2809727\n",
      "Epoch:  0  Batch:  1300 / 3125 train_loss: 1.3110532\n",
      "Epoch:  0  Batch:  1320 / 3125 train_loss: 1.2914238\n",
      "Epoch:  0  Batch:  1340 / 3125 train_loss: 1.150346\n",
      "Epoch:  0  Batch:  1360 / 3125 train_loss: 1.1686358\n",
      "Epoch:  0  Batch:  1380 / 3125 train_loss: 1.1837778\n",
      "Epoch:  0  Batch:  1400 / 3125 train_loss: 1.3522271\n",
      "Epoch:  0  Batch:  1420 / 3125 train_loss: 1.3148043\n",
      "Epoch:  0  Batch:  1440 / 3125 train_loss: 1.1446927\n",
      "Epoch:  0  Batch:  1460 / 3125 train_loss: 1.2555412\n",
      "Epoch:  0  Batch:  1480 / 3125 train_loss: 1.339241\n",
      "Epoch:  0  Batch:  1500 / 3125 train_loss: 1.419539\n",
      "Epoch:  0  Batch:  1520 / 3125 train_loss: 1.322492\n",
      "Epoch:  0  Batch:  1540 / 3125 train_loss: 1.3643665\n",
      "Epoch:  0  Batch:  1560 / 3125 train_loss: 1.183428\n",
      "Epoch:  0  Batch:  1580 / 3125 train_loss: 1.2670901\n",
      "Epoch:  0  Batch:  1600 / 3125 train_loss: 1.3065875\n",
      "Epoch:  0  Batch:  1620 / 3125 train_loss: 1.2583954\n",
      "Epoch:  0  Batch:  1640 / 3125 train_loss: 1.4072943\n",
      "Epoch:  0  Batch:  1660 / 3125 train_loss: 1.3135645\n",
      "Epoch:  0  Batch:  1680 / 3125 train_loss: 1.2550335\n",
      "Epoch:  0  Batch:  1700 / 3125 train_loss: 1.1303113\n",
      "Epoch:  0  Batch:  1720 / 3125 train_loss: 1.1492898\n",
      "Epoch:  0  Batch:  1740 / 3125 train_loss: 1.2549422\n",
      "Epoch:  0  Batch:  1760 / 3125 train_loss: 1.4286087\n",
      "Epoch:  0  Batch:  1780 / 3125 train_loss: 1.1423912\n",
      "Epoch:  0  Batch:  1800 / 3125 train_loss: 1.2039567\n",
      "Epoch:  0  Batch:  1820 / 3125 train_loss: 1.2037873\n",
      "Epoch:  0  Batch:  1840 / 3125 train_loss: 1.3142684\n",
      "Epoch:  0  Batch:  1860 / 3125 train_loss: 1.2232591\n",
      "Epoch:  0  Batch:  1880 / 3125 train_loss: 1.3178985\n",
      "Epoch:  0  Batch:  1900 / 3125 train_loss: 1.096327\n",
      "Epoch:  0  Batch:  1920 / 3125 train_loss: 1.179475\n",
      "Epoch:  0  Batch:  1940 / 3125 train_loss: 1.0897257\n",
      "Epoch:  0  Batch:  1960 / 3125 train_loss: 1.1477205\n",
      "Epoch:  0  Batch:  1980 / 3125 train_loss: 1.1944699\n",
      "Epoch:  0  Batch:  2000 / 3125 train_loss: 1.4058986\n",
      "Epoch:  0  Batch:  2020 / 3125 train_loss: 1.3319231\n",
      "Epoch:  0  Batch:  2040 / 3125 train_loss: 1.1494718\n",
      "Epoch:  0  Batch:  2060 / 3125 train_loss: 1.0378104\n",
      "Epoch:  0  Batch:  2080 / 3125 train_loss: 1.3147557\n",
      "Epoch:  0  Batch:  2100 / 3125 train_loss: 1.1968431\n",
      "Epoch:  0  Batch:  2120 / 3125 train_loss: 1.1786771\n",
      "Epoch:  0  Batch:  2140 / 3125 train_loss: 1.2203686\n",
      "Epoch:  0  Batch:  2160 / 3125 train_loss: 1.1970313\n",
      "Epoch:  0  Batch:  2180 / 3125 train_loss: 1.209013\n",
      "Epoch:  0  Batch:  2200 / 3125 train_loss: 1.1424924\n",
      "Epoch:  0  Batch:  2220 / 3125 train_loss: 1.1321641\n",
      "Epoch:  0  Batch:  2240 / 3125 train_loss: 1.0220313\n",
      "Epoch:  0  Batch:  2260 / 3125 train_loss: 1.0666475\n",
      "Epoch:  0  Batch:  2280 / 3125 train_loss: 1.2600564\n",
      "Epoch:  0  Batch:  2300 / 3125 train_loss: 1.2922976\n",
      "Epoch:  0  Batch:  2320 / 3125 train_loss: 1.37573\n",
      "Epoch:  0  Batch:  2340 / 3125 train_loss: 1.2792368\n",
      "Epoch:  0  Batch:  2360 / 3125 train_loss: 1.247871\n",
      "Epoch:  0  Batch:  2380 / 3125 train_loss: 1.1845772\n",
      "Epoch:  0  Batch:  2400 / 3125 train_loss: 1.2841017\n",
      "Epoch:  0  Batch:  2420 / 3125 train_loss: 1.1535778\n",
      "Epoch:  0  Batch:  2440 / 3125 train_loss: 1.2539432\n",
      "Epoch:  0  Batch:  2460 / 3125 train_loss: 1.1664914\n",
      "Epoch:  0  Batch:  2480 / 3125 train_loss: 1.2133684\n",
      "Epoch:  0  Batch:  2500 / 3125 train_loss: 1.24088\n",
      "Epoch:  0  Batch:  2520 / 3125 train_loss: 1.0395424\n",
      "Epoch:  0  Batch:  2540 / 3125 train_loss: 1.0928733\n",
      "Epoch:  0  Batch:  2560 / 3125 train_loss: 1.0104357\n",
      "Epoch:  0  Batch:  2580 / 3125 train_loss: 1.1760662\n",
      "Epoch:  0  Batch:  2600 / 3125 train_loss: 1.1897388\n",
      "Epoch:  0  Batch:  2620 / 3125 train_loss: 1.0435168\n",
      "Epoch:  0  Batch:  2640 / 3125 train_loss: 1.1373984\n",
      "Epoch:  0  Batch:  2660 / 3125 train_loss: 1.2629287\n",
      "Epoch:  0  Batch:  2680 / 3125 train_loss: 1.054555\n",
      "Epoch:  0  Batch:  2700 / 3125 train_loss: 1.1988201\n",
      "Epoch:  0  Batch:  2720 / 3125 train_loss: 1.135499\n",
      "Epoch:  0  Batch:  2740 / 3125 train_loss: 1.1583097\n",
      "Epoch:  0  Batch:  2760 / 3125 train_loss: 1.2410802\n",
      "Epoch:  0  Batch:  2780 / 3125 train_loss: 1.1431501\n",
      "Epoch:  0  Batch:  2800 / 3125 train_loss: 1.2894392\n",
      "Epoch:  0  Batch:  2820 / 3125 train_loss: 1.4014713\n",
      "Epoch:  0  Batch:  2840 / 3125 train_loss: 1.1848507\n",
      "Epoch:  0  Batch:  2860 / 3125 train_loss: 1.0713788\n",
      "Epoch:  0  Batch:  2880 / 3125 train_loss: 1.1724948\n",
      "Epoch:  0  Batch:  2900 / 3125 train_loss: 1.2153137\n",
      "Epoch:  0  Batch:  2920 / 3125 train_loss: 1.1925702\n",
      "Epoch:  0  Batch:  2940 / 3125 train_loss: 1.1571712\n",
      "Epoch:  0  Batch:  2960 / 3125 train_loss: 1.194133\n",
      "Epoch:  0  Batch:  2980 / 3125 train_loss: 1.1398004\n",
      "Epoch:  0  Batch:  3000 / 3125 train_loss: 1.1694205\n",
      "Epoch:  0  Batch:  3020 / 3125 train_loss: 1.1833208\n",
      "Epoch:  0  Batch:  3040 / 3125 train_loss: 1.1560751\n",
      "Epoch:  0  Batch:  3060 / 3125 train_loss: 1.193538\n",
      "Epoch:  0  Batch:  3080 / 3125 train_loss: 1.2593527\n",
      "Epoch:  0  Batch:  3100 / 3125 train_loss: 1.223001\n",
      "Epoch:  0  Batch:  3120 / 3125 train_loss: 1.0470504\n",
      "Epoch:  0  Batch:  0 / 781 test_loss: 0.9918797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Batch:  20 / 781 test_loss: 1.1404462\n",
      "Epoch:  0  Batch:  40 / 781 test_loss: 1.0672472\n",
      "Epoch:  0  Batch:  60 / 781 test_loss: 1.3214824\n",
      "Epoch:  0  Batch:  80 / 781 test_loss: 1.4217193\n",
      "Epoch:  0  Batch:  100 / 781 test_loss: 1.3318105\n",
      "Epoch:  0  Batch:  120 / 781 test_loss: 1.2531283\n",
      "Epoch:  0  Batch:  140 / 781 test_loss: 1.1868552\n",
      "Epoch:  0  Batch:  160 / 781 test_loss: 1.3459724\n",
      "Epoch:  0  Batch:  180 / 781 test_loss: 1.2844152\n",
      "Epoch:  0  Batch:  200 / 781 test_loss: 1.1984853\n",
      "Epoch:  0  Batch:  220 / 781 test_loss: 0.97620267\n",
      "Epoch:  0  Batch:  240 / 781 test_loss: 1.1959771\n",
      "Epoch:  0  Batch:  260 / 781 test_loss: 1.1780281\n",
      "Epoch:  0  Batch:  280 / 781 test_loss: 1.4169071\n",
      "Epoch:  0  Batch:  300 / 781 test_loss: 1.1605544\n",
      "Epoch:  0  Batch:  320 / 781 test_loss: 1.3431023\n",
      "Epoch:  0  Batch:  340 / 781 test_loss: 0.8604841\n",
      "Epoch:  0  Batch:  360 / 781 test_loss: 1.2684189\n",
      "Epoch:  0  Batch:  380 / 781 test_loss: 1.2067487\n",
      "Epoch:  0  Batch:  400 / 781 test_loss: 1.1034935\n",
      "Epoch:  0  Batch:  420 / 781 test_loss: 1.0327849\n",
      "Epoch:  0  Batch:  440 / 781 test_loss: 1.3111596\n",
      "Epoch:  0  Batch:  460 / 781 test_loss: 1.1420518\n",
      "Epoch:  0  Batch:  480 / 781 test_loss: 1.1787683\n",
      "Epoch:  0  Batch:  500 / 781 test_loss: 1.0538993\n",
      "Epoch:  0  Batch:  520 / 781 test_loss: 1.184612\n",
      "Epoch:  0  Batch:  540 / 781 test_loss: 1.0121057\n",
      "Epoch:  0  Batch:  560 / 781 test_loss: 1.2966051\n",
      "Epoch:  0  Batch:  580 / 781 test_loss: 1.2120166\n",
      "Epoch:  0  Batch:  600 / 781 test_loss: 1.2021415\n",
      "Epoch:  0  Batch:  620 / 781 test_loss: 1.2563932\n",
      "Epoch:  0  Batch:  640 / 781 test_loss: 1.2235436\n",
      "Epoch:  0  Batch:  660 / 781 test_loss: 1.2122439\n",
      "Epoch:  0  Batch:  680 / 781 test_loss: 1.4742072\n",
      "Epoch:  0  Batch:  700 / 781 test_loss: 1.169841\n",
      "Epoch:  0  Batch:  720 / 781 test_loss: 1.3216947\n",
      "Epoch:  0  Batch:  740 / 781 test_loss: 1.242008\n",
      "Epoch:  0  Batch:  760 / 781 test_loss: 1.1631874\n",
      "Epoch:  0  Batch:  780 / 781 test_loss: 1.2049034\n",
      "Epoch:  1  Batch:  0 / 3125 train_loss: 1.3307662\n",
      "Epoch:  1  Batch:  20 / 3125 train_loss: 1.0959313\n",
      "Epoch:  1  Batch:  40 / 3125 train_loss: 1.2156734\n",
      "Epoch:  1  Batch:  60 / 3125 train_loss: 1.0040113\n",
      "Epoch:  1  Batch:  80 / 3125 train_loss: 1.14081\n",
      "Epoch:  1  Batch:  100 / 3125 train_loss: 1.2356079\n",
      "Epoch:  1  Batch:  120 / 3125 train_loss: 1.3186879\n",
      "Epoch:  1  Batch:  140 / 3125 train_loss: 1.1827856\n",
      "Epoch:  1  Batch:  160 / 3125 train_loss: 1.0185113\n",
      "Epoch:  1  Batch:  180 / 3125 train_loss: 1.1274477\n",
      "Epoch:  1  Batch:  200 / 3125 train_loss: 1.3709418\n",
      "Epoch:  1  Batch:  220 / 3125 train_loss: 1.1447034\n",
      "Epoch:  1  Batch:  240 / 3125 train_loss: 1.1890666\n",
      "Epoch:  1  Batch:  260 / 3125 train_loss: 1.2170296\n",
      "Epoch:  1  Batch:  280 / 3125 train_loss: 1.2936227\n",
      "Epoch:  1  Batch:  300 / 3125 train_loss: 1.1968377\n",
      "Epoch:  1  Batch:  320 / 3125 train_loss: 1.282788\n",
      "Epoch:  1  Batch:  340 / 3125 train_loss: 1.0066994\n",
      "Epoch:  1  Batch:  360 / 3125 train_loss: 1.1660683\n",
      "Epoch:  1  Batch:  380 / 3125 train_loss: 1.1352873\n",
      "Epoch:  1  Batch:  400 / 3125 train_loss: 1.073778\n",
      "Epoch:  1  Batch:  420 / 3125 train_loss: 1.0459913\n",
      "Epoch:  1  Batch:  440 / 3125 train_loss: 1.1677804\n",
      "Epoch:  1  Batch:  460 / 3125 train_loss: 1.1751336\n",
      "Epoch:  1  Batch:  480 / 3125 train_loss: 1.1650817\n",
      "Epoch:  1  Batch:  500 / 3125 train_loss: 0.88415396\n",
      "Epoch:  1  Batch:  520 / 3125 train_loss: 1.1443093\n",
      "Epoch:  1  Batch:  540 / 3125 train_loss: 1.0906572\n",
      "Epoch:  1  Batch:  560 / 3125 train_loss: 1.1766492\n",
      "Epoch:  1  Batch:  580 / 3125 train_loss: 1.2738007\n",
      "Epoch:  1  Batch:  600 / 3125 train_loss: 1.2748289\n",
      "Epoch:  1  Batch:  620 / 3125 train_loss: 1.2033842\n",
      "Epoch:  1  Batch:  640 / 3125 train_loss: 1.2037616\n",
      "Epoch:  1  Batch:  660 / 3125 train_loss: 1.1397653\n",
      "Epoch:  1  Batch:  680 / 3125 train_loss: 1.139271\n",
      "Epoch:  1  Batch:  700 / 3125 train_loss: 1.1463645\n",
      "Epoch:  1  Batch:  720 / 3125 train_loss: 1.0121996\n",
      "Epoch:  1  Batch:  740 / 3125 train_loss: 1.1259786\n",
      "Epoch:  1  Batch:  760 / 3125 train_loss: 1.1241606\n",
      "Epoch:  1  Batch:  780 / 3125 train_loss: 1.1630706\n",
      "Epoch:  1  Batch:  800 / 3125 train_loss: 1.0471861\n",
      "Epoch:  1  Batch:  820 / 3125 train_loss: 1.0270143\n",
      "Epoch:  1  Batch:  840 / 3125 train_loss: 1.0051928\n",
      "Epoch:  1  Batch:  860 / 3125 train_loss: 1.0000806\n",
      "Epoch:  1  Batch:  880 / 3125 train_loss: 1.0933379\n",
      "Epoch:  1  Batch:  900 / 3125 train_loss: 1.1048787\n",
      "Epoch:  1  Batch:  920 / 3125 train_loss: 1.1448797\n",
      "Epoch:  1  Batch:  940 / 3125 train_loss: 1.2787889\n",
      "Epoch:  1  Batch:  960 / 3125 train_loss: 1.2529784\n",
      "Epoch:  1  Batch:  980 / 3125 train_loss: 1.2436002\n",
      "Epoch:  1  Batch:  1000 / 3125 train_loss: 1.146007\n",
      "Epoch:  1  Batch:  1020 / 3125 train_loss: 1.2056074\n",
      "Epoch:  1  Batch:  1040 / 3125 train_loss: 1.0861033\n",
      "Epoch:  1  Batch:  1060 / 3125 train_loss: 1.2424093\n",
      "Epoch:  1  Batch:  1080 / 3125 train_loss: 1.0934662\n",
      "Epoch:  1  Batch:  1100 / 3125 train_loss: 1.1036801\n",
      "Epoch:  1  Batch:  1120 / 3125 train_loss: 1.1586679\n",
      "Epoch:  1  Batch:  1140 / 3125 train_loss: 1.1288973\n",
      "Epoch:  1  Batch:  1160 / 3125 train_loss: 1.0795513\n",
      "Epoch:  1  Batch:  1180 / 3125 train_loss: 1.1086365\n",
      "Epoch:  1  Batch:  1200 / 3125 train_loss: 1.1287464\n",
      "Epoch:  1  Batch:  1220 / 3125 train_loss: 1.0320793\n",
      "Epoch:  1  Batch:  1240 / 3125 train_loss: 0.97158897\n",
      "Epoch:  1  Batch:  1260 / 3125 train_loss: 1.096388\n",
      "Epoch:  1  Batch:  1280 / 3125 train_loss: 1.0710064\n",
      "Epoch:  1  Batch:  1300 / 3125 train_loss: 1.0393177\n",
      "Epoch:  1  Batch:  1320 / 3125 train_loss: 1.0467958\n",
      "Epoch:  1  Batch:  1340 / 3125 train_loss: 0.9242145\n",
      "Epoch:  1  Batch:  1360 / 3125 train_loss: 0.9975141\n",
      "Epoch:  1  Batch:  1380 / 3125 train_loss: 1.0403467\n",
      "Epoch:  1  Batch:  1400 / 3125 train_loss: 1.1222327\n",
      "Epoch:  1  Batch:  1420 / 3125 train_loss: 1.1667752\n",
      "Epoch:  1  Batch:  1440 / 3125 train_loss: 0.9751713\n",
      "Epoch:  1  Batch:  1460 / 3125 train_loss: 1.094673\n",
      "Epoch:  1  Batch:  1480 / 3125 train_loss: 1.1521218\n",
      "Epoch:  1  Batch:  1500 / 3125 train_loss: 1.2123268\n",
      "Epoch:  1  Batch:  1520 / 3125 train_loss: 1.0990137\n",
      "Epoch:  1  Batch:  1540 / 3125 train_loss: 1.100957\n",
      "Epoch:  1  Batch:  1560 / 3125 train_loss: 0.96344316\n",
      "Epoch:  1  Batch:  1580 / 3125 train_loss: 1.1025503\n",
      "Epoch:  1  Batch:  1600 / 3125 train_loss: 1.0697396\n",
      "Epoch:  1  Batch:  1620 / 3125 train_loss: 1.0636849\n",
      "Epoch:  1  Batch:  1640 / 3125 train_loss: 1.2222624\n",
      "Epoch:  1  Batch:  1660 / 3125 train_loss: 1.1445451\n",
      "Epoch:  1  Batch:  1680 / 3125 train_loss: 1.1137049\n",
      "Epoch:  1  Batch:  1700 / 3125 train_loss: 0.919193\n",
      "Epoch:  1  Batch:  1720 / 3125 train_loss: 1.0015383\n",
      "Epoch:  1  Batch:  1740 / 3125 train_loss: 1.1194527\n",
      "Epoch:  1  Batch:  1760 / 3125 train_loss: 1.2342389\n",
      "Epoch:  1  Batch:  1780 / 3125 train_loss: 0.98645663\n",
      "Epoch:  1  Batch:  1800 / 3125 train_loss: 1.02845\n",
      "Epoch:  1  Batch:  1820 / 3125 train_loss: 1.0386541\n",
      "Epoch:  1  Batch:  1840 / 3125 train_loss: 1.1543025\n",
      "Epoch:  1  Batch:  1860 / 3125 train_loss: 1.04277\n",
      "Epoch:  1  Batch:  1880 / 3125 train_loss: 1.1393785\n",
      "Epoch:  1  Batch:  1900 / 3125 train_loss: 0.9099953\n",
      "Epoch:  1  Batch:  1920 / 3125 train_loss: 1.0420177\n",
      "Epoch:  1  Batch:  1940 / 3125 train_loss: 0.96619296\n",
      "Epoch:  1  Batch:  1960 / 3125 train_loss: 1.0028477\n",
      "Epoch:  1  Batch:  1980 / 3125 train_loss: 1.0091144\n",
      "Epoch:  1  Batch:  2000 / 3125 train_loss: 1.2612371\n",
      "Epoch:  1  Batch:  2020 / 3125 train_loss: 1.2276292\n",
      "Epoch:  1  Batch:  2040 / 3125 train_loss: 1.0182757\n",
      "Epoch:  1  Batch:  2060 / 3125 train_loss: 0.89297915\n",
      "Epoch:  1  Batch:  2080 / 3125 train_loss: 1.1413988\n",
      "Epoch:  1  Batch:  2100 / 3125 train_loss: 0.9381672\n",
      "Epoch:  1  Batch:  2120 / 3125 train_loss: 1.0448363\n",
      "Epoch:  1  Batch:  2140 / 3125 train_loss: 1.0619481\n",
      "Epoch:  1  Batch:  2160 / 3125 train_loss: 0.97591496\n",
      "Epoch:  1  Batch:  2180 / 3125 train_loss: 1.0716691\n",
      "Epoch:  1  Batch:  2200 / 3125 train_loss: 0.99427354\n",
      "Epoch:  1  Batch:  2220 / 3125 train_loss: 0.97331965\n",
      "Epoch:  1  Batch:  2240 / 3125 train_loss: 0.9233419\n",
      "Epoch:  1  Batch:  2260 / 3125 train_loss: 0.9619156\n",
      "Epoch:  1  Batch:  2280 / 3125 train_loss: 1.1084647\n",
      "Epoch:  1  Batch:  2300 / 3125 train_loss: 1.0588639\n",
      "Epoch:  1  Batch:  2320 / 3125 train_loss: 1.1767505\n",
      "Epoch:  1  Batch:  2340 / 3125 train_loss: 1.0696054\n",
      "Epoch:  1  Batch:  2360 / 3125 train_loss: 1.0532815\n",
      "Epoch:  1  Batch:  2380 / 3125 train_loss: 1.0400467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  Batch:  2400 / 3125 train_loss: 1.1128215\n",
      "Epoch:  1  Batch:  2420 / 3125 train_loss: 0.98719466\n",
      "Epoch:  1  Batch:  2440 / 3125 train_loss: 1.0305676\n",
      "Epoch:  1  Batch:  2460 / 3125 train_loss: 0.96805817\n",
      "Epoch:  1  Batch:  2480 / 3125 train_loss: 1.0549607\n",
      "Epoch:  1  Batch:  2500 / 3125 train_loss: 1.0386844\n",
      "Epoch:  1  Batch:  2520 / 3125 train_loss: 0.95966804\n",
      "Epoch:  1  Batch:  2540 / 3125 train_loss: 0.9613092\n",
      "Epoch:  1  Batch:  2560 / 3125 train_loss: 0.85862964\n",
      "Epoch:  1  Batch:  2580 / 3125 train_loss: 1.0366757\n",
      "Epoch:  1  Batch:  2600 / 3125 train_loss: 1.0783887\n",
      "Epoch:  1  Batch:  2620 / 3125 train_loss: 0.89628977\n",
      "Epoch:  1  Batch:  2640 / 3125 train_loss: 1.0233835\n",
      "Epoch:  1  Batch:  2660 / 3125 train_loss: 1.1771518\n",
      "Epoch:  1  Batch:  2680 / 3125 train_loss: 0.92584044\n",
      "Epoch:  1  Batch:  2700 / 3125 train_loss: 1.0125048\n",
      "Epoch:  1  Batch:  2720 / 3125 train_loss: 0.907007\n",
      "Epoch:  1  Batch:  2740 / 3125 train_loss: 1.0025446\n",
      "Epoch:  1  Batch:  2760 / 3125 train_loss: 1.0206727\n",
      "Epoch:  1  Batch:  2780 / 3125 train_loss: 0.9193332\n",
      "Epoch:  1  Batch:  2800 / 3125 train_loss: 1.1360508\n",
      "Epoch:  1  Batch:  2820 / 3125 train_loss: 1.1963587\n",
      "Epoch:  1  Batch:  2840 / 3125 train_loss: 1.0826396\n",
      "Epoch:  1  Batch:  2860 / 3125 train_loss: 0.94305444\n",
      "Epoch:  1  Batch:  2880 / 3125 train_loss: 1.0257708\n",
      "Epoch:  1  Batch:  2900 / 3125 train_loss: 1.0357113\n",
      "Epoch:  1  Batch:  2920 / 3125 train_loss: 1.0254636\n",
      "Epoch:  1  Batch:  2940 / 3125 train_loss: 1.0129521\n",
      "Epoch:  1  Batch:  2960 / 3125 train_loss: 0.98509115\n",
      "Epoch:  1  Batch:  2980 / 3125 train_loss: 0.9661391\n",
      "Epoch:  1  Batch:  3000 / 3125 train_loss: 1.1369054\n",
      "Epoch:  1  Batch:  3020 / 3125 train_loss: 1.0783443\n",
      "Epoch:  1  Batch:  3040 / 3125 train_loss: 1.0083067\n",
      "Epoch:  1  Batch:  3060 / 3125 train_loss: 1.0019099\n",
      "Epoch:  1  Batch:  3080 / 3125 train_loss: 1.1113586\n",
      "Epoch:  1  Batch:  3100 / 3125 train_loss: 1.1220968\n",
      "Epoch:  1  Batch:  3120 / 3125 train_loss: 0.8679751\n",
      "Epoch:  1  Batch:  0 / 781 test_loss: 0.9493418\n",
      "Epoch:  1  Batch:  20 / 781 test_loss: 1.0805697\n",
      "Epoch:  1  Batch:  40 / 781 test_loss: 0.89748883\n",
      "Epoch:  1  Batch:  60 / 781 test_loss: 1.1959295\n",
      "Epoch:  1  Batch:  80 / 781 test_loss: 1.2085173\n",
      "Epoch:  1  Batch:  100 / 781 test_loss: 1.1225305\n",
      "Epoch:  1  Batch:  120 / 781 test_loss: 1.0497831\n",
      "Epoch:  1  Batch:  140 / 781 test_loss: 0.9908841\n",
      "Epoch:  1  Batch:  160 / 781 test_loss: 1.1464946\n",
      "Epoch:  1  Batch:  180 / 781 test_loss: 1.0895193\n",
      "Epoch:  1  Batch:  200 / 781 test_loss: 1.0235803\n",
      "Epoch:  1  Batch:  220 / 781 test_loss: 0.83738524\n",
      "Epoch:  1  Batch:  240 / 781 test_loss: 1.1059453\n",
      "Epoch:  1  Batch:  260 / 781 test_loss: 1.009758\n",
      "Epoch:  1  Batch:  280 / 781 test_loss: 1.2455919\n",
      "Epoch:  1  Batch:  300 / 781 test_loss: 1.0010781\n",
      "Epoch:  1  Batch:  320 / 781 test_loss: 1.1480994\n",
      "Epoch:  1  Batch:  340 / 781 test_loss: 0.7479221\n",
      "Epoch:  1  Batch:  360 / 781 test_loss: 1.0798261\n",
      "Epoch:  1  Batch:  380 / 781 test_loss: 1.0548674\n",
      "Epoch:  1  Batch:  400 / 781 test_loss: 0.95196754\n",
      "Epoch:  1  Batch:  420 / 781 test_loss: 0.87100244\n",
      "Epoch:  1  Batch:  440 / 781 test_loss: 1.0959243\n",
      "Epoch:  1  Batch:  460 / 781 test_loss: 1.0317808\n",
      "Epoch:  1  Batch:  480 / 781 test_loss: 1.000055\n",
      "Epoch:  1  Batch:  500 / 781 test_loss: 0.8888089\n",
      "Epoch:  1  Batch:  520 / 781 test_loss: 0.95558673\n",
      "Epoch:  1  Batch:  540 / 781 test_loss: 0.84363216\n",
      "Epoch:  1  Batch:  560 / 781 test_loss: 1.0770463\n",
      "Epoch:  1  Batch:  580 / 781 test_loss: 0.9986624\n",
      "Epoch:  1  Batch:  600 / 781 test_loss: 1.0944755\n",
      "Epoch:  1  Batch:  620 / 781 test_loss: 1.0711906\n",
      "Epoch:  1  Batch:  640 / 781 test_loss: 1.1081305\n",
      "Epoch:  1  Batch:  660 / 781 test_loss: 0.9927606\n",
      "Epoch:  1  Batch:  680 / 781 test_loss: 1.2014678\n",
      "Epoch:  1  Batch:  700 / 781 test_loss: 0.9934944\n",
      "Epoch:  1  Batch:  720 / 781 test_loss: 1.1494431\n",
      "Epoch:  1  Batch:  740 / 781 test_loss: 1.0219802\n",
      "Epoch:  1  Batch:  760 / 781 test_loss: 0.99352294\n",
      "Epoch:  1  Batch:  780 / 781 test_loss: 1.0329678\n",
      "Epoch:  2  Batch:  0 / 3125 train_loss: 1.1602218\n",
      "Epoch:  2  Batch:  20 / 3125 train_loss: 0.9979637\n",
      "Epoch:  2  Batch:  40 / 3125 train_loss: 1.0844473\n",
      "Epoch:  2  Batch:  60 / 3125 train_loss: 0.85361075\n",
      "Epoch:  2  Batch:  80 / 3125 train_loss: 0.9936261\n",
      "Epoch:  2  Batch:  100 / 3125 train_loss: 1.0659367\n",
      "Epoch:  2  Batch:  120 / 3125 train_loss: 1.1404953\n",
      "Epoch:  2  Batch:  140 / 3125 train_loss: 1.0846796\n",
      "Epoch:  2  Batch:  160 / 3125 train_loss: 0.8742768\n",
      "Epoch:  2  Batch:  180 / 3125 train_loss: 1.0262952\n",
      "Epoch:  2  Batch:  200 / 3125 train_loss: 1.2102449\n",
      "Epoch:  2  Batch:  220 / 3125 train_loss: 1.0421898\n",
      "Epoch:  2  Batch:  240 / 3125 train_loss: 1.0933516\n",
      "Epoch:  2  Batch:  260 / 3125 train_loss: 1.0431592\n",
      "Epoch:  2  Batch:  280 / 3125 train_loss: 1.104408\n",
      "Epoch:  2  Batch:  300 / 3125 train_loss: 1.1241552\n",
      "Epoch:  2  Batch:  320 / 3125 train_loss: 1.1151966\n",
      "Epoch:  2  Batch:  340 / 3125 train_loss: 0.8413136\n",
      "Epoch:  2  Batch:  360 / 3125 train_loss: 0.99300003\n",
      "Epoch:  2  Batch:  380 / 3125 train_loss: 1.034676\n",
      "Epoch:  2  Batch:  400 / 3125 train_loss: 0.967996\n",
      "Epoch:  2  Batch:  420 / 3125 train_loss: 0.9225181\n",
      "Epoch:  2  Batch:  440 / 3125 train_loss: 0.96041715\n",
      "Epoch:  2  Batch:  460 / 3125 train_loss: 1.0548323\n",
      "Epoch:  2  Batch:  480 / 3125 train_loss: 1.076711\n",
      "Epoch:  2  Batch:  500 / 3125 train_loss: 0.773898\n",
      "Epoch:  2  Batch:  520 / 3125 train_loss: 0.98788255\n",
      "Epoch:  2  Batch:  540 / 3125 train_loss: 0.96244067\n",
      "Epoch:  2  Batch:  560 / 3125 train_loss: 1.089333\n",
      "Epoch:  2  Batch:  580 / 3125 train_loss: 1.0787055\n",
      "Epoch:  2  Batch:  600 / 3125 train_loss: 1.1398414\n",
      "Epoch:  2  Batch:  620 / 3125 train_loss: 1.0173028\n",
      "Epoch:  2  Batch:  640 / 3125 train_loss: 1.0639687\n",
      "Epoch:  2  Batch:  660 / 3125 train_loss: 0.9871273\n",
      "Epoch:  2  Batch:  680 / 3125 train_loss: 1.0849768\n",
      "Epoch:  2  Batch:  700 / 3125 train_loss: 0.98730016\n",
      "Epoch:  2  Batch:  720 / 3125 train_loss: 0.88129735\n",
      "Epoch:  2  Batch:  740 / 3125 train_loss: 0.996156\n",
      "Epoch:  2  Batch:  760 / 3125 train_loss: 0.92608607\n",
      "Epoch:  2  Batch:  780 / 3125 train_loss: 0.9849625\n",
      "Epoch:  2  Batch:  800 / 3125 train_loss: 0.9200634\n",
      "Epoch:  2  Batch:  820 / 3125 train_loss: 0.925118\n",
      "Epoch:  2  Batch:  840 / 3125 train_loss: 0.9017699\n",
      "Epoch:  2  Batch:  860 / 3125 train_loss: 0.93639886\n",
      "Epoch:  2  Batch:  880 / 3125 train_loss: 0.9626789\n",
      "Epoch:  2  Batch:  900 / 3125 train_loss: 0.97054154\n",
      "Epoch:  2  Batch:  920 / 3125 train_loss: 1.042978\n",
      "Epoch:  2  Batch:  940 / 3125 train_loss: 1.0777283\n",
      "Epoch:  2  Batch:  960 / 3125 train_loss: 1.0993979\n",
      "Epoch:  2  Batch:  980 / 3125 train_loss: 1.151942\n",
      "Epoch:  2  Batch:  1000 / 3125 train_loss: 1.0401857\n",
      "Epoch:  2  Batch:  1020 / 3125 train_loss: 1.0144207\n",
      "Epoch:  2  Batch:  1040 / 3125 train_loss: 0.92227656\n",
      "Epoch:  2  Batch:  1060 / 3125 train_loss: 1.0760382\n",
      "Epoch:  2  Batch:  1080 / 3125 train_loss: 0.9612271\n",
      "Epoch:  2  Batch:  1100 / 3125 train_loss: 0.94665337\n",
      "Epoch:  2  Batch:  1120 / 3125 train_loss: 1.0072875\n",
      "Epoch:  2  Batch:  1140 / 3125 train_loss: 1.0105027\n",
      "Epoch:  2  Batch:  1160 / 3125 train_loss: 0.9180427\n",
      "Epoch:  2  Batch:  1180 / 3125 train_loss: 0.966949\n",
      "Epoch:  2  Batch:  1200 / 3125 train_loss: 1.0589336\n",
      "Epoch:  2  Batch:  1220 / 3125 train_loss: 0.9583361\n",
      "Epoch:  2  Batch:  1240 / 3125 train_loss: 0.89637196\n",
      "Epoch:  2  Batch:  1260 / 3125 train_loss: 0.96690357\n",
      "Epoch:  2  Batch:  1280 / 3125 train_loss: 0.9804211\n",
      "Epoch:  2  Batch:  1300 / 3125 train_loss: 0.96068287\n",
      "Epoch:  2  Batch:  1320 / 3125 train_loss: 0.9676671\n",
      "Epoch:  2  Batch:  1340 / 3125 train_loss: 0.80011797\n",
      "Epoch:  2  Batch:  1360 / 3125 train_loss: 0.93357486\n",
      "Epoch:  2  Batch:  1380 / 3125 train_loss: 0.91909194\n",
      "Epoch:  2  Batch:  1400 / 3125 train_loss: 1.0542924\n",
      "Epoch:  2  Batch:  1420 / 3125 train_loss: 0.99914277\n",
      "Epoch:  2  Batch:  1440 / 3125 train_loss: 0.8516494\n",
      "Epoch:  2  Batch:  1460 / 3125 train_loss: 0.984684\n",
      "Epoch:  2  Batch:  1480 / 3125 train_loss: 0.9667481\n",
      "Epoch:  2  Batch:  1500 / 3125 train_loss: 1.0517275\n",
      "Epoch:  2  Batch:  1520 / 3125 train_loss: 0.90644026\n",
      "Epoch:  2  Batch:  1540 / 3125 train_loss: 1.0237101\n",
      "Epoch:  2  Batch:  1560 / 3125 train_loss: 0.8577895\n",
      "Epoch:  2  Batch:  1580 / 3125 train_loss: 0.9991845\n",
      "Epoch:  2  Batch:  1600 / 3125 train_loss: 0.95037615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2  Batch:  1620 / 3125 train_loss: 0.8865442\n",
      "Epoch:  2  Batch:  1640 / 3125 train_loss: 1.0653884\n",
      "Epoch:  2  Batch:  1660 / 3125 train_loss: 1.0526332\n",
      "Epoch:  2  Batch:  1680 / 3125 train_loss: 0.9955786\n",
      "Epoch:  2  Batch:  1700 / 3125 train_loss: 0.87795174\n",
      "Epoch:  2  Batch:  1720 / 3125 train_loss: 0.9439789\n",
      "Epoch:  2  Batch:  1740 / 3125 train_loss: 1.0168117\n",
      "Epoch:  2  Batch:  1760 / 3125 train_loss: 1.0655355\n",
      "Epoch:  2  Batch:  1780 / 3125 train_loss: 0.87254727\n",
      "Epoch:  2  Batch:  1800 / 3125 train_loss: 0.92124414\n",
      "Epoch:  2  Batch:  1820 / 3125 train_loss: 0.9359318\n",
      "Epoch:  2  Batch:  1840 / 3125 train_loss: 1.0379326\n",
      "Epoch:  2  Batch:  1860 / 3125 train_loss: 0.9405535\n",
      "Epoch:  2  Batch:  1880 / 3125 train_loss: 1.003304\n",
      "Epoch:  2  Batch:  1900 / 3125 train_loss: 0.8296358\n",
      "Epoch:  2  Batch:  1920 / 3125 train_loss: 0.9327144\n",
      "Epoch:  2  Batch:  1940 / 3125 train_loss: 0.84793997\n",
      "Epoch:  2  Batch:  1960 / 3125 train_loss: 0.91932684\n",
      "Epoch:  2  Batch:  1980 / 3125 train_loss: 0.914827\n",
      "Epoch:  2  Batch:  2000 / 3125 train_loss: 1.1786611\n",
      "Epoch:  2  Batch:  2020 / 3125 train_loss: 1.1423982\n",
      "Epoch:  2  Batch:  2040 / 3125 train_loss: 0.9032202\n",
      "Epoch:  2  Batch:  2060 / 3125 train_loss: 0.8258575\n",
      "Epoch:  2  Batch:  2080 / 3125 train_loss: 1.0647638\n",
      "Epoch:  2  Batch:  2100 / 3125 train_loss: 0.89237523\n",
      "Epoch:  2  Batch:  2120 / 3125 train_loss: 0.95501924\n",
      "Epoch:  2  Batch:  2140 / 3125 train_loss: 0.98593545\n",
      "Epoch:  2  Batch:  2160 / 3125 train_loss: 0.89591897\n",
      "Epoch:  2  Batch:  2180 / 3125 train_loss: 0.99085927\n",
      "Epoch:  2  Batch:  2200 / 3125 train_loss: 0.8857863\n",
      "Epoch:  2  Batch:  2220 / 3125 train_loss: 0.8984694\n",
      "Epoch:  2  Batch:  2240 / 3125 train_loss: 0.89130414\n",
      "Epoch:  2  Batch:  2260 / 3125 train_loss: 0.93033016\n",
      "Epoch:  2  Batch:  2280 / 3125 train_loss: 1.0363238\n",
      "Epoch:  2  Batch:  2300 / 3125 train_loss: 0.93478733\n",
      "Epoch:  2  Batch:  2320 / 3125 train_loss: 1.0975124\n",
      "Epoch:  2  Batch:  2340 / 3125 train_loss: 0.922954\n",
      "Epoch:  2  Batch:  2360 / 3125 train_loss: 0.9563482\n",
      "Epoch:  2  Batch:  2380 / 3125 train_loss: 0.96033967\n",
      "Epoch:  2  Batch:  2400 / 3125 train_loss: 1.0582201\n",
      "Epoch:  2  Batch:  2420 / 3125 train_loss: 0.8856462\n",
      "Epoch:  2  Batch:  2440 / 3125 train_loss: 0.9064053\n",
      "Epoch:  2  Batch:  2460 / 3125 train_loss: 0.90444016\n",
      "Epoch:  2  Batch:  2480 / 3125 train_loss: 0.9862304\n",
      "Epoch:  2  Batch:  2500 / 3125 train_loss: 0.8918965\n",
      "Epoch:  2  Batch:  2520 / 3125 train_loss: 0.906482\n",
      "Epoch:  2  Batch:  2540 / 3125 train_loss: 0.8887498\n",
      "Epoch:  2  Batch:  2560 / 3125 train_loss: 0.76395774\n",
      "Epoch:  2  Batch:  2580 / 3125 train_loss: 0.9335233\n",
      "Epoch:  2  Batch:  2600 / 3125 train_loss: 0.96686304\n",
      "Epoch:  2  Batch:  2620 / 3125 train_loss: 0.8221781\n",
      "Epoch:  2  Batch:  2640 / 3125 train_loss: 0.9612164\n",
      "Epoch:  2  Batch:  2660 / 3125 train_loss: 1.1011263\n",
      "Epoch:  2  Batch:  2680 / 3125 train_loss: 0.85984516\n",
      "Epoch:  2  Batch:  2700 / 3125 train_loss: 0.94054127\n",
      "Epoch:  2  Batch:  2720 / 3125 train_loss: 0.80590695\n",
      "Epoch:  2  Batch:  2740 / 3125 train_loss: 0.9309772\n",
      "Epoch:  2  Batch:  2760 / 3125 train_loss: 0.8787042\n",
      "Epoch:  2  Batch:  2780 / 3125 train_loss: 0.8407182\n",
      "Epoch:  2  Batch:  2800 / 3125 train_loss: 1.057354\n",
      "Epoch:  2  Batch:  2820 / 3125 train_loss: 1.0762494\n",
      "Epoch:  2  Batch:  2840 / 3125 train_loss: 0.97853476\n",
      "Epoch:  2  Batch:  2860 / 3125 train_loss: 0.84286404\n",
      "Epoch:  2  Batch:  2880 / 3125 train_loss: 0.943241\n",
      "Epoch:  2  Batch:  2900 / 3125 train_loss: 0.9437028\n",
      "Epoch:  2  Batch:  2920 / 3125 train_loss: 0.92090887\n",
      "Epoch:  2  Batch:  2940 / 3125 train_loss: 0.9373627\n",
      "Epoch:  2  Batch:  2960 / 3125 train_loss: 0.89143455\n",
      "Epoch:  2  Batch:  2980 / 3125 train_loss: 0.87411934\n",
      "Epoch:  2  Batch:  3000 / 3125 train_loss: 1.0846624\n",
      "Epoch:  2  Batch:  3020 / 3125 train_loss: 0.9933163\n",
      "Epoch:  2  Batch:  3040 / 3125 train_loss: 0.93228745\n",
      "Epoch:  2  Batch:  3060 / 3125 train_loss: 0.92636716\n",
      "Epoch:  2  Batch:  3080 / 3125 train_loss: 0.9651145\n",
      "Epoch:  2  Batch:  3100 / 3125 train_loss: 1.0574391\n",
      "Epoch:  2  Batch:  3120 / 3125 train_loss: 0.8387685\n",
      "Epoch:  2  Batch:  0 / 781 test_loss: 0.9290939\n",
      "Epoch:  2  Batch:  20 / 781 test_loss: 0.9835319\n",
      "Epoch:  2  Batch:  40 / 781 test_loss: 0.83634925\n",
      "Epoch:  2  Batch:  60 / 781 test_loss: 1.0651039\n",
      "Epoch:  2  Batch:  80 / 781 test_loss: 1.1041982\n",
      "Epoch:  2  Batch:  100 / 781 test_loss: 1.0376637\n",
      "Epoch:  2  Batch:  120 / 781 test_loss: 0.9429257\n",
      "Epoch:  2  Batch:  140 / 781 test_loss: 0.9550961\n",
      "Epoch:  2  Batch:  160 / 781 test_loss: 1.0595853\n",
      "Epoch:  2  Batch:  180 / 781 test_loss: 1.0156589\n",
      "Epoch:  2  Batch:  200 / 781 test_loss: 0.9488797\n",
      "Epoch:  2  Batch:  220 / 781 test_loss: 0.7895146\n",
      "Epoch:  2  Batch:  240 / 781 test_loss: 1.0203025\n",
      "Epoch:  2  Batch:  260 / 781 test_loss: 0.9620861\n",
      "Epoch:  2  Batch:  280 / 781 test_loss: 1.1871495\n",
      "Epoch:  2  Batch:  300 / 781 test_loss: 0.89703524\n",
      "Epoch:  2  Batch:  320 / 781 test_loss: 1.0401607\n",
      "Epoch:  2  Batch:  340 / 781 test_loss: 0.683469\n",
      "Epoch:  2  Batch:  360 / 781 test_loss: 1.0189795\n",
      "Epoch:  2  Batch:  380 / 781 test_loss: 1.0093609\n",
      "Epoch:  2  Batch:  400 / 781 test_loss: 0.875234\n",
      "Epoch:  2  Batch:  420 / 781 test_loss: 0.8090994\n",
      "Epoch:  2  Batch:  440 / 781 test_loss: 1.0225155\n",
      "Epoch:  2  Batch:  460 / 781 test_loss: 0.9146659\n",
      "Epoch:  2  Batch:  480 / 781 test_loss: 0.8932282\n",
      "Epoch:  2  Batch:  500 / 781 test_loss: 0.86699146\n",
      "Epoch:  2  Batch:  520 / 781 test_loss: 0.8592679\n",
      "Epoch:  2  Batch:  540 / 781 test_loss: 0.79718554\n",
      "Epoch:  2  Batch:  560 / 781 test_loss: 1.0193328\n",
      "Epoch:  2  Batch:  580 / 781 test_loss: 0.91814035\n",
      "Epoch:  2  Batch:  600 / 781 test_loss: 1.0010186\n",
      "Epoch:  2  Batch:  620 / 781 test_loss: 0.9355093\n",
      "Epoch:  2  Batch:  640 / 781 test_loss: 1.0293491\n",
      "Epoch:  2  Batch:  660 / 781 test_loss: 0.89250565\n",
      "Epoch:  2  Batch:  680 / 781 test_loss: 1.0927908\n",
      "Epoch:  2  Batch:  700 / 781 test_loss: 0.9325918\n",
      "Epoch:  2  Batch:  720 / 781 test_loss: 1.0879158\n",
      "Epoch:  2  Batch:  740 / 781 test_loss: 0.9317804\n",
      "Epoch:  2  Batch:  760 / 781 test_loss: 0.9156176\n",
      "Epoch:  2  Batch:  780 / 781 test_loss: 0.93143344\n",
      "Epoch:  3  Batch:  0 / 3125 train_loss: 1.0628259\n",
      "Epoch:  3  Batch:  20 / 3125 train_loss: 0.9613072\n",
      "Epoch:  3  Batch:  40 / 3125 train_loss: 0.9486681\n",
      "Epoch:  3  Batch:  60 / 3125 train_loss: 0.7809737\n",
      "Epoch:  3  Batch:  80 / 3125 train_loss: 0.88926804\n",
      "Epoch:  3  Batch:  100 / 3125 train_loss: 1.0150359\n",
      "Epoch:  3  Batch:  120 / 3125 train_loss: 1.0436321\n",
      "Epoch:  3  Batch:  140 / 3125 train_loss: 1.0087621\n",
      "Epoch:  3  Batch:  160 / 3125 train_loss: 0.782236\n",
      "Epoch:  3  Batch:  180 / 3125 train_loss: 0.93122137\n",
      "Epoch:  3  Batch:  200 / 3125 train_loss: 1.1070217\n",
      "Epoch:  3  Batch:  220 / 3125 train_loss: 0.9349704\n",
      "Epoch:  3  Batch:  240 / 3125 train_loss: 1.037215\n",
      "Epoch:  3  Batch:  260 / 3125 train_loss: 0.9606303\n",
      "Epoch:  3  Batch:  280 / 3125 train_loss: 1.0370657\n",
      "Epoch:  3  Batch:  300 / 3125 train_loss: 1.0656507\n",
      "Epoch:  3  Batch:  320 / 3125 train_loss: 1.0522884\n",
      "Epoch:  3  Batch:  340 / 3125 train_loss: 0.75991094\n",
      "Epoch:  3  Batch:  360 / 3125 train_loss: 0.8809298\n",
      "Epoch:  3  Batch:  380 / 3125 train_loss: 0.9065417\n",
      "Epoch:  3  Batch:  400 / 3125 train_loss: 0.91237634\n",
      "Epoch:  3  Batch:  420 / 3125 train_loss: 0.8522936\n",
      "Epoch:  3  Batch:  440 / 3125 train_loss: 0.86730045\n",
      "Epoch:  3  Batch:  460 / 3125 train_loss: 0.941078\n",
      "Epoch:  3  Batch:  480 / 3125 train_loss: 1.0092988\n",
      "Epoch:  3  Batch:  500 / 3125 train_loss: 0.7260425\n",
      "Epoch:  3  Batch:  520 / 3125 train_loss: 0.94795406\n",
      "Epoch:  3  Batch:  540 / 3125 train_loss: 0.8808628\n",
      "Epoch:  3  Batch:  560 / 3125 train_loss: 1.0385797\n",
      "Epoch:  3  Batch:  580 / 3125 train_loss: 0.98876923\n",
      "Epoch:  3  Batch:  600 / 3125 train_loss: 1.003284\n",
      "Epoch:  3  Batch:  620 / 3125 train_loss: 0.9305644\n",
      "Epoch:  3  Batch:  640 / 3125 train_loss: 0.95040965\n",
      "Epoch:  3  Batch:  660 / 3125 train_loss: 0.9385334\n",
      "Epoch:  3  Batch:  680 / 3125 train_loss: 1.014\n",
      "Epoch:  3  Batch:  700 / 3125 train_loss: 0.9338834\n",
      "Epoch:  3  Batch:  720 / 3125 train_loss: 0.8511207\n",
      "Epoch:  3  Batch:  740 / 3125 train_loss: 0.923998\n",
      "Epoch:  3  Batch:  760 / 3125 train_loss: 0.8232074\n",
      "Epoch:  3  Batch:  780 / 3125 train_loss: 0.92902696\n",
      "Epoch:  3  Batch:  800 / 3125 train_loss: 0.821404\n",
      "Epoch:  3  Batch:  820 / 3125 train_loss: 0.8579875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3  Batch:  840 / 3125 train_loss: 0.8393072\n",
      "Epoch:  3  Batch:  860 / 3125 train_loss: 0.874577\n",
      "Epoch:  3  Batch:  880 / 3125 train_loss: 0.90655166\n",
      "Epoch:  3  Batch:  900 / 3125 train_loss: 0.91894853\n",
      "Epoch:  3  Batch:  920 / 3125 train_loss: 0.9933686\n",
      "Epoch:  3  Batch:  940 / 3125 train_loss: 0.94604224\n",
      "Epoch:  3  Batch:  960 / 3125 train_loss: 1.0220087\n",
      "Epoch:  3  Batch:  980 / 3125 train_loss: 1.0910976\n",
      "Epoch:  3  Batch:  1000 / 3125 train_loss: 1.0051311\n",
      "Epoch:  3  Batch:  1020 / 3125 train_loss: 0.9670228\n",
      "Epoch:  3  Batch:  1040 / 3125 train_loss: 0.8521394\n",
      "Epoch:  3  Batch:  1060 / 3125 train_loss: 0.98051643\n",
      "Epoch:  3  Batch:  1080 / 3125 train_loss: 0.89200485\n",
      "Epoch:  3  Batch:  1100 / 3125 train_loss: 0.8622385\n",
      "Epoch:  3  Batch:  1120 / 3125 train_loss: 0.9549992\n",
      "Epoch:  3  Batch:  1140 / 3125 train_loss: 0.9285684\n",
      "Epoch:  3  Batch:  1160 / 3125 train_loss: 0.8418571\n",
      "Epoch:  3  Batch:  1180 / 3125 train_loss: 0.8847121\n",
      "Epoch:  3  Batch:  1200 / 3125 train_loss: 1.0228356\n",
      "Epoch:  3  Batch:  1220 / 3125 train_loss: 0.9460423\n",
      "Epoch:  3  Batch:  1240 / 3125 train_loss: 0.7969877\n",
      "Epoch:  3  Batch:  1260 / 3125 train_loss: 0.89780384\n",
      "Epoch:  3  Batch:  1280 / 3125 train_loss: 0.9219576\n",
      "Epoch:  3  Batch:  1300 / 3125 train_loss: 0.90653485\n",
      "Epoch:  3  Batch:  1320 / 3125 train_loss: 0.869478\n",
      "Epoch:  3  Batch:  1340 / 3125 train_loss: 0.76469606\n",
      "Epoch:  3  Batch:  1360 / 3125 train_loss: 0.8706711\n",
      "Epoch:  3  Batch:  1380 / 3125 train_loss: 0.8780036\n",
      "Epoch:  3  Batch:  1400 / 3125 train_loss: 0.9901564\n",
      "Epoch:  3  Batch:  1420 / 3125 train_loss: 0.9188357\n",
      "Epoch:  3  Batch:  1440 / 3125 train_loss: 0.8048799\n",
      "Epoch:  3  Batch:  1460 / 3125 train_loss: 0.9417538\n",
      "Epoch:  3  Batch:  1480 / 3125 train_loss: 0.8801657\n",
      "Epoch:  3  Batch:  1500 / 3125 train_loss: 0.960852\n",
      "Epoch:  3  Batch:  1520 / 3125 train_loss: 0.83827025\n",
      "Epoch:  3  Batch:  1540 / 3125 train_loss: 0.983554\n",
      "Epoch:  3  Batch:  1560 / 3125 train_loss: 0.7833582\n",
      "Epoch:  3  Batch:  1580 / 3125 train_loss: 0.94600934\n",
      "Epoch:  3  Batch:  1600 / 3125 train_loss: 0.89330137\n",
      "Epoch:  3  Batch:  1620 / 3125 train_loss: 0.840888\n",
      "Epoch:  3  Batch:  1640 / 3125 train_loss: 0.97927564\n",
      "Epoch:  3  Batch:  1660 / 3125 train_loss: 1.0024406\n",
      "Epoch:  3  Batch:  1680 / 3125 train_loss: 0.93027943\n",
      "Epoch:  3  Batch:  1700 / 3125 train_loss: 0.82617253\n",
      "Epoch:  3  Batch:  1720 / 3125 train_loss: 0.8768162\n",
      "Epoch:  3  Batch:  1740 / 3125 train_loss: 0.9722244\n",
      "Epoch:  3  Batch:  1760 / 3125 train_loss: 0.9624204\n",
      "Epoch:  3  Batch:  1780 / 3125 train_loss: 0.86903965\n",
      "Epoch:  3  Batch:  1800 / 3125 train_loss: 0.8600247\n",
      "Epoch:  3  Batch:  1820 / 3125 train_loss: 0.8689452\n",
      "Epoch:  3  Batch:  1840 / 3125 train_loss: 0.9875102\n",
      "Epoch:  3  Batch:  1860 / 3125 train_loss: 0.908188\n",
      "Epoch:  3  Batch:  1880 / 3125 train_loss: 0.918334\n",
      "Epoch:  3  Batch:  1900 / 3125 train_loss: 0.7991859\n",
      "Epoch:  3  Batch:  1920 / 3125 train_loss: 0.88540804\n",
      "Epoch:  3  Batch:  1940 / 3125 train_loss: 0.80894995\n",
      "Epoch:  3  Batch:  1960 / 3125 train_loss: 0.8410388\n",
      "Epoch:  3  Batch:  1980 / 3125 train_loss: 0.8722874\n",
      "Epoch:  3  Batch:  2000 / 3125 train_loss: 1.0772072\n",
      "Epoch:  3  Batch:  2020 / 3125 train_loss: 1.0677679\n",
      "Epoch:  3  Batch:  2040 / 3125 train_loss: 0.85770756\n",
      "Epoch:  3  Batch:  2060 / 3125 train_loss: 0.7865512\n",
      "Epoch:  3  Batch:  2080 / 3125 train_loss: 1.0228658\n",
      "Epoch:  3  Batch:  2100 / 3125 train_loss: 0.8278794\n",
      "Epoch:  3  Batch:  2120 / 3125 train_loss: 0.8619225\n",
      "Epoch:  3  Batch:  2140 / 3125 train_loss: 0.9327092\n",
      "Epoch:  3  Batch:  2160 / 3125 train_loss: 0.83589214\n",
      "Epoch:  3  Batch:  2180 / 3125 train_loss: 0.9399843\n",
      "Epoch:  3  Batch:  2200 / 3125 train_loss: 0.8131222\n",
      "Epoch:  3  Batch:  2220 / 3125 train_loss: 0.84196126\n",
      "Epoch:  3  Batch:  2240 / 3125 train_loss: 0.8593193\n",
      "Epoch:  3  Batch:  2260 / 3125 train_loss: 0.9039483\n",
      "Epoch:  3  Batch:  2280 / 3125 train_loss: 0.95467687\n",
      "Epoch:  3  Batch:  2300 / 3125 train_loss: 0.87605584\n",
      "Epoch:  3  Batch:  2320 / 3125 train_loss: 1.0197703\n",
      "Epoch:  3  Batch:  2340 / 3125 train_loss: 0.8661287\n",
      "Epoch:  3  Batch:  2360 / 3125 train_loss: 0.91695446\n",
      "Epoch:  3  Batch:  2380 / 3125 train_loss: 0.88599074\n",
      "Epoch:  3  Batch:  2400 / 3125 train_loss: 0.975454\n",
      "Epoch:  3  Batch:  2420 / 3125 train_loss: 0.8294772\n",
      "Epoch:  3  Batch:  2440 / 3125 train_loss: 0.8541727\n",
      "Epoch:  3  Batch:  2460 / 3125 train_loss: 0.8777472\n",
      "Epoch:  3  Batch:  2480 / 3125 train_loss: 0.95711964\n",
      "Epoch:  3  Batch:  2500 / 3125 train_loss: 0.8263718\n",
      "Epoch:  3  Batch:  2520 / 3125 train_loss: 0.8952685\n",
      "Epoch:  3  Batch:  2540 / 3125 train_loss: 0.84783363\n",
      "Epoch:  3  Batch:  2560 / 3125 train_loss: 0.705064\n",
      "Epoch:  3  Batch:  2580 / 3125 train_loss: 0.91126394\n",
      "Epoch:  3  Batch:  2600 / 3125 train_loss: 0.9073729\n",
      "Epoch:  3  Batch:  2620 / 3125 train_loss: 0.80360985\n",
      "Epoch:  3  Batch:  2640 / 3125 train_loss: 0.91018766\n",
      "Epoch:  3  Batch:  2660 / 3125 train_loss: 1.0426786\n",
      "Epoch:  3  Batch:  2680 / 3125 train_loss: 0.81096685\n",
      "Epoch:  3  Batch:  2700 / 3125 train_loss: 0.8996172\n",
      "Epoch:  3  Batch:  2720 / 3125 train_loss: 0.7547069\n",
      "Epoch:  3  Batch:  2740 / 3125 train_loss: 0.8927119\n",
      "Epoch:  3  Batch:  2760 / 3125 train_loss: 0.8140367\n",
      "Epoch:  3  Batch:  2780 / 3125 train_loss: 0.850191\n",
      "Epoch:  3  Batch:  2800 / 3125 train_loss: 1.0302168\n",
      "Epoch:  3  Batch:  2820 / 3125 train_loss: 1.0631555\n",
      "Epoch:  3  Batch:  2840 / 3125 train_loss: 0.90937525\n",
      "Epoch:  3  Batch:  2860 / 3125 train_loss: 0.79546326\n",
      "Epoch:  3  Batch:  2880 / 3125 train_loss: 0.877414\n",
      "Epoch:  3  Batch:  2900 / 3125 train_loss: 0.9079858\n",
      "Epoch:  3  Batch:  2920 / 3125 train_loss: 0.8681147\n",
      "Epoch:  3  Batch:  2940 / 3125 train_loss: 0.8899251\n",
      "Epoch:  3  Batch:  2960 / 3125 train_loss: 0.8540056\n",
      "Epoch:  3  Batch:  2980 / 3125 train_loss: 0.8399542\n",
      "Epoch:  3  Batch:  3000 / 3125 train_loss: 1.0344325\n",
      "Epoch:  3  Batch:  3020 / 3125 train_loss: 0.9903047\n",
      "Epoch:  3  Batch:  3040 / 3125 train_loss: 0.91612744\n",
      "Epoch:  3  Batch:  3060 / 3125 train_loss: 0.83814776\n",
      "Epoch:  3  Batch:  3080 / 3125 train_loss: 0.98159206\n",
      "Epoch:  3  Batch:  3100 / 3125 train_loss: 1.0309703\n",
      "Epoch:  3  Batch:  3120 / 3125 train_loss: 0.8226639\n",
      "Epoch:  3  Batch:  0 / 781 test_loss: 0.88087225\n",
      "Epoch:  3  Batch:  20 / 781 test_loss: 0.97310007\n",
      "Epoch:  3  Batch:  40 / 781 test_loss: 0.8207305\n",
      "Epoch:  3  Batch:  60 / 781 test_loss: 1.0119483\n",
      "Epoch:  3  Batch:  80 / 781 test_loss: 1.0028942\n",
      "Epoch:  3  Batch:  100 / 781 test_loss: 1.024502\n",
      "Epoch:  3  Batch:  120 / 781 test_loss: 0.8836367\n",
      "Epoch:  3  Batch:  140 / 781 test_loss: 0.9208547\n",
      "Epoch:  3  Batch:  160 / 781 test_loss: 1.0088432\n",
      "Epoch:  3  Batch:  180 / 781 test_loss: 0.9738611\n",
      "Epoch:  3  Batch:  200 / 781 test_loss: 0.9388757\n",
      "Epoch:  3  Batch:  220 / 781 test_loss: 0.7556359\n",
      "Epoch:  3  Batch:  240 / 781 test_loss: 1.013861\n",
      "Epoch:  3  Batch:  260 / 781 test_loss: 0.9184983\n",
      "Epoch:  3  Batch:  280 / 781 test_loss: 1.1191514\n",
      "Epoch:  3  Batch:  300 / 781 test_loss: 0.842343\n",
      "Epoch:  3  Batch:  320 / 781 test_loss: 0.9921178\n",
      "Epoch:  3  Batch:  340 / 781 test_loss: 0.64349794\n",
      "Epoch:  3  Batch:  360 / 781 test_loss: 0.9835553\n",
      "Epoch:  3  Batch:  380 / 781 test_loss: 0.97921747\n",
      "Epoch:  3  Batch:  400 / 781 test_loss: 0.8377098\n",
      "Epoch:  3  Batch:  420 / 781 test_loss: 0.75682044\n",
      "Epoch:  3  Batch:  440 / 781 test_loss: 0.98282707\n",
      "Epoch:  3  Batch:  460 / 781 test_loss: 0.88509107\n",
      "Epoch:  3  Batch:  480 / 781 test_loss: 0.8133457\n",
      "Epoch:  3  Batch:  500 / 781 test_loss: 0.8277351\n",
      "Epoch:  3  Batch:  520 / 781 test_loss: 0.8376862\n",
      "Epoch:  3  Batch:  540 / 781 test_loss: 0.7525873\n",
      "Epoch:  3  Batch:  560 / 781 test_loss: 0.93165886\n",
      "Epoch:  3  Batch:  580 / 781 test_loss: 0.8681729\n",
      "Epoch:  3  Batch:  600 / 781 test_loss: 0.9517844\n",
      "Epoch:  3  Batch:  620 / 781 test_loss: 0.9422301\n",
      "Epoch:  3  Batch:  640 / 781 test_loss: 0.993356\n",
      "Epoch:  3  Batch:  660 / 781 test_loss: 0.8515991\n",
      "Epoch:  3  Batch:  680 / 781 test_loss: 1.0223194\n",
      "Epoch:  3  Batch:  700 / 781 test_loss: 0.88423574\n",
      "Epoch:  3  Batch:  720 / 781 test_loss: 1.0570726\n",
      "Epoch:  3  Batch:  740 / 781 test_loss: 0.9113395\n",
      "Epoch:  3  Batch:  760 / 781 test_loss: 0.8652257\n",
      "Epoch:  3  Batch:  780 / 781 test_loss: 0.86137766\n",
      "Epoch:  4  Batch:  0 / 3125 train_loss: 1.0287492\n",
      "Epoch:  4  Batch:  20 / 3125 train_loss: 0.8925951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4  Batch:  40 / 3125 train_loss: 0.9308213\n",
      "Epoch:  4  Batch:  60 / 3125 train_loss: 0.74592525\n",
      "Epoch:  4  Batch:  80 / 3125 train_loss: 0.85769874\n",
      "Epoch:  4  Batch:  100 / 3125 train_loss: 0.9678439\n",
      "Epoch:  4  Batch:  120 / 3125 train_loss: 0.9761895\n",
      "Epoch:  4  Batch:  140 / 3125 train_loss: 0.9466002\n",
      "Epoch:  4  Batch:  160 / 3125 train_loss: 0.79136646\n",
      "Epoch:  4  Batch:  180 / 3125 train_loss: 0.89343345\n",
      "Epoch:  4  Batch:  200 / 3125 train_loss: 1.0637234\n",
      "Epoch:  4  Batch:  220 / 3125 train_loss: 0.90678215\n",
      "Epoch:  4  Batch:  240 / 3125 train_loss: 0.98828775\n",
      "Epoch:  4  Batch:  260 / 3125 train_loss: 0.9410648\n",
      "Epoch:  4  Batch:  280 / 3125 train_loss: 1.0061865\n",
      "Epoch:  4  Batch:  300 / 3125 train_loss: 1.0150104\n",
      "Epoch:  4  Batch:  320 / 3125 train_loss: 0.98809695\n",
      "Epoch:  4  Batch:  340 / 3125 train_loss: 0.7316575\n",
      "Epoch:  4  Batch:  360 / 3125 train_loss: 0.8425344\n",
      "Epoch:  4  Batch:  380 / 3125 train_loss: 0.8569876\n",
      "Epoch:  4  Batch:  400 / 3125 train_loss: 0.8668929\n",
      "Epoch:  4  Batch:  420 / 3125 train_loss: 0.8256947\n",
      "Epoch:  4  Batch:  440 / 3125 train_loss: 0.82524526\n",
      "Epoch:  4  Batch:  460 / 3125 train_loss: 0.8966998\n",
      "Epoch:  4  Batch:  480 / 3125 train_loss: 0.94357306\n",
      "Epoch:  4  Batch:  500 / 3125 train_loss: 0.68567044\n",
      "Epoch:  4  Batch:  520 / 3125 train_loss: 0.92993593\n",
      "Epoch:  4  Batch:  540 / 3125 train_loss: 0.8315587\n",
      "Epoch:  4  Batch:  560 / 3125 train_loss: 1.0352732\n",
      "Epoch:  4  Batch:  580 / 3125 train_loss: 0.96597373\n",
      "Epoch:  4  Batch:  600 / 3125 train_loss: 0.9591117\n",
      "Epoch:  4  Batch:  620 / 3125 train_loss: 0.89140195\n",
      "Epoch:  4  Batch:  640 / 3125 train_loss: 0.87779456\n",
      "Epoch:  4  Batch:  660 / 3125 train_loss: 0.8860296\n",
      "Epoch:  4  Batch:  680 / 3125 train_loss: 0.9868763\n",
      "Epoch:  4  Batch:  700 / 3125 train_loss: 0.90399075\n",
      "Epoch:  4  Batch:  720 / 3125 train_loss: 0.78283083\n",
      "Epoch:  4  Batch:  740 / 3125 train_loss: 0.8492138\n",
      "Epoch:  4  Batch:  760 / 3125 train_loss: 0.80846703\n",
      "Epoch:  4  Batch:  780 / 3125 train_loss: 0.87869126\n",
      "Epoch:  4  Batch:  800 / 3125 train_loss: 0.77225447\n",
      "Epoch:  4  Batch:  820 / 3125 train_loss: 0.8347634\n",
      "Epoch:  4  Batch:  840 / 3125 train_loss: 0.8171588\n",
      "Epoch:  4  Batch:  860 / 3125 train_loss: 0.8481417\n",
      "Epoch:  4  Batch:  880 / 3125 train_loss: 0.8379416\n",
      "Epoch:  4  Batch:  900 / 3125 train_loss: 0.89186084\n",
      "Epoch:  4  Batch:  920 / 3125 train_loss: 0.9673302\n",
      "Epoch:  4  Batch:  940 / 3125 train_loss: 0.9123865\n",
      "Epoch:  4  Batch:  960 / 3125 train_loss: 0.9787618\n",
      "Epoch:  4  Batch:  980 / 3125 train_loss: 0.9993826\n",
      "Epoch:  4  Batch:  1000 / 3125 train_loss: 0.9530146\n",
      "Epoch:  4  Batch:  1020 / 3125 train_loss: 0.8994513\n",
      "Epoch:  4  Batch:  1040 / 3125 train_loss: 0.8348396\n",
      "Epoch:  4  Batch:  1060 / 3125 train_loss: 0.9295165\n",
      "Epoch:  4  Batch:  1080 / 3125 train_loss: 0.87948304\n",
      "Epoch:  4  Batch:  1100 / 3125 train_loss: 0.83304393\n",
      "Epoch:  4  Batch:  1120 / 3125 train_loss: 0.88752955\n",
      "Epoch:  4  Batch:  1140 / 3125 train_loss: 0.86492383\n",
      "Epoch:  4  Batch:  1160 / 3125 train_loss: 0.8084669\n",
      "Epoch:  4  Batch:  1180 / 3125 train_loss: 0.83023703\n",
      "Epoch:  4  Batch:  1200 / 3125 train_loss: 0.9713601\n",
      "Epoch:  4  Batch:  1220 / 3125 train_loss: 0.9499139\n",
      "Epoch:  4  Batch:  1240 / 3125 train_loss: 0.77799594\n",
      "Epoch:  4  Batch:  1260 / 3125 train_loss: 0.8773674\n",
      "Epoch:  4  Batch:  1280 / 3125 train_loss: 0.9006616\n",
      "Epoch:  4  Batch:  1300 / 3125 train_loss: 0.84752\n",
      "Epoch:  4  Batch:  1320 / 3125 train_loss: 0.8480311\n",
      "Epoch:  4  Batch:  1340 / 3125 train_loss: 0.73531795\n",
      "Epoch:  4  Batch:  1360 / 3125 train_loss: 0.80510163\n",
      "Epoch:  4  Batch:  1380 / 3125 train_loss: 0.84403205\n",
      "Epoch:  4  Batch:  1400 / 3125 train_loss: 0.9484761\n",
      "Epoch:  4  Batch:  1420 / 3125 train_loss: 0.86604434\n",
      "Epoch:  4  Batch:  1440 / 3125 train_loss: 0.76551235\n",
      "Epoch:  4  Batch:  1460 / 3125 train_loss: 0.9011919\n",
      "Epoch:  4  Batch:  1480 / 3125 train_loss: 0.8428403\n",
      "Epoch:  4  Batch:  1500 / 3125 train_loss: 0.9221683\n",
      "Epoch:  4  Batch:  1520 / 3125 train_loss: 0.80055267\n",
      "Epoch:  4  Batch:  1540 / 3125 train_loss: 0.94688165\n",
      "Epoch:  4  Batch:  1560 / 3125 train_loss: 0.7626765\n",
      "Epoch:  4  Batch:  1580 / 3125 train_loss: 0.9374299\n",
      "Epoch:  4  Batch:  1600 / 3125 train_loss: 0.83935565\n",
      "Epoch:  4  Batch:  1620 / 3125 train_loss: 0.8009627\n",
      "Epoch:  4  Batch:  1640 / 3125 train_loss: 0.9624908\n",
      "Epoch:  4  Batch:  1660 / 3125 train_loss: 0.99165964\n",
      "Epoch:  4  Batch:  1680 / 3125 train_loss: 0.9032352\n",
      "Epoch:  4  Batch:  1700 / 3125 train_loss: 0.80225885\n",
      "Epoch:  4  Batch:  1720 / 3125 train_loss: 0.8708318\n",
      "Epoch:  4  Batch:  1740 / 3125 train_loss: 0.9571804\n",
      "Epoch:  4  Batch:  1760 / 3125 train_loss: 0.9133396\n",
      "Epoch:  4  Batch:  1780 / 3125 train_loss: 0.8496252\n",
      "Epoch:  4  Batch:  1800 / 3125 train_loss: 0.84342337\n",
      "Epoch:  4  Batch:  1820 / 3125 train_loss: 0.8391893\n",
      "Epoch:  4  Batch:  1840 / 3125 train_loss: 0.93788826\n",
      "Epoch:  4  Batch:  1860 / 3125 train_loss: 0.88335097\n",
      "Epoch:  4  Batch:  1880 / 3125 train_loss: 0.8613108\n",
      "Epoch:  4  Batch:  1900 / 3125 train_loss: 0.76512337\n",
      "Epoch:  4  Batch:  1920 / 3125 train_loss: 0.8366542\n",
      "Epoch:  4  Batch:  1940 / 3125 train_loss: 0.77585477\n",
      "Epoch:  4  Batch:  1960 / 3125 train_loss: 0.76687914\n",
      "Epoch:  4  Batch:  1980 / 3125 train_loss: 0.85292864\n",
      "Epoch:  4  Batch:  2000 / 3125 train_loss: 1.0301859\n",
      "Epoch:  4  Batch:  2020 / 3125 train_loss: 1.0140774\n",
      "Epoch:  4  Batch:  2040 / 3125 train_loss: 0.8359244\n",
      "Epoch:  4  Batch:  2060 / 3125 train_loss: 0.7965763\n",
      "Epoch:  4  Batch:  2080 / 3125 train_loss: 0.9922302\n",
      "Epoch:  4  Batch:  2100 / 3125 train_loss: 0.81325644\n",
      "Epoch:  4  Batch:  2120 / 3125 train_loss: 0.8468944\n",
      "Epoch:  4  Batch:  2140 / 3125 train_loss: 0.8923294\n",
      "Epoch:  4  Batch:  2160 / 3125 train_loss: 0.80295074\n",
      "Epoch:  4  Batch:  2180 / 3125 train_loss: 0.9258011\n",
      "Epoch:  4  Batch:  2200 / 3125 train_loss: 0.79001963\n",
      "Epoch:  4  Batch:  2220 / 3125 train_loss: 0.82355183\n",
      "Epoch:  4  Batch:  2240 / 3125 train_loss: 0.84981954\n",
      "Epoch:  4  Batch:  2260 / 3125 train_loss: 0.879992\n",
      "Epoch:  4  Batch:  2280 / 3125 train_loss: 0.9072356\n",
      "Epoch:  4  Batch:  2300 / 3125 train_loss: 0.8508508\n",
      "Epoch:  4  Batch:  2320 / 3125 train_loss: 0.9868556\n",
      "Epoch:  4  Batch:  2340 / 3125 train_loss: 0.8442705\n",
      "Epoch:  4  Batch:  2360 / 3125 train_loss: 0.8840181\n",
      "Epoch:  4  Batch:  2380 / 3125 train_loss: 0.85697734\n",
      "Epoch:  4  Batch:  2400 / 3125 train_loss: 0.9347183\n",
      "Epoch:  4  Batch:  2420 / 3125 train_loss: 0.8029894\n",
      "Epoch:  4  Batch:  2440 / 3125 train_loss: 0.81600904\n",
      "Epoch:  4  Batch:  2460 / 3125 train_loss: 0.8509753\n",
      "Epoch:  4  Batch:  2480 / 3125 train_loss: 0.93167394\n",
      "Epoch:  4  Batch:  2500 / 3125 train_loss: 0.81097496\n",
      "Epoch:  4  Batch:  2520 / 3125 train_loss: 0.9010903\n",
      "Epoch:  4  Batch:  2540 / 3125 train_loss: 0.8227861\n",
      "Epoch:  4  Batch:  2560 / 3125 train_loss: 0.67975396\n",
      "Epoch:  4  Batch:  2580 / 3125 train_loss: 0.8971136\n",
      "Epoch:  4  Batch:  2600 / 3125 train_loss: 0.88149357\n",
      "Epoch:  4  Batch:  2620 / 3125 train_loss: 0.76383096\n",
      "Epoch:  4  Batch:  2640 / 3125 train_loss: 0.85197985\n",
      "Epoch:  4  Batch:  2660 / 3125 train_loss: 1.0409465\n",
      "Epoch:  4  Batch:  2680 / 3125 train_loss: 0.813416\n",
      "Epoch:  4  Batch:  2700 / 3125 train_loss: 0.8911412\n",
      "Epoch:  4  Batch:  2720 / 3125 train_loss: 0.72780454\n",
      "Epoch:  4  Batch:  2740 / 3125 train_loss: 0.89146346\n",
      "Epoch:  4  Batch:  2760 / 3125 train_loss: 0.7710117\n",
      "Epoch:  4  Batch:  2780 / 3125 train_loss: 0.81496096\n",
      "Epoch:  4  Batch:  2800 / 3125 train_loss: 0.99776053\n",
      "Epoch:  4  Batch:  2820 / 3125 train_loss: 1.0247465\n",
      "Epoch:  4  Batch:  2840 / 3125 train_loss: 0.88257444\n",
      "Epoch:  4  Batch:  2860 / 3125 train_loss: 0.77882254\n",
      "Epoch:  4  Batch:  2880 / 3125 train_loss: 0.86423403\n",
      "Epoch:  4  Batch:  2900 / 3125 train_loss: 0.88868713\n",
      "Epoch:  4  Batch:  2920 / 3125 train_loss: 0.8477356\n",
      "Epoch:  4  Batch:  2940 / 3125 train_loss: 0.88086766\n",
      "Epoch:  4  Batch:  2960 / 3125 train_loss: 0.8464798\n",
      "Epoch:  4  Batch:  2980 / 3125 train_loss: 0.78561854\n",
      "Epoch:  4  Batch:  3000 / 3125 train_loss: 1.0017977\n",
      "Epoch:  4  Batch:  3020 / 3125 train_loss: 0.968153\n",
      "Epoch:  4  Batch:  3040 / 3125 train_loss: 0.8878288\n",
      "Epoch:  4  Batch:  3060 / 3125 train_loss: 0.80196685\n",
      "Epoch:  4  Batch:  3080 / 3125 train_loss: 0.9556543\n",
      "Epoch:  4  Batch:  3100 / 3125 train_loss: 1.0194106\n",
      "Epoch:  4  Batch:  3120 / 3125 train_loss: 0.8206629\n",
      "Epoch:  4  Batch:  0 / 781 test_loss: 0.86855423\n",
      "Epoch:  4  Batch:  20 / 781 test_loss: 0.9356517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4  Batch:  40 / 781 test_loss: 0.81374997\n",
      "Epoch:  4  Batch:  60 / 781 test_loss: 0.96828514\n",
      "Epoch:  4  Batch:  80 / 781 test_loss: 0.952919\n",
      "Epoch:  4  Batch:  100 / 781 test_loss: 1.0081987\n",
      "Epoch:  4  Batch:  120 / 781 test_loss: 0.84494144\n",
      "Epoch:  4  Batch:  140 / 781 test_loss: 0.88940644\n",
      "Epoch:  4  Batch:  160 / 781 test_loss: 1.0214047\n",
      "Epoch:  4  Batch:  180 / 781 test_loss: 0.9649385\n",
      "Epoch:  4  Batch:  200 / 781 test_loss: 0.9160206\n",
      "Epoch:  4  Batch:  220 / 781 test_loss: 0.7368808\n",
      "Epoch:  4  Batch:  240 / 781 test_loss: 0.9808645\n",
      "Epoch:  4  Batch:  260 / 781 test_loss: 0.8798727\n",
      "Epoch:  4  Batch:  280 / 781 test_loss: 1.0855305\n",
      "Epoch:  4  Batch:  300 / 781 test_loss: 0.8139478\n",
      "Epoch:  4  Batch:  320 / 781 test_loss: 0.9338336\n",
      "Epoch:  4  Batch:  340 / 781 test_loss: 0.6500989\n",
      "Epoch:  4  Batch:  360 / 781 test_loss: 0.94650185\n",
      "Epoch:  4  Batch:  380 / 781 test_loss: 0.9499921\n",
      "Epoch:  4  Batch:  400 / 781 test_loss: 0.81901836\n",
      "Epoch:  4  Batch:  420 / 781 test_loss: 0.73479974\n",
      "Epoch:  4  Batch:  440 / 781 test_loss: 0.95551056\n",
      "Epoch:  4  Batch:  460 / 781 test_loss: 0.8744242\n",
      "Epoch:  4  Batch:  480 / 781 test_loss: 0.7723937\n",
      "Epoch:  4  Batch:  500 / 781 test_loss: 0.79987955\n",
      "Epoch:  4  Batch:  520 / 781 test_loss: 0.80721116\n",
      "Epoch:  4  Batch:  540 / 781 test_loss: 0.7631289\n",
      "Epoch:  4  Batch:  560 / 781 test_loss: 0.9036241\n",
      "Epoch:  4  Batch:  580 / 781 test_loss: 0.8469218\n",
      "Epoch:  4  Batch:  600 / 781 test_loss: 0.9058749\n",
      "Epoch:  4  Batch:  620 / 781 test_loss: 0.90368164\n",
      "Epoch:  4  Batch:  640 / 781 test_loss: 1.0033801\n",
      "Epoch:  4  Batch:  660 / 781 test_loss: 0.84181225\n",
      "Epoch:  4  Batch:  680 / 781 test_loss: 0.9939576\n",
      "Epoch:  4  Batch:  700 / 781 test_loss: 0.8755065\n",
      "Epoch:  4  Batch:  720 / 781 test_loss: 1.00667\n",
      "Epoch:  4  Batch:  740 / 781 test_loss: 0.88894993\n",
      "Epoch:  4  Batch:  760 / 781 test_loss: 0.8460164\n",
      "Epoch:  4  Batch:  780 / 781 test_loss: 0.83424604\n"
     ]
    }
   ],
   "source": [
    "model_file = \"models/final_movies_recommendations_model\"\n",
    "\n",
    "losses = {'train':[], 'test':[]}\n",
    "\n",
    "\n",
    "# Number of Epochs\n",
    "num_epochs = 5\n",
    "# Batch Size\n",
    "batch_size = 256\n",
    "dropout_keep_prob = 0.5\n",
    "\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 20\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch_index in range(num_epochs):\n",
    "        train_X,test_X, train_y, test_y = train_test_split(X_all, y_all, test_size = 0.2, random_state = 0)  \n",
    "        \n",
    "        for batch_index in range(len(train_X) // batch_size):\n",
    "            \n",
    "            start_index = batch_index * batch_size\n",
    "            end_index = min((batch_index+1)*batch_size , len(train_X))\n",
    "            x = train_X[start_index:end_index]\n",
    "            y = train_y[start_index:end_index]\n",
    "\n",
    "            genres = np.zeros([batch_size, 18])\n",
    "            for i in range(batch_size):\n",
    "                genres[i] = x.take(6,1)[i]\n",
    "\n",
    "            titles = np.zeros([batch_size, movie_title_len])\n",
    "            for i in range(batch_size):\n",
    "                titles[i] = x.take(5,1)[i]\n",
    "\n",
    "            feed = {\n",
    "                model.user_id: np.reshape(x.take(0,1), [batch_size, 1]),\n",
    "                model.user_gender: np.reshape(x.take(2,1), [batch_size, 1]),\n",
    "                model.user_age: np.reshape(x.take(3,1), [batch_size, 1]),\n",
    "                model.user_job: np.reshape(x.take(4,1), [batch_size, 1]),\n",
    "                model.movie_id: np.reshape(x.take(1,1), [batch_size, 1]),\n",
    "                model.movie_genres: genres,  \n",
    "                model.movie_titles: titles,  \n",
    "                model.ratings: np.reshape(y, [batch_size, 1]),\n",
    "                model.dropout_keep_prob: dropout_keep_prob\n",
    "                }\n",
    "\n",
    "            step, train_loss, _ = sess.run([model.global_step, model.loss, model.train_op], feed)  #cost\n",
    "            losses['train'].append(train_loss)\n",
    "\n",
    "            if(batch_index % show_every_n_batches == 0):\n",
    "                print('Epoch: ',epoch_index,' Batch: ',batch_index,\"/\",len(train_X)//batch_size,'train_loss:',train_loss)\n",
    "                \n",
    "        for batch_index in range(len(test_X) // batch_size):\n",
    "            \n",
    "            start_index = batch_index * batch_size\n",
    "            end_index = min((batch_index+1)*batch_size , len(test_X))\n",
    "            x = test_X[start_index:end_index]\n",
    "            y = test_y[start_index:end_index]\n",
    "\n",
    "            genres = np.zeros([batch_size, 18])\n",
    "            for i in range(batch_size):\n",
    "                genres[i] = x.take(6,1)[i]\n",
    "\n",
    "            titles = np.zeros([batch_size, movie_title_len])\n",
    "            for i in range(batch_size):\n",
    "                titles[i] = x.take(5,1)[i]\n",
    "\n",
    "            feed = {\n",
    "                model.user_id: np.reshape(x.take(0,1), [batch_size, 1]),\n",
    "                model.user_gender: np.reshape(x.take(2,1), [batch_size, 1]),\n",
    "                model.user_age: np.reshape(x.take(3,1), [batch_size, 1]),\n",
    "                model.user_job: np.reshape(x.take(4,1), [batch_size, 1]),\n",
    "                model.movie_id: np.reshape(x.take(1,1), [batch_size, 1]),\n",
    "                model.movie_genres: genres,  \n",
    "                model.movie_titles: titles,  \n",
    "                model.ratings: np.reshape(y, [batch_size, 1]),\n",
    "                model.dropout_keep_prob: dropout_keep_prob\n",
    "                }\n",
    "\n",
    "            step, test_loss = sess.run([model.global_step, model.loss], feed)  #cost\n",
    "            losses['test'].append(test_loss)\n",
    "\n",
    "            if(batch_index % show_every_n_batches == 0):\n",
    "                print('Epoch: ',epoch_index,' Batch: ',batch_index,\"/\",len(test_X)//batch_size,'test_loss:',test_loss)\n",
    "    \n",
    "    model.saver.save(sess, model_file)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses['train'], label='Training loss')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses['test'], label='Test loss')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting rating given user and moive id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_map = {val[0]:i for i, val in enumerate(movies.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_movie(user_id_val, movie_id_val):\n",
    "    \n",
    "    with tf.Session() as sess:  \n",
    "        model.saver.restore(sess, model_file)\n",
    "        \n",
    "        genres = np.zeros([1, 18])\n",
    "        genres[0] = movies.values[movie_id_map[movie_id_val]][2]\n",
    "    \n",
    "        titles = np.zeros([1, movie_title_len])\n",
    "        titles[0] = movies.values[movie_id_map[movie_id_val]][1]\n",
    "    \n",
    "        feed = {\n",
    "              model.user_id: np.reshape(users.values[user_id_val-1][0], [1, 1]),\n",
    "              model.user_gender: np.reshape(users.values[user_id_val-1][1], [1, 1]),\n",
    "              model.user_age: np.reshape(users.values[user_id_val-1][2], [1, 1]),\n",
    "              model.user_job: np.reshape(users.values[user_id_val-1][3], [1, 1]),\n",
    "              model.movie_id: np.reshape(movies.values[movie_id_map[movie_id_val]][0], [1, 1]),\n",
    "              model.movie_genres: genres,  \n",
    "              model.movie_titles: titles,  \n",
    "              model.dropout_keep_prob: 1\n",
    "        }\n",
    "    \n",
    "        # Get Prediction\n",
    "        pred_rating= sess.run([model.pred_ratings], feed)  \n",
    "    \n",
    "        return (pred_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/final_movies_recommendations_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[4.5714545]], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_movie(2, 1193)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Users and Movies Feature Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/final_movies_recommendations_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6040, 200)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_feature_matrix = []\n",
    "\n",
    "with tf.Session() as sess:  \n",
    "    model.saver.restore(sess, model_file)\n",
    "\n",
    "    for user in users.values:\n",
    "        \n",
    "        feed = {\n",
    "              model.user_id: np.reshape(user[0], [1, 1]),\n",
    "              model.user_gender: np.reshape(user[1], [1, 1]),\n",
    "              model.user_age: np.reshape(user[2], [1, 1]),\n",
    "              model.user_job: np.reshape(user[3], [1, 1]), \n",
    "              model.dropout_keep_prob: 1\n",
    "        }\n",
    "        \n",
    "        user_feature = sess.run([model.user_combine_layer_flat], feed)\n",
    "        users_feature_matrix.append(user_feature)\n",
    "\n",
    "users_feature_matrix = np.squeeze(np.array(users_feature_matrix))\n",
    "users_feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moives Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/final_movies_recommendations_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3883, 200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_feature_matrix = []\n",
    "\n",
    "with tf.Session() as sess:  \n",
    "    model.saver.restore(sess, model_file)\n",
    "\n",
    "    for movie in movies.values:\n",
    "        \n",
    "        genres = np.zeros([1, 18])\n",
    "        genres[0] = movie[2]\n",
    "    \n",
    "        titles = np.zeros([1, movie_title_len])\n",
    "        titles[0] = movie[1]\n",
    "        \n",
    "        feed = {\n",
    "              model.movie_id: np.reshape(movie[0], [1, 1]),\n",
    "              model.movie_genres: genres,  \n",
    "              model.movie_titles: titles,  \n",
    "              model.dropout_keep_prob: 1\n",
    "        }\n",
    "        \n",
    "        movie_feature = sess.run([model.movie_combine_layer_flat], feed)\n",
    "        movies_feature_matrix.append(movie_feature)\n",
    "\n",
    "movies_feature_matrix = np.squeeze(np.array(movies_feature_matrix))\n",
    "movies_feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Top k movies that user may favorite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_favorite_movie(user_id, k = 10):\n",
    "    \n",
    "    user_feature = np.array(users_feature_matrix[user_id - 1]).reshape([1, 200])\n",
    "    similarity = user_feature @ movies_feature_matrix.T\n",
    "    best_movies_id = np.argsort(similarity)\n",
    "    best_movies_id = best_movies_id[0][::-1][:2*k+1]\n",
    "    random.shuffle(best_movies_id)\n",
    "    return best_movies_id[:k+1]\n",
    "\n",
    "def print_movies_by_id(movies_id):\n",
    "    print(\"\\nOur Recommendation:\")\n",
    "    print(\"-------------------\")\n",
    "    for movie_id in movies_id[1:]:\n",
    "        movie = movies_old.iloc[movie_id]\n",
    "        title = movie['title']\n",
    "        genres = movie['genres']\n",
    "        print(\"[\" + str(movie_id) + \"] title : \" +title) \n",
    "        print(\"genres: \" +genres)\n",
    "        print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our Recommendation:\n",
      "-------------------\n",
      "[600] title : Criminals (1996)\n",
      "genres: Documentary\n",
      "-------------------\n",
      "[847] title : Godfather, The (1972)\n",
      "genres: Action|Crime|Drama\n",
      "-------------------\n",
      "[1172] title : Thin Blue Line, The (1988)\n",
      "genres: Documentary\n",
      "-------------------\n",
      "[523] title : Schindler's List (1993)\n",
      "genres: Drama|War\n",
      "-------------------\n",
      "[711] title : Wallace & Gromit: The Best of Aardman Animation (1996)\n",
      "genres: Animation\n",
      "-------------------\n",
      "[1132] title : Wrong Trousers, The (1993)\n",
      "genres: Animation|Comedy\n",
      "-------------------\n",
      "[780] title : An Unforgettable Summer (1994)\n",
      "genres: Drama\n",
      "-------------------\n",
      "[315] title : Shawshank Redemption, The (1994)\n",
      "genres: Drama\n",
      "-------------------\n",
      "[2130] title : Phoenix (1998)\n",
      "genres: Crime|Drama\n",
      "-------------------\n",
      "[1215] title : Sting, The (1973)\n",
      "genres: Comedy|Crime\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "print_movies_by_id(top_k_favorite_movie(19, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Other Movies you might like if you watched this movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_movies_you_might_like(movie_id, k = 10):\n",
    "    \n",
    "    watched_movie = movies_old.iloc[movie_id]\n",
    "    print(\"======================================\")\n",
    "    print(\"The movie you watched: \" + watched_movie['title'])\n",
    "    print(\"======================================\")\n",
    "    \n",
    "    movie_feature = np.array(movies_feature_matrix[movie_id_map[movie_id]]).reshape([1,200])\n",
    "    users_similarity = movie_feature @ users_feature_matrix.T\n",
    "    also_liked_user_id = np.argsort(users_similarity)\n",
    "    also_liked_user_id = also_liked_user_id[0][::-1][:k]\n",
    "    \n",
    "    common_movies_id = {}\n",
    "    for user_id in also_liked_user_id:\n",
    "        favorite_movies_id = top_k_favorite_movie(user_id, 10)\n",
    "        for movie_id in favorite_movies_id:\n",
    "            if(movie_id in common_movies_id):\n",
    "                common_movies_id[movie_id] += 1\n",
    "            else:\n",
    "                common_movies_id[movie_id] = 1\n",
    "    \n",
    "    sorted_common_movies_id = sorted(common_movies_id.items(), key = lambda x : (x[1], x[0]),\n",
    "                                    reverse = True)\n",
    "    other_movies_id = []\n",
    "    for movie_id in sorted_common_movies_id:\n",
    "        if(len(other_movies_id) < 2*k):\n",
    "            other_movies_id.append(movie_id[0])\n",
    "        \n",
    "    random.shuffle(other_movies_id)    \n",
    "    return other_movies_id[:k+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "The movie you watched: Waiting to Exhale (1995)\n",
      "======================================\n",
      "\n",
      "Our Recommendation:\n",
      "-------------------\n",
      "[711] title : Wallace & Gromit: The Best of Aardman Animation (1996)\n",
      "genres: Animation\n",
      "-------------------\n",
      "[847] title : Godfather, The (1972)\n",
      "genres: Action|Crime|Drama\n",
      "-------------------\n",
      "[2439] title : Breaks, The (1999)\n",
      "genres: Drama\n",
      "-------------------\n",
      "[1194] title : Third Man, The (1949)\n",
      "genres: Mystery|Thriller\n",
      "-------------------\n",
      "[2282] title : Nights of Cabiria (Le Notti di Cabiria) (1957)\n",
      "genres: Drama\n",
      "-------------------\n",
      "[1162] title : Paths of Glory (1957)\n",
      "genres: Drama|War\n",
      "-------------------\n",
      "[900] title : Casablanca (1942)\n",
      "genres: Drama|Romance|War\n",
      "-------------------\n",
      "[1264] title : Big Sleep, The (1946)\n",
      "genres: Film-Noir|Mystery\n",
      "-------------------\n",
      "[2130] title : Phoenix (1998)\n",
      "genres: Crime|Drama\n",
      "-------------------\n",
      "[3366] title : Double Indemnity (1944)\n",
      "genres: Crime|Film-Noir\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "print_movies_by_id(other_movies_you_might_like(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Similiar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_movies(movie_id, k=20):\n",
    "    watched_movie = movies_old.iloc[movie_id]\n",
    "    print(\"======================================\")\n",
    "    print(\"The movie you watched: \" + watched_movie['title'])\n",
    "    print(\"======================================\")\n",
    "    \n",
    "    movie_feature = np.array(movies_feature_matrix[movie_id_map[movie_id]]).reshape([1,200])\n",
    "    similarity = movie_feature @ movies_feature_matrix.T\n",
    "    best_movies_id = np.argsort(similarity)\n",
    "    best_movies_id = best_movies_id[0][::-1][:k+1]\n",
    "    \n",
    "    random.shuffle(best_movies_id)\n",
    "    return best_movies_id[:k+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "The movie you watched: Local Hero (1983)\n",
      "======================================\n",
      "\n",
      "Our Recommendation:\n",
      "-------------------\n",
      "[2933] title : My Best Fiend (Mein liebster Feind) (1999)\n",
      "genres: Documentary\n",
      "-------------------\n",
      "[781] title : Last Klezmer: Leopold Kozlowski, His Life and Music, The (1995)\n",
      "genres: Documentary\n",
      "-------------------\n",
      "[3611] title : Decline of Western Civilization Part II: The Metal Years, The (1988)\n",
      "genres: Documentary\n",
      "-------------------\n",
      "[2840] title : Five Wives, Three Secretaries and Me (1998)\n",
      "genres: Documentary\n",
      "-------------------\n",
      "[29] title : Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)\n",
      "genres: Drama\n",
      "-------------------\n",
      "[125] title : Silence of the Palace, The (Saimt el Qusur) (1994)\n",
      "genres: Drama\n",
      "-------------------\n",
      "[1340] title : Paradise Lost: The Child Murders at Robin Hood Hills (1996)\n",
      "genres: Documentary\n",
      "-------------------\n",
      "[1095] title : Microcosmos (Microcosmos: Le peuple de l'herbe) (1996)\n",
      "genres: Documentary\n",
      "-------------------\n",
      "[3113] title : Mr. Death: The Rise and Fall of Fred A. Leuchter Jr. (1999)\n",
      "genres: Documentary\n",
      "-------------------\n",
      "[1722] title : Ayn Rand: A Sense of Life (1997)\n",
      "genres: Documentary\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "print_movies_by_id(similar_movies(1219, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
